{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996810cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import graphviz\n",
    "import pydot\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099c828",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ebcf6351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_cited</th>\n",
       "      <th>com1</th>\n",
       "      <th>com2</th>\n",
       "      <th>com3</th>\n",
       "      <th>com4</th>\n",
       "      <th>com5</th>\n",
       "      <th>com6</th>\n",
       "      <th>com7</th>\n",
       "      <th>com8</th>\n",
       "      <th>com9</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_cocitation_degree</th>\n",
       "      <th>max_cocitation_degree</th>\n",
       "      <th>avg_cocitation_pagerank</th>\n",
       "      <th>max_cocitation_pagerank</th>\n",
       "      <th>avg_cocitation_closeness</th>\n",
       "      <th>max_cocitation_closeness</th>\n",
       "      <th>avg_cocitation_betweenness</th>\n",
       "      <th>max_cocitation_betweenness</th>\n",
       "      <th>avg_cocitation_eigenvector</th>\n",
       "      <th>max_cocitation_eigenvector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812305</td>\n",
       "      <td>-0.844063</td>\n",
       "      <td>-0.700841</td>\n",
       "      <td>-0.678452</td>\n",
       "      <td>-1.645109</td>\n",
       "      <td>-0.828659</td>\n",
       "      <td>-0.366730</td>\n",
       "      <td>-0.349845</td>\n",
       "      <td>-0.752988</td>\n",
       "      <td>-0.828408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812606</td>\n",
       "      <td>-0.844451</td>\n",
       "      <td>-0.490453</td>\n",
       "      <td>-0.569488</td>\n",
       "      <td>-2.726319</td>\n",
       "      <td>-3.024031</td>\n",
       "      <td>-0.366730</td>\n",
       "      <td>-0.349845</td>\n",
       "      <td>-0.753003</td>\n",
       "      <td>-0.828430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812606</td>\n",
       "      <td>-0.844451</td>\n",
       "      <td>-0.717578</td>\n",
       "      <td>-0.697287</td>\n",
       "      <td>-2.726319</td>\n",
       "      <td>-3.024031</td>\n",
       "      <td>-0.366730</td>\n",
       "      <td>-0.349845</td>\n",
       "      <td>-0.753003</td>\n",
       "      <td>-0.828430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628536</td>\n",
       "      <td>-0.532096</td>\n",
       "      <td>-0.535448</td>\n",
       "      <td>-0.430261</td>\n",
       "      <td>0.102117</td>\n",
       "      <td>0.249852</td>\n",
       "      <td>-0.351946</td>\n",
       "      <td>-0.328593</td>\n",
       "      <td>-0.619343</td>\n",
       "      <td>-0.568847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.686576</td>\n",
       "      <td>-0.710584</td>\n",
       "      <td>-0.570225</td>\n",
       "      <td>-0.553282</td>\n",
       "      <td>0.195121</td>\n",
       "      <td>0.120344</td>\n",
       "      <td>-0.356354</td>\n",
       "      <td>-0.340922</td>\n",
       "      <td>-0.685004</td>\n",
       "      <td>-0.745566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55019</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.051715</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>5.059372</td>\n",
       "      <td>2.553292</td>\n",
       "      <td>0.923501</td>\n",
       "      <td>0.681408</td>\n",
       "      <td>10.533310</td>\n",
       "      <td>4.579372</td>\n",
       "      <td>0.638905</td>\n",
       "      <td>0.146249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55020</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228599</td>\n",
       "      <td>0.468993</td>\n",
       "      <td>1.592733</td>\n",
       "      <td>0.602681</td>\n",
       "      <td>0.824773</td>\n",
       "      <td>0.581175</td>\n",
       "      <td>2.374633</td>\n",
       "      <td>0.889854</td>\n",
       "      <td>0.476812</td>\n",
       "      <td>0.032744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55021</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362556</td>\n",
       "      <td>-0.302388</td>\n",
       "      <td>-0.286997</td>\n",
       "      <td>-0.264262</td>\n",
       "      <td>0.446099</td>\n",
       "      <td>0.367708</td>\n",
       "      <td>-0.179878</td>\n",
       "      <td>-0.181007</td>\n",
       "      <td>-0.416045</td>\n",
       "      <td>-0.360568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55022</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>-0.320625</td>\n",
       "      <td>-0.540804</td>\n",
       "      <td>-0.498352</td>\n",
       "      <td>-1.074596</td>\n",
       "      <td>0.329756</td>\n",
       "      <td>-0.346609</td>\n",
       "      <td>-0.331647</td>\n",
       "      <td>-0.447493</td>\n",
       "      <td>-0.400565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55023</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812606</td>\n",
       "      <td>-0.844451</td>\n",
       "      <td>-0.717578</td>\n",
       "      <td>-0.697287</td>\n",
       "      <td>-2.726319</td>\n",
       "      <td>-3.024031</td>\n",
       "      <td>-0.366730</td>\n",
       "      <td>-0.349845</td>\n",
       "      <td>-0.753003</td>\n",
       "      <td>-0.828430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55024 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       times_cited  com1  com2  com3  com4  com5  com6  com7  com8  com9  ...  \\\n",
       "0                2     0     0     0     0     0     0     1     0     0  ...   \n",
       "1                1     0     0     0     0     0     0     0     0     0  ...   \n",
       "2               48     0     0     0     0     0     0     0     0     0  ...   \n",
       "3               24     0     0     0     0     0     0     0     0     0  ...   \n",
       "4                3     0     0     0     0     0     0     1     0     0  ...   \n",
       "...            ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "55019           33     0     0     0     0     0     0     0     0     0  ...   \n",
       "55020           64     0     0     0     0     0     0     0     0     0  ...   \n",
       "55021           32     0     0     0     1     0     0     0     0     0  ...   \n",
       "55022           10     0     0     0     0     0     1     0     0     0  ...   \n",
       "55023            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "       avg_cocitation_degree  max_cocitation_degree  avg_cocitation_pagerank  \\\n",
       "0                  -0.812305              -0.844063                -0.700841   \n",
       "1                  -0.812606              -0.844451                -0.490453   \n",
       "2                  -0.812606              -0.844451                -0.717578   \n",
       "3                  -0.628536              -0.532096                -0.535448   \n",
       "4                  -0.686576              -0.710584                -0.570225   \n",
       "...                      ...                    ...                      ...   \n",
       "55019               2.051715               0.998639                 5.059372   \n",
       "55020               1.228599               0.468993                 1.592733   \n",
       "55021              -0.362556              -0.302388                -0.286997   \n",
       "55022              -0.405571              -0.320625                -0.540804   \n",
       "55023              -0.812606              -0.844451                -0.717578   \n",
       "\n",
       "       max_cocitation_pagerank  avg_cocitation_closeness  \\\n",
       "0                    -0.678452                 -1.645109   \n",
       "1                    -0.569488                 -2.726319   \n",
       "2                    -0.697287                 -2.726319   \n",
       "3                    -0.430261                  0.102117   \n",
       "4                    -0.553282                  0.195121   \n",
       "...                        ...                       ...   \n",
       "55019                 2.553292                  0.923501   \n",
       "55020                 0.602681                  0.824773   \n",
       "55021                -0.264262                  0.446099   \n",
       "55022                -0.498352                 -1.074596   \n",
       "55023                -0.697287                 -2.726319   \n",
       "\n",
       "       max_cocitation_closeness  avg_cocitation_betweenness  \\\n",
       "0                     -0.828659                   -0.366730   \n",
       "1                     -3.024031                   -0.366730   \n",
       "2                     -3.024031                   -0.366730   \n",
       "3                      0.249852                   -0.351946   \n",
       "4                      0.120344                   -0.356354   \n",
       "...                         ...                         ...   \n",
       "55019                  0.681408                   10.533310   \n",
       "55020                  0.581175                    2.374633   \n",
       "55021                  0.367708                   -0.179878   \n",
       "55022                  0.329756                   -0.346609   \n",
       "55023                 -3.024031                   -0.366730   \n",
       "\n",
       "       max_cocitation_betweenness  avg_cocitation_eigenvector  \\\n",
       "0                       -0.349845                   -0.752988   \n",
       "1                       -0.349845                   -0.753003   \n",
       "2                       -0.349845                   -0.753003   \n",
       "3                       -0.328593                   -0.619343   \n",
       "4                       -0.340922                   -0.685004   \n",
       "...                           ...                         ...   \n",
       "55019                    4.579372                    0.638905   \n",
       "55020                    0.889854                    0.476812   \n",
       "55021                   -0.181007                   -0.416045   \n",
       "55022                   -0.331647                   -0.447493   \n",
       "55023                   -0.349845                   -0.753003   \n",
       "\n",
       "       max_cocitation_eigenvector  \n",
       "0                       -0.828408  \n",
       "1                       -0.828430  \n",
       "2                       -0.828430  \n",
       "3                       -0.568847  \n",
       "4                       -0.745566  \n",
       "...                           ...  \n",
       "55019                    0.146249  \n",
       "55020                    0.032744  \n",
       "55021                   -0.360568  \n",
       "55022                   -0.400565  \n",
       "55023                   -0.828430  \n",
       "\n",
       "[55024 rows x 78 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('Data_model_citation_counts.csv')\n",
    "# Display Data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3b27b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "84d20a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation\n",
    "# Set division\n",
    "kf = 10   # 10-fold\n",
    "p = 78    # p-dimension\n",
    "KF = KFold(n_splits = kf, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff76533",
   "metadata": {},
   "source": [
    "# Determine the number of layers and neurons\n",
    "\n",
    "First, build a neural network model with only one hidden layer and set the initial number of neurons from 10 to 190 (increase 20 for each time). For each initial number, we train the model via the 10-fold cross-validation (CV). Further, the mean absolute error (MAE) of each validation set is reported and the average of the MAE is named the 10-fold CV MAE. The number of neurons corresponding to the minimum MAE is selected as the optimal number in this hidden layer. Second, fix the number of neurons in the previous hidden layer and add a new hidden layer. The optimal number of neurons in the newly added layer is determined by repeating the first step. Third, add model layers up to 4. \n",
    "\n",
    "## One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct neural network model\n",
    "# Record MAE\n",
    "MAE = np.zeros([kf*10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    for initial_num in range(10,210,20):\n",
    "        # Define Sequential model with 1 hidden layers\n",
    "        model_one_layers = keras.Sequential([\n",
    "            layers.Dense(77, activation = \"relu\", name = \"input\", input_dim = 77),\n",
    "            layers.Dense(initial_num, activation = \"relu\", name = \"layer1\"),\n",
    "            layers.Dense(1, name = \"output\")])\n",
    "        # ReduceLROnPlateau\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                    factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                    patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                    verbose = 1)\n",
    "        # Optimizer for Adam\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "        # Train the model\n",
    "        history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "        # Prediction\n",
    "        test_predictions = model_one_layers.predict(test_X)\n",
    "        # MAE\n",
    "        model_error = abs((test_predictions.ravel() - test_Y))\n",
    "        MAE[i] = model_error.mean()\n",
    "        i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_first_layer.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500670ad",
   "metadata": {},
   "source": [
    "## Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3534f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3954 - mae: 9.3954\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5664 - mae: 8.5664\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2015 - mae: 8.2015\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0403 - mae: 8.0403\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8779 - mae: 7.8779\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8086 - mae: 7.8086\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7165 - mae: 7.7165\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6376 - mae: 7.6376\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4856 - mae: 7.4856\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4180 - mae: 7.4180\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4744 - mae: 7.4744\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3012 - mae: 7.3012\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2463 - mae: 7.2463\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1417 - mae: 7.1417\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0785 - mae: 7.0785\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0974 - mae: 7.0974\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0140 - mae: 7.0140\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0515 - mae: 7.0515\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8517 - mae: 6.8517\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9003 - mae: 6.9003\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8158 - mae: 6.8158\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7801 - mae: 6.7801\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7814 - mae: 6.7814\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8818 - mae: 6.8818\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7877 - mae: 6.7877\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2940 - mae: 6.2940\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1051 - mae: 6.1051\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0166 - mae: 6.0166\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9444 - mae: 5.9444\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8904 - mae: 5.8904\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8798 - mae: 5.8798\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8243 - mae: 5.8243\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7870 - mae: 5.7870\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7519 - mae: 5.7519\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7205 - mae: 5.7205\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6991 - mae: 5.6991\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6716 - mae: 5.6716\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6448 - mae: 5.6448\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6258 - mae: 5.6258\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6042 - mae: 5.6042\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5960 - mae: 5.5960\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 5.5633 - mae: 5.5633\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5560 - mae: 5.5560\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5298 - mae: 5.5298\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5271 - mae: 5.5271\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5130 - mae: 5.5130\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4987 - mae: 5.4987\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4812 - mae: 5.4812\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4492 - mae: 5.4492\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4389 - mae: 5.4389\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4138 - mae: 5.4138\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4137 - mae: 5.4137\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3903 - mae: 5.3903\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3915 - mae: 5.3915\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3558 - mae: 5.3558\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3422 - mae: 5.3422\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3350 - mae: 5.3350\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3250 - mae: 5.3250\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3172 - mae: 5.3172\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3057 - mae: 5.3057\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2720 - mae: 5.2720\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2802 - mae: 5.2802\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2545 - mae: 5.2545\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2598 - mae: 5.2598\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2268 - mae: 5.2268\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2462 - mae: 5.2462\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1998 - mae: 5.1998\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2108 - mae: 5.2108\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1834 - mae: 5.1834\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1785 - mae: 5.1785\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1884 - mae: 5.1884\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1625 - mae: 5.1625\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1517 - mae: 5.1517\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1467 - mae: 5.1467\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1478 - mae: 5.1478\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1156 - mae: 5.1156\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1143 - mae: 5.1143\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1267 - mae: 5.1267\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0884 - mae: 5.0884\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0894 - mae: 5.0894\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1033 - mae: 5.1033\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0744 - mae: 5.0744\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0751 - mae: 5.0751\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0544 - mae: 5.0544\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0655 - mae: 5.0655\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0558 - mae: 5.0558\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0355 - mae: 5.0355\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0297 - mae: 5.0297\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0232 - mae: 5.0232\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0166 - mae: 5.0166\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0234 - mae: 5.0234\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9928 - mae: 4.9928\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0098 - mae: 5.0098\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9914 - mae: 4.9914\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9905 - mae: 4.9905\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9658 - mae: 4.9658\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9744 - mae: 4.9744\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9643 - mae: 4.9643\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9777 - mae: 4.9777\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9287 - mae: 4.9287\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9484 - mae: 4.9484\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9188 - mae: 4.9188\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9420 - mae: 4.9420\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9211 - mae: 4.9211\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9193 - mae: 4.9193\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8127 - mae: 4.8127\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7777 - mae: 4.7777\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7602 - mae: 4.7602\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7454 - mae: 4.7454\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7357 - mae: 4.7357\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7292 - mae: 4.7292\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7256 - mae: 4.7256\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7182 - mae: 4.7182\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7178 - mae: 4.7178\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7114 - mae: 4.7114\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7101 - mae: 4.7101\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7066 - mae: 4.7066\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7050 - mae: 4.7050\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7004 - mae: 4.7004\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6994 - mae: 4.6994\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6997 - mae: 4.6997\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6955 - mae: 4.6955\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6959 - mae: 4.6959\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6930 - mae: 4.6930\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6913 - mae: 4.6913\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6903 - mae: 4.6903\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6906 - mae: 4.6906\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6856 - mae: 4.6856\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6876 - mae: 4.6876\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6861 - mae: 4.6861\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6858 - mae: 4.6858\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6767 - mae: 4.6767\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6707 - mae: 4.6707\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6678 - mae: 4.6678\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6668 - mae: 4.6668\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6652 - mae: 4.6652\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6647 - mae: 4.6647\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6638 - mae: 4.6638\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6633 - mae: 4.6633\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6631 - mae: 4.6631\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6624 - mae: 4.6624\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6619 - mae: 4.6619\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6619 - mae: 4.6619\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6612 - mae: 4.6612\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6612 - mae: 4.6612\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6609 - mae: 4.6609\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6606 - mae: 4.6606\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6602 - mae: 4.6602\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6602 - mae: 4.6602\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6599 - mae: 4.6599\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6598 - mae: 4.6598\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6593 - mae: 4.6593\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6597 - mae: 4.6597\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6590 - mae: 4.6590\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6591 - mae: 4.6591\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6586 - mae: 4.6586\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6587 - mae: 4.6587\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6583 - mae: 4.6583\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6584 - mae: 4.6584\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6581 - mae: 4.6581\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6579 - mae: 4.6579\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6578 - mae: 4.6578\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6577 - mae: 4.6577\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6577 - mae: 4.6577\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6571 - mae: 4.6571\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6574 - mae: 4.6574\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6571 - mae: 4.6571\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6568 - mae: 4.6568\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6565 - mae: 4.6565\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6567 - mae: 4.6567\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6564 - mae: 4.6564\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6562 - mae: 4.6562\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6561 - mae: 4.6561\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6557 - mae: 4.6557\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6561 - mae: 4.6561\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6557 - mae: 4.6557\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6555 - mae: 4.6555\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6552 - mae: 4.6552\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6553 - mae: 4.6553\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6551 - mae: 4.6551\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6550 - mae: 4.6550\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6549 - mae: 4.6549\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6550 - mae: 4.6550\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 5s 4ms/step - loss: 4.6547 - mae: 4.6547\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6545 - mae: 4.6545\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6543 - mae: 4.6543\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6543 - mae: 4.6543\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6543 - mae: 4.6543\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6540 - mae: 4.6540\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6536 - mae: 4.6536\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6537 - mae: 4.6537\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6537 - mae: 4.6537\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6537 - mae: 4.6537\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6525 - mae: 4.6525\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6520 - mae: 4.6520\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6518 - mae: 4.6518\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6516 - mae: 4.6516\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6515 - mae: 4.6515\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6514 - mae: 4.6514\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6514 - mae: 4.6514\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3931 - mae: 9.3931\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6877 - mae: 8.6877\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4488 - mae: 8.4488\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0992 - mae: 8.0992\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0102 - mae: 8.0102\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8835 - mae: 7.8835\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8406 - mae: 7.8406\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8063 - mae: 7.8063\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7438 - mae: 7.7438\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5231 - mae: 7.5231\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5204 - mae: 7.5204\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4815 - mae: 7.4815\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2245 - mae: 7.2245\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2377 - mae: 7.2377\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2323 - mae: 7.2323\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1921 - mae: 7.1921\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1487 - mae: 7.1487\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0827 - mae: 7.0827\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0827 - mae: 7.0827\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9801 - mae: 6.9801\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9846 - mae: 6.9846\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9818 - mae: 6.9818\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9052 - mae: 6.9052\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8593 - mae: 6.8593\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8807 - mae: 6.8807\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8387 - mae: 6.8387\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7231 - mae: 6.7231\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7011 - mae: 6.7011\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7413 - mae: 6.7413\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7819 - mae: 6.7819\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7311 - mae: 6.7311\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0791 - mae: 6.0791\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9196 - mae: 5.9196\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8467 - mae: 5.8467\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7726 - mae: 5.7726\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7304 - mae: 5.7304\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6867 - mae: 5.6867\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6433 - mae: 5.6433\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6261 - mae: 5.6261\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5922 - mae: 5.5922\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5828 - mae: 5.5828\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5311 - mae: 5.5311\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5342 - mae: 5.5342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5046 - mae: 5.5046\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4947 - mae: 5.4947\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4613 - mae: 5.4613\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4364 - mae: 5.4364\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4171 - mae: 5.4171\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4169 - mae: 5.4169\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3886 - mae: 5.3886\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3903 - mae: 5.3903\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3454 - mae: 5.3454\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3449 - mae: 5.3449\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3281 - mae: 5.3281\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3165 - mae: 5.3165\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2987 - mae: 5.2987\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2829 - mae: 5.2829\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2674 - mae: 5.2674\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2653 - mae: 5.2653\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2439 - mae: 5.2439\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2133 - mae: 5.2133\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2220 - mae: 5.2220\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2054 - mae: 5.2054\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1803 - mae: 5.1803\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1857 - mae: 5.1857\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1337 - mae: 5.1337\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1425 - mae: 5.1425\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1256 - mae: 5.1256\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1277 - mae: 5.1277\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1224 - mae: 5.1224\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1146 - mae: 5.1146\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0905 - mae: 5.0905\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0996 - mae: 5.0996\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0823 - mae: 5.0823\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0678 - mae: 5.0678\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0608 - mae: 5.0608\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0514 - mae: 5.0514\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0487 - mae: 5.0487\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0266 - mae: 5.0266\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0302 - mae: 5.0302\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0245 - mae: 5.0245\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0143 - mae: 5.0143\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0062 - mae: 5.0062\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9951 - mae: 4.9951\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9918 - mae: 4.9918\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9939 - mae: 4.9939\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9764 - mae: 4.9764\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9708 - mae: 4.9708\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9798 - mae: 4.9798\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9567 - mae: 4.9567\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9508 - mae: 4.9508\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9405 - mae: 4.9405\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9471 - mae: 4.9471\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9313 - mae: 4.9313\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9203 - mae: 4.9203\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9420 - mae: 4.9420\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9163 - mae: 4.9163\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9026 - mae: 4.9026\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9005 - mae: 4.9005\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8935 - mae: 4.8935\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8897 - mae: 4.8897\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8911 - mae: 4.8911\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8754 - mae: 4.8754\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8587 - mae: 4.8587\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8590 - mae: 4.8590\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8749 - mae: 4.8749\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8600 - mae: 4.8600\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7696 - mae: 4.7696\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7321 - mae: 4.7321\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7085 - mae: 4.7085\n",
      "Epoch 111/200\n",
      " 960/1548 [=================>............] - ETA: 2s - loss: 4.7029 - mae: 4.7029"
     ]
    }
   ],
   "source": [
    "# Construct neural network model\n",
    "# Record MAE\n",
    "MAE = np.zeros([kf*10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    for initial_num in range(10,210,20):\n",
    "        # Define Sequential model with 2 hidden layers\n",
    "        model_one_layers = keras.Sequential([\n",
    "            layers.Dense(77, activation = \"relu\", name = \"input\", input_dim = 77),\n",
    "            layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "            layers.Dense(initial_num, activation = \"relu\", name = \"layer2\"),\n",
    "            layers.Dense(1, name = \"output\")])\n",
    "        # ReduceLROnPlateau\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                    factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                    patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                    verbose = 1)\n",
    "        # Optimizer for Adam\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "        # Train the model\n",
    "        history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "        # Prediction\n",
    "        test_predictions = model_one_layers.predict(test_X)\n",
    "        # MAE\n",
    "        model_error = abs((test_predictions.ravel() - test_Y))\n",
    "        MAE[i] = model_error.mean()\n",
    "        i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_second_layer.csv\",sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbac25",
   "metadata": {},
   "source": [
    "## Three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4edd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8750 - mae: 9.8750\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.8073 - mae: 8.8073\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4712 - mae: 8.4712\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2773 - mae: 8.2773\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1411 - mae: 8.1411\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0689 - mae: 8.0689\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9311 - mae: 7.9311\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1306 - mae: 8.1306\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9467 - mae: 7.9467\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8554 - mae: 7.8554\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6738 - mae: 7.6738\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7414 - mae: 7.7414\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8225 - mae: 7.8225\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6629 - mae: 7.6629\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6705 - mae: 7.6705\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4727 - mae: 7.4727\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4338 - mae: 7.4338\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2511 - mae: 7.2511\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2006 - mae: 7.2006\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1801 - mae: 7.1801\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2575 - mae: 7.2575\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1102 - mae: 7.1102\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0962 - mae: 7.0962\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2706 - mae: 7.2706\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0859 - mae: 7.0859\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0597 - mae: 7.0597\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0346 - mae: 7.0346\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0156 - mae: 7.0156\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9371 - mae: 6.9371\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2223 - mae: 7.2223\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8392 - mae: 6.8392\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8772 - mae: 6.8772\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8744 - mae: 6.8744\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7277 - mae: 6.7277\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7051 - mae: 6.7051\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8024 - mae: 6.8024\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7373 - mae: 6.7373\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6314 - mae: 6.6314\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6475 - mae: 6.6475\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6842 - mae: 6.6842\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5815 - mae: 6.5815\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5761 - mae: 6.5761\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6853 - mae: 6.6853\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7406 - mae: 6.7406\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4639 - mae: 6.4639\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6829 - mae: 6.6829\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5763 - mae: 6.5763\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6497 - mae: 6.6497\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0383 - mae: 6.0383\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8595 - mae: 5.8595\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7521 - mae: 5.7521\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6592 - mae: 5.6592\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5694 - mae: 5.5694\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5661 - mae: 5.5661\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4990 - mae: 5.4990\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4865 - mae: 5.4865\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4415 - mae: 5.4415\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4001 - mae: 5.4001\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3856 - mae: 5.3856\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3480 - mae: 5.3480\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3393 - mae: 5.3393\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3178 - mae: 5.3178\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2862 - mae: 5.2862\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3030 - mae: 5.3030\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2528 - mae: 5.2528\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2502 - mae: 5.2502\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2281 - mae: 5.2281\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2117 - mae: 5.2117\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1843 - mae: 5.1843\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1738 - mae: 5.1738\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1748 - mae: 5.1748\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1544 - mae: 5.1544\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1446 - mae: 5.1446\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1152 - mae: 5.1152\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1206 - mae: 5.1206\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1012 - mae: 5.1012\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0879 - mae: 5.0879\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0727 - mae: 5.0727\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0557 - mae: 5.0557\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0473 - mae: 5.0473\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0361 - mae: 5.0361\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0372 - mae: 5.0372\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0248 - mae: 5.0248\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0399 - mae: 5.0399\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0252 - mae: 5.0252\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9998 - mae: 4.9998\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9925 - mae: 4.9925\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9916 - mae: 4.9916\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9692 - mae: 4.9692\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9675 - mae: 4.9675\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9509 - mae: 4.9509\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9380 - mae: 4.9380\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9390 - mae: 4.9390\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9225 - mae: 4.9225\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9355 - mae: 4.9355\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9049 - mae: 4.9049\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9066 - mae: 4.9066\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8991 - mae: 4.8991\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9068 - mae: 4.9068\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8852 - mae: 4.8852\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8932 - mae: 4.8932\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8574 - mae: 4.8574\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8673 - mae: 4.8673\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8628 - mae: 4.8628\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8705 - mae: 4.8705\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8048 - mae: 4.8048\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7582 - mae: 4.7582\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7335 - mae: 4.7335\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7172 - mae: 4.7172\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7095 - mae: 4.7095\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7029 - mae: 4.7029\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6960 - mae: 4.6960\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6935 - mae: 4.6935\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6890 - mae: 4.6890\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6829 - mae: 4.6829\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6815 - mae: 4.6815\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6796 - mae: 4.6796\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6757 - mae: 4.6757\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6747 - mae: 4.6747\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6726 - mae: 4.6726\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6696 - mae: 4.6696\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6678 - mae: 4.6678\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6668 - mae: 4.6668\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6668 - mae: 4.6668\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6648 - mae: 4.6648\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6622 - mae: 4.6622\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6617 - mae: 4.6617\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6597 - mae: 4.6597\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6582 - mae: 4.6582\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6595 - mae: 4.6595\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6549 - mae: 4.6549\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6543 - mae: 4.6543\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6527 - mae: 4.6527\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6537 - mae: 4.6537\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6517 - mae: 4.6517\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6512 - mae: 4.6512\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6480 - mae: 4.6480\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6491 - mae: 4.6491\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6466 - mae: 4.6466\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6461 - mae: 4.6461\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6470 - mae: 4.6470\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6453 - mae: 4.6453\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6420 - mae: 4.6420\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6413 - mae: 4.6413\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6419 - mae: 4.6419\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6420 - mae: 4.6420\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6395 - mae: 4.6395\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6374 - mae: 4.6374\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6393 - mae: 4.6393\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6387 - mae: 4.6387\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6347 - mae: 4.6347\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6352 - mae: 4.6352\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6350 - mae: 4.6350\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6331 - mae: 4.6331\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6351 - mae: 4.6351\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6322 - mae: 4.6322\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6336 - mae: 4.6336\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6299 - mae: 4.6299\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6314 - mae: 4.6314\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6294 - mae: 4.6294\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6293 - mae: 4.6293\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6269 - mae: 4.6269\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6268 - mae: 4.6268\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6290 - mae: 4.6290\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6257 - mae: 4.6257\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6248 - mae: 4.6248\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6244 - mae: 4.6244\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6223 - mae: 4.6223\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6241 - mae: 4.6241\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6225 - mae: 4.6225\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6227 - mae: 4.6227\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6148 - mae: 4.6148\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6112 - mae: 4.6112\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6090 - mae: 4.6090\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6075 - mae: 4.6075\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6063 - mae: 4.6063\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6053 - mae: 4.6053\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6044 - mae: 4.6044\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6040 - mae: 4.6040\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6032 - mae: 4.6032\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6032 - mae: 4.6032\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6025 - mae: 4.6025\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6024 - mae: 4.6024\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6022 - mae: 4.6022\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6020 - mae: 4.6020\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6017 - mae: 4.6017\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6015 - mae: 4.6015\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6016 - mae: 4.6016\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6012 - mae: 4.6012\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6010 - mae: 4.6010\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6009 - mae: 4.6009\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6010 - mae: 4.6010\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6004 - mae: 4.6004\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6005 - mae: 4.6005\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6005 - mae: 4.6005\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6001 - mae: 4.6001\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6003 - mae: 4.6003\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6000 - mae: 4.6000\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.8683 - mae: 9.8683\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.1618 - mae: 9.1618\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5624 - mae: 8.5624\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1829 - mae: 8.1829\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0796 - mae: 8.0796\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8863 - mae: 7.8863\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8403 - mae: 7.8403\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8183 - mae: 7.8183\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6616 - mae: 7.6616\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4808 - mae: 7.4808\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6317 - mae: 7.6317\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6146 - mae: 7.6146\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5263 - mae: 7.5263\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1510 - mae: 7.1510\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7284 - mae: 6.7284\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6288 - mae: 6.6288\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5264 - mae: 6.5264\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4660 - mae: 6.4660\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4319 - mae: 6.4319\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3701 - mae: 6.3701\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3461 - mae: 6.3461\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3088 - mae: 6.3088\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2702 - mae: 6.2702\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2324 - mae: 6.2324\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2156 - mae: 6.2156\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1560 - mae: 6.1560\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1498 - mae: 6.1498\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1030 - mae: 6.1030\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0734 - mae: 6.0734\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0650 - mae: 6.0650\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0043 - mae: 6.0043\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9857 - mae: 5.9857\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9858 - mae: 5.9858\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9753 - mae: 5.9753\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9204 - mae: 5.9204\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9060 - mae: 5.9060\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8524 - mae: 5.8524\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8675 - mae: 5.8675\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8212 - mae: 5.8212\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8012 - mae: 5.8012\n",
      "Epoch 42/200\n",
      " 415/1548 [=======>......................] - ETA: 4s - loss: 5.7355 - mae: 5.7355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4648 - mae: 5.4648\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4399 - mae: 5.4399\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4322 - mae: 5.4322\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4061 - mae: 5.4061\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3992 - mae: 5.3992\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3717 - mae: 5.3717\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3570 - mae: 5.3570\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3475 - mae: 5.3475\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3376 - mae: 5.3376\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3343 - mae: 5.3343\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3047 - mae: 5.3047\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2779 - mae: 5.2779\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2702 - mae: 5.2702\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2611 - mae: 5.2611\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2203 - mae: 5.2203\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2082 - mae: 5.2082\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2159 - mae: 5.2159\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2080 - mae: 5.2080\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2064 - mae: 5.2064\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1746 - mae: 5.1746\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1554 - mae: 5.1554\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1460 - mae: 5.1460\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1137 - mae: 5.1137\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1330 - mae: 5.1330\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1088 - mae: 5.1088\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0804 - mae: 5.0804\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1006 - mae: 5.1006\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0606 - mae: 5.0606\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0572 - mae: 5.0572\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0505 - mae: 5.0505\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0140 - mae: 5.0140\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0487 - mae: 5.0487\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0399 - mae: 5.0399\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0314 - mae: 5.0314\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8786 - mae: 4.8786\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7957 - mae: 4.7957\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7647 - mae: 4.7647\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7417 - mae: 4.7417\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7327 - mae: 4.7327\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7144 - mae: 4.7144\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7116 - mae: 4.7116\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7040 - mae: 4.7040\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6959 - mae: 4.6959\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6911 - mae: 4.6911\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6832 - mae: 4.6832\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6774 - mae: 4.6774\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6746 - mae: 4.6746\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6683 - mae: 4.6683\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6618 - mae: 4.6618\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6610 - mae: 4.6610\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6586 - mae: 4.6586\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6541 - mae: 4.6541\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6483 - mae: 4.6483\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6458 - mae: 4.6458\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6433 - mae: 4.6433\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6410 - mae: 4.6410\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6365 - mae: 4.6365\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6384 - mae: 4.6384\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6314 - mae: 4.6314\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6340 - mae: 4.6340\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6299 - mae: 4.6299\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6257 - mae: 4.6257\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6262 - mae: 4.6262\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6240 - mae: 4.6240\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6212 - mae: 4.6212\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6164 - mae: 4.6164\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6200 - mae: 4.6200\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6143 - mae: 4.6143\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6154 - mae: 4.6154\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6114 - mae: 4.6114\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6077 - mae: 4.6077\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6072 - mae: 4.6072\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6048 - mae: 4.6048\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6044 - mae: 4.6044\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6048 - mae: 4.6048\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6004 - mae: 4.6004\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6019 - mae: 4.6019\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5956 - mae: 4.5956\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5977 - mae: 4.5977\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5928 - mae: 4.5928\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5909 - mae: 4.5909\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5929 - mae: 4.5929\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5865 - mae: 4.5865\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5832 - mae: 4.5832\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5886 - mae: 4.5886\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5836 - mae: 4.5836\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5819 - mae: 4.5819\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5780 - mae: 4.5780\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5792 - mae: 4.5792\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5789 - mae: 4.5789\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5743 - mae: 4.5743\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5768 - mae: 4.5768\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5718 - mae: 4.5718\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5710 - mae: 4.5710\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5721 - mae: 4.5721\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5683 - mae: 4.5683\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5660 - mae: 4.5660\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5673 - mae: 4.5673\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5668 - mae: 4.5668\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5620 - mae: 4.5620\n",
      "Epoch 157/200\n",
      " 512/1548 [========>.....................] - ETA: 3s - loss: 4.4640 - mae: 4.4640"
     ]
    }
   ],
   "source": [
    "# Construct neural network model\n",
    "# Record MAE\n",
    "MAE = np.zeros([kf*10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    for initial_num in range(10,210,20):\n",
    "        # Define Sequential model with 3 hidden layers\n",
    "        model_one_layers = keras.Sequential([\n",
    "            layers.Dense(77, activation = \"relu\", name = \"input\", input_dim = 77),\n",
    "            layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "            layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "            layers.Dense(initial_num, activation = \"relu\", name = \"layer3\"),\n",
    "            layers.Dense(1, name = \"output\")])\n",
    "        # ReduceLROnPlateau\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                    factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                    patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                    verbose = 1)\n",
    "        # Optimizer for Adam\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "        # Train the model\n",
    "        history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "        # Prediction\n",
    "        test_predictions = model_one_layers.predict(test_X)\n",
    "        # MAE\n",
    "        model_error = abs((test_predictions.ravel() - test_Y))\n",
    "        MAE[i] = model_error.mean()\n",
    "        i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_third_layer.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da8eb9",
   "metadata": {},
   "source": [
    "## Four hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b56ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8203 - mae: 9.8203\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9070 - mae: 8.9070\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6593 - mae: 8.6593\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.8133 - mae: 8.8133\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3882 - mae: 8.3882\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.3934 - mae: 8.3934\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1555 - mae: 8.1555\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5788 - mae: 8.5788\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5246 - mae: 8.5246\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4456 - mae: 8.4456\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8652 - mae: 7.8652\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5001 - mae: 7.5001\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4147 - mae: 7.4147\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3324 - mae: 7.3324\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2735 - mae: 7.2735\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1907 - mae: 7.1907\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1709 - mae: 7.1709\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0756 - mae: 7.0756\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0501 - mae: 7.0501\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0063 - mae: 7.0063\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9439 - mae: 6.9439\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8955 - mae: 6.8955\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8517 - mae: 6.8517\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8148 - mae: 6.8148\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.7786 - mae: 6.7786\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7272 - mae: 6.7272\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7125 - mae: 6.7125\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6537 - mae: 6.6537\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6533 - mae: 6.6533\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6234 - mae: 6.6234\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6200 - mae: 6.6200\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5379 - mae: 6.5379\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5204 - mae: 6.5204\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5053 - mae: 6.5053\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4668 - mae: 6.4668\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4109 - mae: 6.4109\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3867 - mae: 6.3867\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3760 - mae: 6.3760\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3720 - mae: 6.3720\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3078 - mae: 6.3078\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2657 - mae: 6.2657\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2433 - mae: 6.2433\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2006 - mae: 6.2006\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2352 - mae: 6.2352\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1683 - mae: 6.1683\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1733 - mae: 6.1733\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1388 - mae: 6.1388\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1067 - mae: 6.1067\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0971 - mae: 6.0971\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0696 - mae: 6.0696\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0449 - mae: 6.0449\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0328 - mae: 6.0328\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9969 - mae: 5.9969\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0004 - mae: 6.0004\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9940 - mae: 5.9940\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9472 - mae: 5.9472\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9250 - mae: 5.9250\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9068 - mae: 5.9068\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9199 - mae: 5.9199\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8839 - mae: 5.8839\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8793 - mae: 5.8793\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8050 - mae: 5.8050\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8685 - mae: 5.8685\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8280 - mae: 5.8280\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8092 - mae: 5.8092\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5971 - mae: 5.5971\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5696 - mae: 5.5696\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5404 - mae: 5.5404\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5307 - mae: 5.5307\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5226 - mae: 5.5226\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5017 - mae: 5.5017\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5071 - mae: 5.5071\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5038 - mae: 5.5038\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4934 - mae: 5.4934\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4888 - mae: 5.4888\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4874 - mae: 5.4874\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4792 - mae: 5.4792\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4673 - mae: 5.4673A: \n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4725 - mae: 5.4725\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4666 - mae: 5.4666\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4586 - mae: 5.4586\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4645 - mae: 5.4645\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4520 - mae: 5.4520\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4540 - mae: 5.4540\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4477 - mae: 5.4477\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4442 - mae: 5.4442\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4403 - mae: 5.4403\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4386 - mae: 5.4386\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4337 - mae: 5.4337\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4314 - mae: 5.4314\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4353 - mae: 5.4353\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4256 - mae: 5.4256\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4196 - mae: 5.4196\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4143 - mae: 5.4143\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4161 - mae: 5.4161\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4140 - mae: 5.4140\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4084 - mae: 5.4084\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4124 - mae: 5.4124\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4055 - mae: 5.4055\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4040 - mae: 5.4040\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4013 - mae: 5.4013\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3978 - mae: 5.3978\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3967 - mae: 5.3967\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3936 - mae: 5.3936\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3861 - mae: 5.3861\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3805 - mae: 5.3805\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3863 - mae: 5.3863\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3813 - mae: 5.3813\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3773 - mae: 5.3773\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3764 - mae: 5.3764\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3689 - mae: 5.3689\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3732 - mae: 5.3732\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3703 - mae: 5.3703\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3671 - mae: 5.3671\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3630 - mae: 5.3630\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3590 - mae: 5.3590\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3539 - mae: 5.3539\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3555 - mae: 5.3555\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3595 - mae: 5.3595\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3505 - mae: 5.3505\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3498 - mae: 5.3498\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3491 - mae: 5.3491\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3453 - mae: 5.3453\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3453 - mae: 5.3453\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3402 - mae: 5.3402\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3333 - mae: 5.3333\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3377 - mae: 5.3377\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3307 - mae: 5.3307\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3329 - mae: 5.3329\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3252 - mae: 5.3252\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3326 - mae: 5.3326\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3254 - mae: 5.3254\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3230 - mae: 5.3230\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3201 - mae: 5.3201\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3162 - mae: 5.3162\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3147 - mae: 5.3147\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3119 - mae: 5.3119\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3117 - mae: 5.3117\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3078 - mae: 5.3078\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3063 - mae: 5.3063\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3064 - mae: 5.3064\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3019 - mae: 5.3019\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3003 - mae: 5.3003\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2992 - mae: 5.2992\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2927 - mae: 5.2927\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2953 - mae: 5.2953\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2933 - mae: 5.2933\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2907 - mae: 5.2907\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2858 - mae: 5.2858\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2856 - mae: 5.2856\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2825 - mae: 5.2825\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2815 - mae: 5.2815\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2820 - mae: 5.2820\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2751 - mae: 5.2751\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2716 - mae: 5.2716\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2809 - mae: 5.2809\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2723 - mae: 5.2723\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2682 - mae: 5.2682\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2683 - mae: 5.2683\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2707 - mae: 5.2707\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2578 - mae: 5.2578\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2663 - mae: 5.2663\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2583 - mae: 5.2583\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2575 - mae: 5.2575\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2540 - mae: 5.2540\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2582 - mae: 5.2582\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2543 - mae: 5.2543\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2465 - mae: 5.2465\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2520 - mae: 5.2520\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2444 - mae: 5.2444\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2470 - mae: 5.2470\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2473 - mae: 5.2473\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2417 - mae: 5.2417\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2383 - mae: 5.2383\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2397 - mae: 5.2397\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2339 - mae: 5.2339\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2333 - mae: 5.2333\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2342 - mae: 5.2342\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2285 - mae: 5.2285\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2282 - mae: 5.2282\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2248 - mae: 5.2248\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2247 - mae: 5.2247\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2245 - mae: 5.2245\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2176 - mae: 5.2176\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2198 - mae: 5.2198\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2148 - mae: 5.2148\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2171 - mae: 5.2171\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2148 - mae: 5.2148\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2122 - mae: 5.2122\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2110 - mae: 5.2110\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2099 - mae: 5.2099\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2087 - mae: 5.2087\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2108 - mae: 5.2108\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2020 - mae: 5.2020\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2034 - mae: 5.2034\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1981 - mae: 5.1981\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2000 - mae: 5.2000\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1969 - mae: 5.1969\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1945 - mae: 5.1945\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1950 - mae: 5.1950\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.7489 - mae: 9.7489\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9008 - mae: 8.9008\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6097 - mae: 8.6097\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3561 - mae: 8.3561\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2657 - mae: 8.2657\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2488 - mae: 8.2488\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1177 - mae: 8.1177\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0918 - mae: 8.0918\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0077 - mae: 8.0077\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7912 - mae: 7.7912\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8273 - mae: 7.8273\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7631 - mae: 7.7631\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.7201 - mae: 7.7201\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6480 - mae: 7.6480\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6455 - mae: 7.6455\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6543 - mae: 7.6543\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5476 - mae: 7.5476\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5610 - mae: 7.5610\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4994 - mae: 7.4994\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5251 - mae: 7.5251\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4341 - mae: 7.4341\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5930 - mae: 7.5930\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9857 - mae: 7.9857\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2396 - mae: 8.2396\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0389 - mae: 7.0389\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8622 - mae: 6.8622\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7716 - mae: 6.7716\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6815 - mae: 6.6815\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6114 - mae: 6.6114\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5566 - mae: 6.5566\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4608 - mae: 6.4608\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4578 - mae: 6.4578\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3585 - mae: 6.3585\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3214 - mae: 6.3214\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2360 - mae: 6.2360\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2448 - mae: 6.2448\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1645 - mae: 6.1645\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1396 - mae: 6.1396\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1052 - mae: 6.1052\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0587 - mae: 6.0587\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0603 - mae: 6.0603\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9976 - mae: 5.9976\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9622 - mae: 5.9622\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9354 - mae: 5.9354\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8974 - mae: 5.8974\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8855 - mae: 5.8855\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8721 - mae: 5.8721\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8541 - mae: 5.8541\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8314 - mae: 5.8314\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8143 - mae: 5.8143\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7856 - mae: 5.7856\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7900 - mae: 5.7900\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7452 - mae: 5.7452\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7583 - mae: 5.7583\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7286 - mae: 5.7286\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7186 - mae: 5.7186\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7036 - mae: 5.7036\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6896 - mae: 5.6896\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6571 - mae: 5.6571\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6849 - mae: 5.6849\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6381 - mae: 5.6381\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6268 - mae: 5.6268\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6114 - mae: 5.6114\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5790 - mae: 5.5790\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6000 - mae: 5.6000\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5674 - mae: 5.5674\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5775 - mae: 5.5775\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4973 - mae: 5.4973\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5378 - mae: 5.5378\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4851 - mae: 5.4851\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5165 - mae: 5.5165\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4736 - mae: 5.4736\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4891 - mae: 5.4891\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4550 - mae: 5.4550\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4400 - mae: 5.4400\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4426 - mae: 5.4426\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4354 - mae: 5.4354\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4349 - mae: 5.4349\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4086 - mae: 5.4086\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4161 - mae: 5.4161\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3703 - mae: 5.3703\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3639 - mae: 5.3639\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3508 - mae: 5.3508\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3408 - mae: 5.3408\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3338 - mae: 5.3338\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3429 - mae: 5.3429\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3059 - mae: 5.3059\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2847 - mae: 5.2847\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3090 - mae: 5.3090\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3133 - mae: 5.3133\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2545 - mae: 5.2545\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2562 - mae: 5.2562\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3031 - mae: 5.3031\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2399 - mae: 5.2399\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2229 - mae: 5.2229\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2387 - mae: 5.2387\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1902 - mae: 5.1902\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2574 - mae: 5.2574\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1631 - mae: 5.1631\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2120 - mae: 5.2120\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1651 - mae: 5.1651\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2083 - mae: 5.2083\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0735 - mae: 5.0735\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0081 - mae: 5.0081\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9725 - mae: 4.9725\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9516 - mae: 4.9516\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9322 - mae: 4.9322\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9245 - mae: 4.9245\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9205 - mae: 4.9205\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9130 - mae: 4.9130\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9052 - mae: 4.9052\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9027 - mae: 4.9027\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8909 - mae: 4.8909\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8916 - mae: 4.8916\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8874 - mae: 4.8874\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8884 - mae: 4.8884\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8751 - mae: 4.8751\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8779 - mae: 4.8779\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8706 - mae: 4.8706\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8697 - mae: 4.8697\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8666 - mae: 4.8666\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8670 - mae: 4.8670\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8617 - mae: 4.8617\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8599 - mae: 4.8599\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8576 - mae: 4.8576\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8562 - mae: 4.8562\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8531 - mae: 4.8531\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8543 - mae: 4.8543\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8513 - mae: 4.8513\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8485 - mae: 4.8485\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8469 - mae: 4.8469\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8428 - mae: 4.8428\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8437 - mae: 4.8437\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8426 - mae: 4.8426\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8370 - mae: 4.8370\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8422 - mae: 4.8422\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8335 - mae: 4.8335\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8322 - mae: 4.8322\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8336 - mae: 4.8336\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8297 - mae: 4.8297\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8335 - mae: 4.8335\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8270 - mae: 4.8270\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8296 - mae: 4.8296\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8248 - mae: 4.8248\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8267 - mae: 4.8267\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8243 - mae: 4.8243\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8202 - mae: 4.8202\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8217 - mae: 4.8217\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8180 - mae: 4.8180\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8172 - mae: 4.8172\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8169 - mae: 4.8169\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8180 - mae: 4.8180\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8157 - mae: 4.8157\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8103 - mae: 4.8103\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8129 - mae: 4.8129\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8126 - mae: 4.8126\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8141 - mae: 4.8141\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7991 - mae: 4.7991\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7900 - mae: 4.7900\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7871 - mae: 4.7871\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7847 - mae: 4.7847\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7836 - mae: 4.7836\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7819 - mae: 4.7819\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7810 - mae: 4.7810\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7799 - mae: 4.7799\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7795 - mae: 4.7795\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7789 - mae: 4.7789\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7777 - mae: 4.7777\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7778 - mae: 4.7778\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7771 - mae: 4.7771\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7769 - mae: 4.7769\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7769 - mae: 4.7769\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7761 - mae: 4.7761\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7758 - mae: 4.7758\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7757 - mae: 4.7757\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7750 - mae: 4.7750\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7750 - mae: 4.7750\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7748 - mae: 4.7748\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7746 - mae: 4.7746\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7741 - mae: 4.7741\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7745 - mae: 4.7745\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7737 - mae: 4.7737\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7738 - mae: 4.7738\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7735 - mae: 4.7735\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7735 - mae: 4.7735\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7733 - mae: 4.7733\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7729 - mae: 4.7729\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7730 - mae: 4.7730\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7727 - mae: 4.7727\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7725 - mae: 4.7725\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7723 - mae: 4.7723\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7723 - mae: 4.7723\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7715 - mae: 4.7715\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7719 - mae: 4.7719\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7716 - mae: 4.7716\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7716 - mae: 4.7716\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7701 - mae: 4.7701\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7694 - mae: 4.7694\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7691 - mae: 4.7691\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7688 - mae: 4.7688\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.9990 - mae: 9.9990\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.9625 - mae: 8.9625\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6731 - mae: 8.6731\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4193 - mae: 8.4193\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4870 - mae: 8.4870\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5584 - mae: 8.5584\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2859 - mae: 8.2859\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0059 - mae: 8.0059\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0997 - mae: 8.0997\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9209 - mae: 7.9209\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5037 - mae: 8.5037\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0021 - mae: 8.0021\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8889 - mae: 7.8889\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9261 - mae: 7.9261\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1675 - mae: 8.1675\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1358 - mae: 8.1358\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4090 - mae: 7.4090\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1212 - mae: 7.1212\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9970 - mae: 6.9970\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9040 - mae: 6.9040\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.8199 - mae: 6.8199\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7415 - mae: 6.7415\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6800 - mae: 6.6800\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6480 - mae: 6.6480\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5895 - mae: 6.5895\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5416 - mae: 6.5416\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4801 - mae: 6.4801\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4395 - mae: 6.4395\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4307 - mae: 6.4307\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3962 - mae: 6.3962\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3643 - mae: 6.3643\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3336 - mae: 6.3336\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2582 - mae: 6.2582\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2830 - mae: 6.2830\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2379 - mae: 6.2379\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2139 - mae: 6.2139\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1586 - mae: 6.1586\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1653 - mae: 6.1653\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1248 - mae: 6.1248\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.0895 - mae: 6.0895\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0997 - mae: 6.0997\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0590 - mae: 6.0590\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0419 - mae: 6.0419\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0380 - mae: 6.0380\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9964 - mae: 5.9964\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0124 - mae: 6.0124\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9221 - mae: 5.9221\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9313 - mae: 5.9313\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8667 - mae: 5.8667\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9048 - mae: 5.9048\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9060 - mae: 5.9060\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8308 - mae: 5.8308\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8315 - mae: 5.8315\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7806 - mae: 5.7806\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7685 - mae: 5.7685\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7199 - mae: 5.7199\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7750 - mae: 5.7750\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6937 - mae: 5.6937\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6993 - mae: 5.6993\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6543 - mae: 5.6543\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6327 - mae: 5.6327\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6376 - mae: 5.6376\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6085 - mae: 5.6085\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6360 - mae: 5.6360\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6602 - mae: 5.6602\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5939 - mae: 5.5939\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5692 - mae: 5.5692\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5722 - mae: 5.5722\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5193 - mae: 5.5193\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5349 - mae: 5.5349\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4976 - mae: 5.4976\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4883 - mae: 5.4883\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4975 - mae: 5.4975\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4517 - mae: 5.4517\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4570 - mae: 5.4570\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4433 - mae: 5.4433\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4542 - mae: 5.4542\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4312 - mae: 5.4312\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3973 - mae: 5.3973\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4054 - mae: 5.4054\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3783 - mae: 5.3783\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3933 - mae: 5.3933\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3720 - mae: 5.3720\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3790 - mae: 5.3790\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3276 - mae: 5.3276\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3595 - mae: 5.3595\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3609 - mae: 5.3609\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3783 - mae: 5.3783\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1928 - mae: 5.1928\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1230 - mae: 5.1230\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0935 - mae: 5.0935\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0671 - mae: 5.0671\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0538 - mae: 5.0538\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0322 - mae: 5.0322\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0212 - mae: 5.0212\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0084 - mae: 5.0084\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0008 - mae: 5.0008\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9902 - mae: 4.9902\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9842 - mae: 4.9842\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9791 - mae: 4.9791\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9680 - mae: 4.9680\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9663 - mae: 4.9663\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9577 - mae: 4.9577\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9518 - mae: 4.9518\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9479 - mae: 4.9479\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9392 - mae: 4.9392\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9390 - mae: 4.9390\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9353 - mae: 4.9353\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9301 - mae: 4.9301\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9281 - mae: 4.9281\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9182 - mae: 4.9182\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9152 - mae: 4.9152\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9188 - mae: 4.9188\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9063 - mae: 4.9063\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.9111 - mae: 4.9111\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9017 - mae: 4.9017\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9009 - mae: 4.9009\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8960 - mae: 4.8960\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8952 - mae: 4.8952\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8908 - mae: 4.8908\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8889 - mae: 4.8889\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8917 - mae: 4.8917\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8879 - mae: 4.8879\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8856 - mae: 4.8856\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8844 - mae: 4.8844\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8797 - mae: 4.8797\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8773 - mae: 4.8773\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8787 - mae: 4.8787\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8725 - mae: 4.8725\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8753 - mae: 4.8753\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8678 - mae: 4.8678\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8728 - mae: 4.8728\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8689 - mae: 4.8689\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8643 - mae: 4.8643\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8623 - mae: 4.8623\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8632 - mae: 4.8632\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8609 - mae: 4.8609\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8571 - mae: 4.8571\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8592 - mae: 4.8592\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8529 - mae: 4.8529\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8522 - mae: 4.8522\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8532 - mae: 4.8532\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8493 - mae: 4.8493\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8505 - mae: 4.8505\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8493 - mae: 4.8493\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8470 - mae: 4.8470\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8433 - mae: 4.8433\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8449 - mae: 4.8449\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8414 - mae: 4.8414\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8394 - mae: 4.8394\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8427 - mae: 4.8427\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8364 - mae: 4.8364\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8395 - mae: 4.8395\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8353 - mae: 4.8353\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8348 - mae: 4.8348\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8333 - mae: 4.8333\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8320 - mae: 4.8320\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8321 - mae: 4.8321\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8317 - mae: 4.8317\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8253 - mae: 4.8253\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8285 - mae: 4.8285\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8220 - mae: 4.8220\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8205 - mae: 4.8205\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8238 - mae: 4.8238\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8207 - mae: 4.8207\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8166 - mae: 4.8166\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8191 - mae: 4.8191\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8149 - mae: 4.8149\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8143 - mae: 4.8143\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8151 - mae: 4.8151\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8124 - mae: 4.8124\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8101 - mae: 4.8101\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8087 - mae: 4.8087\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8123 - mae: 4.8123\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8031 - mae: 4.8031\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8042 - mae: 4.8042\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8053 - mae: 4.8053\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8065 - mae: 4.8065\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8075 - mae: 4.8075\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7901 - mae: 4.7901\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7825 - mae: 4.7825\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7769 - mae: 4.7769\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7725 - mae: 4.7725\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7693 - mae: 4.7693\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7668 - mae: 4.7668\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7654 - mae: 4.7654\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7644 - mae: 4.7644\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7631 - mae: 4.7631\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7620 - mae: 4.7620\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7610 - mae: 4.7610\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7610 - mae: 4.7610\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7599 - mae: 4.7599\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7598 - mae: 4.7598\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7591 - mae: 4.7591\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7590 - mae: 4.7590\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7586 - mae: 4.7586\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7576 - mae: 4.7576\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7577 - mae: 4.7577\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7574 - mae: 4.7574\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7573 - mae: 4.7573\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8697 - mae: 9.8697\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9020 - mae: 8.9020\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4647 - mae: 8.4647\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5783 - mae: 8.5783\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3932 - mae: 8.3932\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2711 - mae: 8.2711\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1527 - mae: 8.1527\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1567 - mae: 8.1567\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8921 - mae: 7.8921\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9783 - mae: 7.9783\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9346 - mae: 7.9346\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7830 - mae: 7.7830\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1601 - mae: 8.1601\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1549 - mae: 8.1549\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8274 - mae: 7.8274\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7854 - mae: 7.7854\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3211 - mae: 7.3211\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1196 - mae: 7.1196\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9680 - mae: 6.9680\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9044 - mae: 6.9044\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8542 - mae: 6.8542\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8997 - mae: 6.8997\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7689 - mae: 6.7689\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7386 - mae: 6.7386\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.6848 - mae: 6.6848\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6686 - mae: 6.6686\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6521 - mae: 6.6521\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5903 - mae: 6.5903\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5302 - mae: 6.5302\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.5080 - mae: 6.5080\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4395 - mae: 6.4395\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3972 - mae: 6.3972\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3962 - mae: 6.3962\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3436 - mae: 6.3436\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.3092 - mae: 6.3092\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2596 - mae: 6.2596\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2684 - mae: 6.2684\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2404 - mae: 6.2404\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2231 - mae: 6.2231\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2137 - mae: 6.2137\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.1458 - mae: 6.1458\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1618 - mae: 6.1618\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1079 - mae: 6.1079\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0816 - mae: 6.0816\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0809 - mae: 6.0809\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0817 - mae: 6.0817\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0085 - mae: 6.0085\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.0203 - mae: 6.0203\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9968 - mae: 5.9968\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9463 - mae: 5.9463\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9070 - mae: 5.9070\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9103 - mae: 5.9103\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8949 - mae: 5.8949\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8979 - mae: 5.8979\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8894 - mae: 5.8894\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8885 - mae: 5.8885\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8567 - mae: 5.8567\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7852 - mae: 5.7852\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8387 - mae: 5.8387\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7987 - mae: 5.7987\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8257 - mae: 5.8257\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6683 - mae: 5.6683\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6312 - mae: 5.6312\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6015 - mae: 5.6015\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5745 - mae: 5.5745\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5652 - mae: 5.5652\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5524 - mae: 5.5524\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5465 - mae: 5.5465\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5369 - mae: 5.5369\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5255 - mae: 5.5255\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5257 - mae: 5.5257\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5187 - mae: 5.5187\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5099 - mae: 5.5099\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5068 - mae: 5.5068\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5049 - mae: 5.5049\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4924 - mae: 5.4924\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4970 - mae: 5.4970\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4878 - mae: 5.4878\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4907 - mae: 5.4907\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4802 - mae: 5.4802\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4828 - mae: 5.4828\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4776 - mae: 5.4776\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4708 - mae: 5.4708\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4702 - mae: 5.4702\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4651 - mae: 5.4651\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4686 - mae: 5.4686\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4606 - mae: 5.4606\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4593 - mae: 5.4593\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4552 - mae: 5.4552\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4522 - mae: 5.4522\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4516 - mae: 5.4516\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4453 - mae: 5.4453\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4434 - mae: 5.4434\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4423 - mae: 5.4423\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4407 - mae: 5.4407\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4423 - mae: 5.4423\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4369 - mae: 5.4369\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4368 - mae: 5.4368\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4338 - mae: 5.4338\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4350 - mae: 5.4350\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4252 - mae: 5.4252\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4280 - mae: 5.4280\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4238 - mae: 5.4238\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4260 - mae: 5.4260\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4143 - mae: 5.4143\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4205 - mae: 5.4205\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4220 - mae: 5.4220\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4155 - mae: 5.4155\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4044 - mae: 5.4044\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3976 - mae: 5.3976\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3930 - mae: 5.3930\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3896 - mae: 5.3896\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3889 - mae: 5.3889\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3867 - mae: 5.3867\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3849 - mae: 5.3849\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3847 - mae: 5.3847\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3835 - mae: 5.3835\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3828 - mae: 5.3828\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3822 - mae: 5.3822\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3818 - mae: 5.3818\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3808 - mae: 5.3808\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3799 - mae: 5.3799\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3795 - mae: 5.3795\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3794 - mae: 5.3794\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3791 - mae: 5.3791\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3786 - mae: 5.3786\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3779 - mae: 5.3779\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3777 - mae: 5.3777\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3782 - mae: 5.3782\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3772 - mae: 5.3772\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3776 - mae: 5.3776\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3770 - mae: 5.3770\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3766 - mae: 5.3766\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3761 - mae: 5.3761\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3761 - mae: 5.3761\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3761 - mae: 5.3761\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3750 - mae: 5.3750\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3758 - mae: 5.3758\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3745 - mae: 5.3745\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3753 - mae: 5.3753\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3747 - mae: 5.3747\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3743 - mae: 5.3743\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3737 - mae: 5.3737\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3738 - mae: 5.3738\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3737 - mae: 5.3737\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3732 - mae: 5.3732\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3737 - mae: 5.3737\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3731 - mae: 5.3731\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3730 - mae: 5.3730\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3727 - mae: 5.3727\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3722 - mae: 5.3722\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3721 - mae: 5.3721\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3723 - mae: 5.3723\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3717 - mae: 5.3717\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3712 - mae: 5.3712\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3714 - mae: 5.3714\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3715 - mae: 5.3715\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3710 - mae: 5.3710\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3703 - mae: 5.3703\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3707 - mae: 5.3707\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3706 - mae: 5.3706\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3701 - mae: 5.3701\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3707 - mae: 5.3707\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3695 - mae: 5.3695\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3698 - mae: 5.3698\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3689 - mae: 5.3689\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3694 - mae: 5.3694\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3689 - mae: 5.3689\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3685 - mae: 5.3685\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3693 - mae: 5.3693\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3685 - mae: 5.3685\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3682 - mae: 5.3682\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3679 - mae: 5.3679\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3679 - mae: 5.3679\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3682 - mae: 5.3682\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3676 - mae: 5.3676\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3673 - mae: 5.3673\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3668 - mae: 5.3668\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3672 - mae: 5.3672\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3664 - mae: 5.3664\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3675 - mae: 5.3675\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3659 - mae: 5.3659\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3665 - mae: 5.3665\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3653 - mae: 5.3653\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3667 - mae: 5.3667\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3652 - mae: 5.3652\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3658 - mae: 5.3658\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3636 - mae: 5.3636\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3631 - mae: 5.3631\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3628 - mae: 5.3628\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3625 - mae: 5.3625\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3625 - mae: 5.3625\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3623 - mae: 5.3623\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3622 - mae: 5.3622\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3621 - mae: 5.3621\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3621 - mae: 5.3621\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3619 - mae: 5.3619\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3619 - mae: 5.3619\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3618 - mae: 5.3618\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3619 - mae: 5.3619\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8586 - mae: 9.8586\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9774 - mae: 8.9774\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6662 - mae: 8.6662\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5385 - mae: 8.5385\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6801 - mae: 8.6801\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3809 - mae: 8.3809\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4590 - mae: 8.4590\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4694 - mae: 8.4694\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2789 - mae: 8.2789\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2872 - mae: 8.2872\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4554 - mae: 8.4554\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0967 - mae: 8.0967\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6776 - mae: 8.6776\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9476 - mae: 8.9476\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6458 - mae: 8.6458\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0604 - mae: 8.0604\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5999 - mae: 7.5999\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4470 - mae: 7.4470\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2380 - mae: 7.2380\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1224 - mae: 7.1224\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9931 - mae: 6.9931\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.9326 - mae: 6.9326\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.8507 - mae: 6.8507\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7927 - mae: 6.7927\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7243 - mae: 6.7243\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6938 - mae: 6.6938\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6519 - mae: 6.6519\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6183 - mae: 6.6183\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5524 - mae: 6.5524\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5254 - mae: 6.5254\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5669 - mae: 6.5669\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4626 - mae: 6.4626\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4258 - mae: 6.4258\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4105 - mae: 6.4105\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4163 - mae: 6.4163\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3491 - mae: 6.3491\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.3094 - mae: 6.3094\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2814 - mae: 6.2814\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2280 - mae: 6.2280\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2701 - mae: 6.2701\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1863 - mae: 6.1863\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1588 - mae: 6.1588\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0765 - mae: 6.0765\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1078 - mae: 6.1078\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0696 - mae: 6.0696\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9882 - mae: 5.9882\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0335 - mae: 6.0335\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0579 - mae: 6.0579\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9997 - mae: 5.9997\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8194 - mae: 5.8194\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7751 - mae: 5.7751\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7445 - mae: 5.7445\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7464 - mae: 5.7464\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7255 - mae: 5.7255\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7222 - mae: 5.7222\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7057 - mae: 5.7057\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6963 - mae: 5.6963\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6906 - mae: 5.6906\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6819 - mae: 5.6819\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6676 - mae: 5.6676\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6705 - mae: 5.6705\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6590 - mae: 5.6590\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6549 - mae: 5.6549\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6497 - mae: 5.6497\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6460 - mae: 5.6460\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6343 - mae: 5.6343\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6365 - mae: 5.6365\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6282 - mae: 5.6282\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6195 - mae: 5.6195\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6192 - mae: 5.6192\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6179 - mae: 5.6179\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6112 - mae: 5.6112\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6074 - mae: 5.6074\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6001 - mae: 5.6001\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5990 - mae: 5.5990\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5918 - mae: 5.5918\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5904 - mae: 5.5904\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5800 - mae: 5.5800\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5774 - mae: 5.5774\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5748 - mae: 5.5748\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5733 - mae: 5.5733\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5710 - mae: 5.5710\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5656 - mae: 5.5656\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5667 - mae: 5.5667\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5601 - mae: 5.5601\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5604 - mae: 5.5604\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5523 - mae: 5.5523\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5545 - mae: 5.5545\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5461 - mae: 5.5461\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5462 - mae: 5.5462\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5432 - mae: 5.5432\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5406 - mae: 5.5406\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5353 - mae: 5.5353\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5377 - mae: 5.5377\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5226 - mae: 5.5226\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5335 - mae: 5.5335\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5268 - mae: 5.5268\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5289 - mae: 5.5289\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5117 - mae: 5.5117\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5021 - mae: 5.5021\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4992 - mae: 5.4992\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4966 - mae: 5.4966\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4945 - mae: 5.4945\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4945 - mae: 5.4945\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4936 - mae: 5.4936\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4917 - mae: 5.4917\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4906 - mae: 5.4906\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4900 - mae: 5.4900\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4892 - mae: 5.4892\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4885 - mae: 5.4885\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4883 - mae: 5.4883\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4873 - mae: 5.4873\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4863 - mae: 5.4863\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4863 - mae: 5.4863\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4859 - mae: 5.4859\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4848 - mae: 5.4848\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4856 - mae: 5.4856\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4840 - mae: 5.4840\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4840 - mae: 5.4840\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4828 - mae: 5.4828\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4833 - mae: 5.4833\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4826 - mae: 5.4826\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4826 - mae: 5.4826\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4818 - mae: 5.4818\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4820 - mae: 5.4820\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4814 - mae: 5.4814\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4807 - mae: 5.4807\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4806 - mae: 5.4806\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4802 - mae: 5.4802\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4793 - mae: 5.4793\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4791 - mae: 5.4791\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4792 - mae: 5.4792\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4789 - mae: 5.4789\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4784 - mae: 5.4784\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4777 - mae: 5.4777\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4778 - mae: 5.4778\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4775 - mae: 5.4775\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4773 - mae: 5.4773\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4768 - mae: 5.4768\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4759 - mae: 5.4759\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4770 - mae: 5.4770\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4759 - mae: 5.4759\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4754 - mae: 5.4754\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4749 - mae: 5.4749\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4755 - mae: 5.4755\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4750 - mae: 5.4750\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4743 - mae: 5.4743\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4742 - mae: 5.4742\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4740 - mae: 5.4740\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4733 - mae: 5.4733\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4733 - mae: 5.4733\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4727 - mae: 5.4727\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4729 - mae: 5.4729\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4723 - mae: 5.4723\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4727 - mae: 5.4727\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4719 - mae: 5.4719\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4718 - mae: 5.4718\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4714 - mae: 5.4714\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4702 - mae: 5.4702\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4717 - mae: 5.4717\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4706 - mae: 5.4706\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4703 - mae: 5.4703\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4689 - mae: 5.4689\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4683 - mae: 5.4683\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4679 - mae: 5.4679\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4676 - mae: 5.4676\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4674 - mae: 5.4674\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4673 - mae: 5.4673\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4670 - mae: 5.4670\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4670 - mae: 5.4670\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4669 - mae: 5.4669\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4667 - mae: 5.4667\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4667 - mae: 5.4667\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4666 - mae: 5.4666\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4666 - mae: 5.4666\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4665 - mae: 5.4665\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4664 - mae: 5.4664\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4663 - mae: 5.4663\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4664 - mae: 5.4664\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4662 - mae: 5.4662\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4663 - mae: 5.4663\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4662 - mae: 5.4662\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4662 - mae: 5.4662\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4659 - mae: 5.4659\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4659 - mae: 5.4659\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4659 - mae: 5.4659\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4658 - mae: 5.4658\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8815 - mae: 9.8815\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.0178 - mae: 9.0178\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.5582 - mae: 8.5582\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.3080 - mae: 8.3080\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.2211 - mae: 8.2211\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1440 - mae: 8.1440\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.9566 - mae: 7.9566\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.8746 - mae: 7.8746\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.8858 - mae: 7.8858\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.8085 - mae: 7.8085\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.7449 - mae: 7.7449\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.7879 - mae: 7.7879\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.5925 - mae: 7.5925\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.6103 - mae: 7.6103\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.5590 - mae: 7.5590\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4648 - mae: 7.4648\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.5372 - mae: 7.5372\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3773 - mae: 7.3773\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3154 - mae: 7.3154\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3032 - mae: 7.3032\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1879 - mae: 7.1879\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3713 - mae: 7.3713\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.2335 - mae: 7.2335\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3774 - mae: 7.3774\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5884 - mae: 6.5884\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.3953 - mae: 6.3953\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.3121 - mae: 6.3121\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2988 - mae: 6.2988\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2382 - mae: 6.2382\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1977 - mae: 6.1977\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.1589 - mae: 6.1589\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.1056 - mae: 6.1056\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.0880 - mae: 6.0880\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.0549 - mae: 6.0549\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9875 - mae: 5.9875\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9824 - mae: 5.9824\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9556 - mae: 5.9556\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9266 - mae: 5.9266\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8987 - mae: 5.8987\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8925 - mae: 5.8925\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8543 - mae: 5.8543\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8471 - mae: 5.8471\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8169 - mae: 5.8169\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7989 - mae: 5.7989\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7840 - mae: 5.7840\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7497 - mae: 5.7497\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7377 - mae: 5.7377\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7187 - mae: 5.7187\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7076 - mae: 5.7076\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.6916 - mae: 5.6916\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6530 - mae: 5.6530\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6491 - mae: 5.6491\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6421 - mae: 5.6421\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6447 - mae: 5.6447\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6133 - mae: 5.6133\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5900 - mae: 5.5900\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5585 - mae: 5.5585\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5833 - mae: 5.5833\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5343 - mae: 5.5343\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5402 - mae: 5.5402\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5423 - mae: 5.5423\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5060 - mae: 5.5060\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5004 - mae: 5.5004\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4991 - mae: 5.4991\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5019 - mae: 5.5019\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4539 - mae: 5.4539\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4655 - mae: 5.4655\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4518 - mae: 5.4518\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4297 - mae: 5.4297\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4401 - mae: 5.4401\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4210 - mae: 5.4210\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4134 - mae: 5.4134\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4192 - mae: 5.4192\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3986 - mae: 5.3986\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3818 - mae: 5.3818\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3814 - mae: 5.3814\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3575 - mae: 5.3575\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3450 - mae: 5.3450\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3619 - mae: 5.3619\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3396 - mae: 5.3396\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3287 - mae: 5.3287\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3118 - mae: 5.3118\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3123 - mae: 5.3123\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3028 - mae: 5.3028\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2829 - mae: 5.2829\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2995 - mae: 5.2995\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2664 - mae: 5.2664\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2393 - mae: 5.2393\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2666 - mae: 5.2666\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2465 - mae: 5.2465\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2333 - mae: 5.2333\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2147 - mae: 5.2147\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2197 - mae: 5.2197\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2038 - mae: 5.2038\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1910 - mae: 5.1910\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1832 - mae: 5.1832\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1885 - mae: 5.1885\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1790 - mae: 5.1790\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1930 - mae: 5.1930\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1651 - mae: 5.1651\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1757 - mae: 5.1757\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1524 - mae: 5.1524\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1603 - mae: 5.1603\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1297 - mae: 5.1297\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1211 - mae: 5.1211\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1280 - mae: 5.1280\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1217 - mae: 5.1217\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1129 - mae: 5.1129\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0844 - mae: 5.0844\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0995 - mae: 5.0995\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0858 - mae: 5.0858\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0858 - mae: 5.0858\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9678 - mae: 4.9678\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9249 - mae: 4.9249\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9000 - mae: 4.9000\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8801 - mae: 4.8801\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8775 - mae: 4.8775\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8644 - mae: 4.8644\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8554 - mae: 4.8554\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8464 - mae: 4.8464\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8415 - mae: 4.8415\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8392 - mae: 4.8392\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8353 - mae: 4.8353\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8280 - mae: 4.8280\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8289 - mae: 4.8289\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8203 - mae: 4.8203\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.8165 - mae: 4.8165\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8153 - mae: 4.8153\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8110 - mae: 4.8110\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8088 - mae: 4.8088\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8044 - mae: 4.8044\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8019 - mae: 4.8019\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8017 - mae: 4.8017\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7961 - mae: 4.7961\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7917 - mae: 4.7917\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7922 - mae: 4.7922\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7913 - mae: 4.7913\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7876 - mae: 4.7876\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7871 - mae: 4.7871\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7830 - mae: 4.7830\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7826 - mae: 4.7826\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7807 - mae: 4.7807\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7768 - mae: 4.7768\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7743 - mae: 4.7743\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7749 - mae: 4.7749\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7709 - mae: 4.7709\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7729 - mae: 4.7729\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7687 - mae: 4.7687\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7648 - mae: 4.7648\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7678 - mae: 4.7678\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7624 - mae: 4.7624\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7639 - mae: 4.7639\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7572 - mae: 4.7572\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7579 - mae: 4.7579\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7543 - mae: 4.7543\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7555 - mae: 4.7555\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7519 - mae: 4.7519\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7532 - mae: 4.7532\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7484 - mae: 4.7484\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7471 - mae: 4.7471\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7461 - mae: 4.7461\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7441 - mae: 4.7441\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7461 - mae: 4.7461\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7419 - mae: 4.7419\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7416 - mae: 4.7416\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7372 - mae: 4.7372\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7386 - mae: 4.7386\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7344 - mae: 4.7344\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7355 - mae: 4.7355\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7319 - mae: 4.7319\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7318 - mae: 4.7318\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7293 - mae: 4.7293\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7296 - mae: 4.7296\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7233 - mae: 4.7233\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7251 - mae: 4.7251\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7277 - mae: 4.7277\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7219 - mae: 4.7219\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7215 - mae: 4.7215\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7211 - mae: 4.7211\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7175 - mae: 4.7175\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7137 - mae: 4.7137\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7169 - mae: 4.7169\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7147 - mae: 4.7147\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7140 - mae: 4.7140\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6990 - mae: 4.6990\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6943 - mae: 4.6943\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6919 - mae: 4.6919\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6906 - mae: 4.6906\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6892 - mae: 4.6892\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6878 - mae: 4.6878\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6871 - mae: 4.6871\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6861 - mae: 4.6861\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6856 - mae: 4.6856\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6851 - mae: 4.6851\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6841 - mae: 4.6841\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6840 - mae: 4.6840\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6835 - mae: 4.6835\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6828 - mae: 4.6828\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6826 - mae: 4.6826\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6824 - mae: 4.6824\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.8609 - mae: 9.8609\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.0402 - mae: 9.0402\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.6203 - mae: 8.6203\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5869 - mae: 8.5869\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.5341 - mae: 8.5341\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.6515 - mae: 8.6515\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.4226 - mae: 8.4226\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.6978 - mae: 8.6978\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3478 - mae: 8.3478\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.2686 - mae: 8.2686\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2588 - mae: 8.2588\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1110 - mae: 8.1110\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1596 - mae: 8.1596\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.9356 - mae: 7.9356\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9338 - mae: 7.9338\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1398 - mae: 8.1398\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0540 - mae: 8.0540\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8651 - mae: 7.8651\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1742 - mae: 8.1742\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9744 - mae: 7.9744\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.8715 - mae: 7.8715\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1578 - mae: 7.1578\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.9344 - mae: 6.9344\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.7967 - mae: 6.7967\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.6826 - mae: 6.6826\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.6072 - mae: 6.6072\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5816 - mae: 6.5816\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5213 - mae: 6.5213\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4742 - mae: 6.4742\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4112 - mae: 6.4112\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3576 - mae: 6.3576\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.3249 - mae: 6.3249\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2711 - mae: 6.2711\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.2212 - mae: 6.2212\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2443 - mae: 6.2443\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1948 - mae: 6.1948\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2340 - mae: 6.2340\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1387 - mae: 6.1387\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1248 - mae: 6.1248\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1404 - mae: 6.1404\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1207 - mae: 6.1207\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1014 - mae: 6.1014\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0984 - mae: 6.0984\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0426 - mae: 6.0426\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0722 - mae: 6.0722\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0184 - mae: 6.0184\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0395 - mae: 6.0395\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9971 - mae: 5.9971\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0274 - mae: 6.0274\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9942 - mae: 5.9942\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9700 - mae: 5.9700\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9307 - mae: 5.9307\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9614 - mae: 5.9614\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9155 - mae: 5.9155\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9340 - mae: 5.9340\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8905 - mae: 5.8905\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8927 - mae: 5.8927\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8934 - mae: 5.8934\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9173 - mae: 5.9173\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7941 - mae: 5.7941\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7599 - mae: 5.7599\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7358 - mae: 5.7358\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7162 - mae: 5.7162\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7039 - mae: 5.7039\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6900 - mae: 5.6900\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6837 - mae: 5.6837\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6725 - mae: 5.6725\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6683 - mae: 5.6683\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6635 - mae: 5.6635\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6542 - mae: 5.6542\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6523 - mae: 5.6523\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6445 - mae: 5.6445\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6454 - mae: 5.6454\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6347 - mae: 5.6347\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6349 - mae: 5.6349\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6326 - mae: 5.6326\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6249 - mae: 5.6249\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6291 - mae: 5.6291\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6199 - mae: 5.6199\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6220 - mae: 5.6220\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6184 - mae: 5.6184\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6134 - mae: 5.6134\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6126 - mae: 5.6126\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6070 - mae: 5.6070\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6075 - mae: 5.6075\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6021 - mae: 5.6021\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6028 - mae: 5.6028\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5981 - mae: 5.5981\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5976 - mae: 5.5976\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5948 - mae: 5.5948\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5899 - mae: 5.5899\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5931 - mae: 5.5931\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5876 - mae: 5.5876\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5879 - mae: 5.5879\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5824 - mae: 5.5824\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5816 - mae: 5.5816\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5818 - mae: 5.5818\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5773 - mae: 5.5773\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5749 - mae: 5.5749\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5729 - mae: 5.5729\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5742 - mae: 5.5742\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5705 - mae: 5.5705\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5674 - mae: 5.5674\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5666 - mae: 5.5666\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5631 - mae: 5.5631\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5627 - mae: 5.5627\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5624 - mae: 5.5624\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5597 - mae: 5.5597\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5589 - mae: 5.5589\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5527 - mae: 5.5527\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5550 - mae: 5.5550\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5541 - mae: 5.5541\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5531 - mae: 5.5531\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5359 - mae: 5.5359\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5308 - mae: 5.5308\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5291 - mae: 5.5291\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5261 - mae: 5.5261\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5244 - mae: 5.5244\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5227 - mae: 5.5227\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5222 - mae: 5.5222\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5206 - mae: 5.5206\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5204 - mae: 5.5204\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5194 - mae: 5.5194\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5189 - mae: 5.5189\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5186 - mae: 5.5186\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5178 - mae: 5.5178\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5173 - mae: 5.5173\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5170 - mae: 5.5170\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5167 - mae: 5.5167\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5164 - mae: 5.5164\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5159 - mae: 5.5159\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5154 - mae: 5.5154\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5154 - mae: 5.5154\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5147 - mae: 5.5147\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5145 - mae: 5.5145\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5144 - mae: 5.5144\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5141 - mae: 5.5141\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5135 - mae: 5.5135\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5140 - mae: 5.5140\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5132 - mae: 5.5132\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5133 - mae: 5.5133\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5125 - mae: 5.5125\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5127 - mae: 5.5127\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5128 - mae: 5.5128\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5121 - mae: 5.5121\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5115 - mae: 5.5115\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5124 - mae: 5.5124\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5109 - mae: 5.5109\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5121 - mae: 5.5121\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5109 - mae: 5.5109\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5109 - mae: 5.5109\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5095 - mae: 5.5095\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5090 - mae: 5.5090\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5086 - mae: 5.5086\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5086 - mae: 5.5086\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5083 - mae: 5.5083\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5082 - mae: 5.5082\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5080 - mae: 5.5080\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5080 - mae: 5.5080\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5078 - mae: 5.5078\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5077 - mae: 5.5077\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5078 - mae: 5.5078\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5077 - mae: 5.5077\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5076 - mae: 5.5076\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5076 - mae: 5.5076\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5076 - mae: 5.5076\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5075 - mae: 5.5075\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5075 - mae: 5.5075\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5074 - mae: 5.5074\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5074 - mae: 5.5074\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5073 - mae: 5.5073\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5073 - mae: 5.5073\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00190: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5072 - mae: 5.5072\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.7929 - mae: 9.7929\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.8870 - mae: 8.8870\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7303 - mae: 8.7303\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6215 - mae: 8.6215\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4689 - mae: 8.4689\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2045 - mae: 8.2045\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3128 - mae: 8.3128\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.0108 - mae: 8.0108\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1962 - mae: 8.1962\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1058 - mae: 8.1058\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.9358 - mae: 7.9358\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9537 - mae: 7.9537\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8492 - mae: 7.8492\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1000 - mae: 8.1000\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1973 - mae: 8.1973\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1912 - mae: 8.1912\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5958 - mae: 7.5958\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2657 - mae: 7.2657\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0540 - mae: 7.0540\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9304 - mae: 6.9304\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.8535 - mae: 6.8535\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7741 - mae: 6.7741\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7717 - mae: 6.7717\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7272 - mae: 6.7272\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6515 - mae: 6.6515\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6045 - mae: 6.6045\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5521 - mae: 6.5521\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5299 - mae: 6.5299\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4749 - mae: 6.4749\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4566 - mae: 6.4566\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4174 - mae: 6.4174\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3895 - mae: 6.3895\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3488 - mae: 6.3488\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2683 - mae: 6.2683\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2610 - mae: 6.2610\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1929 - mae: 6.1929\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2194 - mae: 6.2194\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1878 - mae: 6.1878\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0975 - mae: 6.0975\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.1169 - mae: 6.1169\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0341 - mae: 6.0341\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0207 - mae: 6.0207\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9918 - mae: 5.9918\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9631 - mae: 5.9631\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9211 - mae: 5.9211\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8831 - mae: 5.8831\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8331 - mae: 5.8331\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8133 - mae: 5.8133\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7596 - mae: 5.7596\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8812 - mae: 5.8812\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7769 - mae: 5.7769\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7136 - mae: 5.7136\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6559 - mae: 5.6559\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6967 - mae: 5.6967\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7117 - mae: 5.7117\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6533 - mae: 5.6533\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5987 - mae: 5.5987\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5857 - mae: 5.5857\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5605 - mae: 5.5605\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5315 - mae: 5.5315\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5326 - mae: 5.5326\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5023 - mae: 5.5023\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5201 - mae: 5.5201\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4566 - mae: 5.4566\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4628 - mae: 5.4628\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4442 - mae: 5.4442\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4441 - mae: 5.4441\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3865 - mae: 5.3865\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4289 - mae: 5.4289\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4094 - mae: 5.4094\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3485 - mae: 5.3485\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3530 - mae: 5.3530\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3579 - mae: 5.3579\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3064 - mae: 5.3064\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2929 - mae: 5.2929\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3205 - mae: 5.3205\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2850 - mae: 5.2850\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2628 - mae: 5.2628\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2697 - mae: 5.2697\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2612 - mae: 5.2612\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2536 - mae: 5.2536\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2457 - mae: 5.2457\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1479 - mae: 5.1479\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2267 - mae: 5.2267\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1821 - mae: 5.1821\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1875 - mae: 5.1875\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0004 - mae: 5.0004\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9383 - mae: 4.9383\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8994 - mae: 4.8994\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8742 - mae: 4.8742\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8457 - mae: 4.8457\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8240 - mae: 4.8240\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8119 - mae: 4.8119\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7960 - mae: 4.7960\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7776 - mae: 4.7776\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7747 - mae: 4.7747\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7644 - mae: 4.7644\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7530 - mae: 4.7530\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7406 - mae: 4.7406\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7347 - mae: 4.7347\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7231 - mae: 4.7231\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7131 - mae: 4.7131\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7095 - mae: 4.7095\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7037 - mae: 4.7037\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7070 - mae: 4.7070\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6961 - mae: 4.6961\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6964 - mae: 4.6964\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6900 - mae: 4.6900\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6821 - mae: 4.6821\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6812 - mae: 4.6812\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6762 - mae: 4.6762\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6754 - mae: 4.6754\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6700 - mae: 4.6700\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6749 - mae: 4.6749\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6705 - mae: 4.6705\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6606 - mae: 4.6606\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6654 - mae: 4.6654\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6558 - mae: 4.6558\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6577 - mae: 4.6577\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6606 - mae: 4.6606\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6570 - mae: 4.6570\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6401 - mae: 4.6401\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6269 - mae: 4.6269\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6209 - mae: 4.6209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6174 - mae: 4.6174\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6138 - mae: 4.6138\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6121 - mae: 4.6121\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6104 - mae: 4.6104\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6088 - mae: 4.6088\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6068 - mae: 4.6068\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6062 - mae: 4.6062\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6049 - mae: 4.6049\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6041 - mae: 4.6041\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6039 - mae: 4.6039\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6034 - mae: 4.6034\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6026 - mae: 4.6026\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6022 - mae: 4.6022\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6018 - mae: 4.6018\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6014 - mae: 4.6014\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6010 - mae: 4.6010\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6005 - mae: 4.6005\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5997 - mae: 4.5997\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5997 - mae: 4.5997\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5988 - mae: 4.5988\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5990 - mae: 4.5990\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5983 - mae: 4.5983\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5984 - mae: 4.5984\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5977 - mae: 4.5977\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5979 - mae: 4.5979\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5971 - mae: 4.5971\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5963 - mae: 4.5963\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5968 - mae: 4.5968\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5963 - mae: 4.5963\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5962 - mae: 4.5962\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5940 - mae: 4.5940\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5932 - mae: 4.5932\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5927 - mae: 4.5927\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5923 - mae: 4.5923\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5920 - mae: 4.5920\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5918 - mae: 4.5918\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5915 - mae: 4.5915\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5913 - mae: 4.5913\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5912 - mae: 4.5912\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5910 - mae: 4.5910\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5910 - mae: 4.5910\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5909 - mae: 4.5909\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5908 - mae: 4.5908\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5907 - mae: 4.5907\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5907 - mae: 4.5907\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5905 - mae: 4.5905\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5905 - mae: 4.5905\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5905 - mae: 4.5905\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5904 - mae: 4.5904\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5902 - mae: 4.5902\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5901 - mae: 4.5901\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5901 - mae: 4.5901\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5899 - mae: 4.5899\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 10.1755 - mae: 10.1755\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3109 - mae: 9.3109\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9137 - mae: 8.9137\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7509 - mae: 8.7509\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6350 - mae: 8.6350\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2752 - mae: 8.2752\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3549 - mae: 8.3549\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3480 - mae: 8.3480\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2653 - mae: 8.2653\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 8.1713 - mae: 8.1713\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1760 - mae: 8.1760\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7252 - mae: 8.7252\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9991 - mae: 7.9991\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0168 - mae: 8.0168\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9682 - mae: 7.9682\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9037 - mae: 7.9037\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9890 - mae: 7.9890\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0866 - mae: 8.0866\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3571 - mae: 8.3571\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3515 - mae: 7.3515\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0971 - mae: 7.0971\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9715 - mae: 6.9715\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8722 - mae: 6.8722\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7933 - mae: 6.7933\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7024 - mae: 6.7024\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6268 - mae: 6.6268\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5560 - mae: 6.5560\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5002 - mae: 6.5002\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4297 - mae: 6.4297\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3807 - mae: 6.3807\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3675 - mae: 6.3675\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3765 - mae: 6.3765\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2991 - mae: 6.2991\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3235 - mae: 6.3235\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2708 - mae: 6.2708\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2795 - mae: 6.2795\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2191 - mae: 6.2191\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1499 - mae: 6.1499\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1062 - mae: 6.1062\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1651 - mae: 6.1651\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1056 - mae: 6.1056\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1069 - mae: 6.1069\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0483 - mae: 6.0483\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0809 - mae: 6.0809\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9918 - mae: 5.9918\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9930 - mae: 5.9930\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9266 - mae: 5.9266\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9188 - mae: 5.9188\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8868 - mae: 5.8868\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9323 - mae: 5.9323\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9238 - mae: 5.9238\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8869 - mae: 5.8869\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7405 - mae: 5.7405\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6780 - mae: 5.6780\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6413 - mae: 5.6413\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6214 - mae: 5.6214\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5896 - mae: 5.5896\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5828 - mae: 5.5828\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5568 - mae: 5.5568\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5501 - mae: 5.5501\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5303 - mae: 5.5303\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5313 - mae: 5.5313\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5152 - mae: 5.5152\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5132 - mae: 5.5132\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5050 - mae: 5.5050\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5019 - mae: 5.5019\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4919 - mae: 5.4919\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4880 - mae: 5.4880\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4802 - mae: 5.4802\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4852 - mae: 5.4852\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4717 - mae: 5.4717\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4767 - mae: 5.4767\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4711 - mae: 5.4711\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4577 - mae: 5.4577\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4688 - mae: 5.4688\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4532 - mae: 5.4532\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4575 - mae: 5.4575\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4461 - mae: 5.4461\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4525 - mae: 5.4525\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4428 - mae: 5.4428\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4418 - mae: 5.4418\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4483 - mae: 5.4483\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4276 - mae: 5.4276\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4315 - mae: 5.4315\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4350 - mae: 5.4350\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4216 - mae: 5.4216\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4252 - mae: 5.4252\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4218 - mae: 5.4218\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4206 - mae: 5.4206\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4202 - mae: 5.4202\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4172 - mae: 5.4172\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4123 - mae: 5.4123\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4119 - mae: 5.4119\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4097 - mae: 5.4097\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4055 - mae: 5.4055\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4070 - mae: 5.4070\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3929 - mae: 5.3929\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4006 - mae: 5.4006\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3954 - mae: 5.3954\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3921 - mae: 5.3921\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3918 - mae: 5.3918\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3931 - mae: 5.3931\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3876 - mae: 5.3876\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3830 - mae: 5.3830\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3851 - mae: 5.3851\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3801 - mae: 5.3801\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3729 - mae: 5.3729\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3761 - mae: 5.3761\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3706 - mae: 5.3706\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3785 - mae: 5.3785\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3622 - mae: 5.3622\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3729 - mae: 5.3729\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3573 - mae: 5.3573\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3618 - mae: 5.3618\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3595 - mae: 5.3595\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3559 - mae: 5.3559\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3591 - mae: 5.3591\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3544 - mae: 5.3544\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3567 - mae: 5.3567\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3501 - mae: 5.3501\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3500 - mae: 5.3500\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3488 - mae: 5.3488\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3464 - mae: 5.3464\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3414 - mae: 5.3414\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3357 - mae: 5.3357\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3325 - mae: 5.3325\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3443 - mae: 5.3443\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3359 - mae: 5.3359\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3344 - mae: 5.3344\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3187 - mae: 5.3187\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3107 - mae: 5.3107\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3071 - mae: 5.3071\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3037 - mae: 5.3037\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3006 - mae: 5.3006\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2988 - mae: 5.2988\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2972 - mae: 5.2972\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2959 - mae: 5.2959\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2950 - mae: 5.2950\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2936 - mae: 5.2936\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2927 - mae: 5.2927\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2919 - mae: 5.2919\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2909 - mae: 5.2909\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2903 - mae: 5.2903\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2906 - mae: 5.2906\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2899 - mae: 5.2899\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2898 - mae: 5.2898\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2890 - mae: 5.2890\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2883 - mae: 5.2883\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2882 - mae: 5.2882\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2884 - mae: 5.2884\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2872 - mae: 5.2872\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2866 - mae: 5.2866\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2871 - mae: 5.2871\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2871 - mae: 5.2871\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2862 - mae: 5.2862\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2868 - mae: 5.2868\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2856 - mae: 5.2856\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2854 - mae: 5.2854\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2860 - mae: 5.2860\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2851 - mae: 5.2851\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2855 - mae: 5.2855\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2846 - mae: 5.2846\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2851 - mae: 5.2851\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2846 - mae: 5.2846\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2840 - mae: 5.2840\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2840 - mae: 5.2840\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2842 - mae: 5.2842\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2835 - mae: 5.2835\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2839 - mae: 5.2839\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2828 - mae: 5.2828\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2836 - mae: 5.2836\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2826 - mae: 5.2826\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2829 - mae: 5.2829\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2826 - mae: 5.2826\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2825 - mae: 5.2825\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2804 - mae: 5.2804\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2799 - mae: 5.2799\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2794 - mae: 5.2794\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2792 - mae: 5.2792\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2789 - mae: 5.2789\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2787 - mae: 5.2787\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2785 - mae: 5.2785\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2783 - mae: 5.2783\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2782 - mae: 5.2782\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2781 - mae: 5.2781\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2780 - mae: 5.2780\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2778 - mae: 5.2778\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2779 - mae: 5.2779\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2778 - mae: 5.2778\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2777 - mae: 5.2777\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2777 - mae: 5.2777\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2778 - mae: 5.2778\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2777 - mae: 5.2777\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2775 - mae: 5.2775\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2774 - mae: 5.2774\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2773 - mae: 5.2773\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2773 - mae: 5.2773\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2773 - mae: 5.2773\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2773 - mae: 5.2773\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 10.0798 - mae: 10.0798\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.2247 - mae: 9.2247\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7593 - mae: 8.7593\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5965 - mae: 8.5965\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5630 - mae: 8.5630\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2893 - mae: 8.2893\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3187 - mae: 8.3187\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1006 - mae: 8.1006\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0795 - mae: 8.0795\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0275 - mae: 8.0275\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1810 - mae: 8.1810\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8595 - mae: 7.8595\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7853 - mae: 7.7853\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0255 - mae: 8.0255\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8515 - mae: 7.8515\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7259 - mae: 7.7259\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.4966 - mae: 7.4966\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4258 - mae: 7.4258\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6487 - mae: 7.6487\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8210 - mae: 7.8210\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4283 - mae: 7.4283\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8902 - mae: 6.8902\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7262 - mae: 6.7262\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6199 - mae: 6.6199\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5494 - mae: 6.5494\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5143 - mae: 6.5143\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4604 - mae: 6.4604\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4138 - mae: 6.4138\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3796 - mae: 6.3796\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3446 - mae: 6.3446\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2908 - mae: 6.2908\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2889 - mae: 6.2889\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2354 - mae: 6.2354\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2269 - mae: 6.2269\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1613 - mae: 6.1613\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.1675 - mae: 6.1675\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1442 - mae: 6.1442\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0969 - mae: 6.0969\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0749 - mae: 6.0749\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0792 - mae: 6.0792\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0761 - mae: 6.0761\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0230 - mae: 6.0230\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9954 - mae: 5.9954\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0042 - mae: 6.0042\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9742 - mae: 5.9742\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9642 - mae: 5.9642\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9330 - mae: 5.9330\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9225 - mae: 5.9225\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9022 - mae: 5.9022\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8773 - mae: 5.8773\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8858 - mae: 5.8858\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8522 - mae: 5.8522\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8312 - mae: 5.8312\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8215 - mae: 5.8215\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8193 - mae: 5.8193\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7866 - mae: 5.7866\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7524 - mae: 5.7524\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7773 - mae: 5.7773\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7391 - mae: 5.7391\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7399 - mae: 5.7399\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7126 - mae: 5.7126\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6941 - mae: 5.6941\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6908 - mae: 5.6908\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6553 - mae: 5.6553\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6418 - mae: 5.6418\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6591 - mae: 5.6591\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6634 - mae: 5.6634\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6371 - mae: 5.6371\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6244 - mae: 5.6244\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6161 - mae: 5.6161\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6165 - mae: 5.6165\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5841 - mae: 5.5841\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5848 - mae: 5.5848\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5779 - mae: 5.5779\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5678 - mae: 5.5678\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5508 - mae: 5.5508\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5717 - mae: 5.5717\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5515 - mae: 5.5515\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5248 - mae: 5.5248\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5589 - mae: 5.5589\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4919 - mae: 5.4919\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5175 - mae: 5.5175\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4897 - mae: 5.4897\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4918 - mae: 5.4918\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4917 - mae: 5.4917\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4725 - mae: 5.4725\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4399 - mae: 5.4399\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4440 - mae: 5.4440\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4632 - mae: 5.4632\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4547 - mae: 5.4547\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3519 - mae: 5.3519\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3093 - mae: 5.3093\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.2818 - mae: 5.2818\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2733 - mae: 5.2733\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2554 - mae: 5.2554\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2504 - mae: 5.2504\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2404 - mae: 5.2404\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2349 - mae: 5.2349\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2279 - mae: 5.2279\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2207 - mae: 5.2207\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2159 - mae: 5.2159\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2111 - mae: 5.2111\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2061 - mae: 5.2061\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2008 - mae: 5.2008\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2001 - mae: 5.2001\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1980 - mae: 5.1980\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1932 - mae: 5.1932\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1899 - mae: 5.1899\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1870 - mae: 5.1870\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1872 - mae: 5.1872\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1862 - mae: 5.1862\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1822 - mae: 5.1822\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1796 - mae: 5.1796\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1784 - mae: 5.1784\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1782 - mae: 5.1782\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1744 - mae: 5.1744\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1731 - mae: 5.1731\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1715 - mae: 5.1715\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1700 - mae: 5.1700\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1720 - mae: 5.1720\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1665 - mae: 5.1665\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1681 - mae: 5.1681\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1674 - mae: 5.1674\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1622 - mae: 5.1622\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1602 - mae: 5.1602\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1584 - mae: 5.1584\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1583 - mae: 5.1583\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1568 - mae: 5.1568\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1536 - mae: 5.1536\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1540 - mae: 5.1540\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1501 - mae: 5.1501\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1527 - mae: 5.1527\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1498 - mae: 5.1498\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1486 - mae: 5.1486\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1476 - mae: 5.1476\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1447 - mae: 5.1447\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1457 - mae: 5.1457\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1432 - mae: 5.1432\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1430 - mae: 5.1430\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1412 - mae: 5.1412\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1413 - mae: 5.1413\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1400 - mae: 5.1400\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1394 - mae: 5.1394\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1370 - mae: 5.1370\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1377 - mae: 5.1377\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1360 - mae: 5.1360\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1345 - mae: 5.1345\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1328 - mae: 5.1328\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1326 - mae: 5.1326\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1354 - mae: 5.1354\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1293 - mae: 5.1293\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1306 - mae: 5.1306\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1278 - mae: 5.1278\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1298 - mae: 5.1298\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1267 - mae: 5.1267\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1262 - mae: 5.1262\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1211 - mae: 5.1211\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1255 - mae: 5.1255\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1208 - mae: 5.1208\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1258 - mae: 5.1258\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1222 - mae: 5.1222\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1197 - mae: 5.1197\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1196 - mae: 5.1196\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1182 - mae: 5.1182\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1188 - mae: 5.1188\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1145 - mae: 5.1145\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1178 - mae: 5.1178\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1138 - mae: 5.1138\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1137 - mae: 5.1137\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1117 - mae: 5.1117\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1140 - mae: 5.1140\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1122 - mae: 5.1122\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1110 - mae: 5.1110\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1086 - mae: 5.1086\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1069 - mae: 5.1069\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1088 - mae: 5.1088\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1078 - mae: 5.1078\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1057 - mae: 5.1057\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1038 - mae: 5.1038\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1040 - mae: 5.1040\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1021 - mae: 5.1021\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1025 - mae: 5.1025\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1022 - mae: 5.1022\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1037 - mae: 5.1037\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0927 - mae: 5.0927\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0852 - mae: 5.0852\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0819 - mae: 5.0819\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0797 - mae: 5.0797\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0784 - mae: 5.0784\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0770 - mae: 5.0770\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0767 - mae: 5.0767\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0756 - mae: 5.0756\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0753 - mae: 5.0753\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0747 - mae: 5.0747\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0740 - mae: 5.0740\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0739 - mae: 5.0739\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0734 - mae: 5.0734\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0733 - mae: 5.0733\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0724 - mae: 5.0724\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4648 - mae: 12.4648\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4405 - mae: 12.4405\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4407 - mae: 12.4407\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4397 - mae: 12.4397\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4410 - mae: 12.4410\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4398 - mae: 12.4398\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4404 - mae: 12.4404\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4366 - mae: 12.4366\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4360 - mae: 12.4360\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4359 - mae: 12.4359\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4359 - mae: 12.4359\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4358 - mae: 12.4358\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4359 - mae: 12.4359\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4359 - mae: 12.4359\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4357 - mae: 12.4357\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-21.\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-22.\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-23.\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 9.999999682655227e-24.\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 9.999999998199588e-25.\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000000195414814e-25.\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000000195414814e-26.\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 9.999999887266024e-28.\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000000272452012e-28.\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000000031710769e-29.\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000000031710769e-30.\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000003171077e-31.\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.999999796611899e-33.\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 9.999999502738312e-34.\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.999999319067318e-35.\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 9.999999319067319e-36.\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 9.999999462560281e-37.\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 9.99999946256028e-38.\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 9.99999991097579e-39.\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 9.999999350456405e-40.\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 12.4355 - mae: 12.4355\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.4337 - mae: 9.4337\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4882 - mae: 8.4882\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4063 - mae: 8.4063\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0407 - mae: 8.0407\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0784 - mae: 8.0784\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9308 - mae: 7.9308\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8989 - mae: 7.8989\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7825 - mae: 7.7825\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7358 - mae: 7.7358\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5731 - mae: 7.5731\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6160 - mae: 7.6160\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5436 - mae: 7.5436\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4034 - mae: 7.4034\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3991 - mae: 7.3991\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 7.3734 - mae: 7.3734\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3239 - mae: 7.3239\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2799 - mae: 7.2799\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2948 - mae: 7.2948\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1136 - mae: 7.1136\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1858 - mae: 7.1858\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1886 - mae: 7.1886\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0310 - mae: 7.0310\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2155 - mae: 7.2155\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0332 - mae: 7.0332\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1108 - mae: 7.1108\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4598 - mae: 6.4598\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2791 - mae: 6.2791\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2003 - mae: 6.2003\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1482 - mae: 6.1482\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1017 - mae: 6.1017\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0476 - mae: 6.0476\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0088 - mae: 6.0088\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9661 - mae: 5.9661\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9302 - mae: 5.9302\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9079 - mae: 5.9079\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8880 - mae: 5.8880\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8410 - mae: 5.8410\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8134 - mae: 5.8134\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7861 - mae: 5.7861\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7695 - mae: 5.7695\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7459 - mae: 5.7459\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7200 - mae: 5.7200\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7214 - mae: 5.7214\n",
      "Epoch 44/200\n",
      "1224/1548 [======================>.......] - ETA: 1s - loss: 5.5797 - mae: 5.5797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0880 - mae: 5.0880\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0627 - mae: 5.0627\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0694 - mae: 5.0694\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0284 - mae: 5.0284\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0496 - mae: 5.0496\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0597 - mae: 5.0597\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.0103 - mae: 5.0103\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0149 - mae: 5.0149\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0184 - mae: 5.0184\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0129 - mae: 5.0129\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8777 - mae: 4.8777\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8336 - mae: 4.8336\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8139 - mae: 4.8139\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7998 - mae: 4.7998\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7912 - mae: 4.7912\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7826 - mae: 4.7826\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.7772 - mae: 4.7772\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7704 - mae: 4.7704\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7668 - mae: 4.7668\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7602 - mae: 4.7602\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7546 - mae: 4.7546\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7518 - mae: 4.7518\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7464 - mae: 4.7464\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7435 - mae: 4.7435\n",
      "Epoch 117/200\n",
      " 606/1548 [==========>...................] - ETA: 3s - loss: 4.7317 - mae: 4.7317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6448 - mae: 4.6448\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6442 - mae: 4.6442\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6434 - mae: 4.6434\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6432 - mae: 4.6432\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6435 - mae: 4.6435\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6423 - mae: 4.6423\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6422 - mae: 4.6422\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6419 - mae: 4.6419\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6418 - mae: 4.6418\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6413 - mae: 4.6413\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6410 - mae: 4.6410\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6408 - mae: 4.6408\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6403 - mae: 4.6403\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6403 - mae: 4.6403\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6399 - mae: 4.6399\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6398 - mae: 4.6398\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6394 - mae: 4.6394\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6397 - mae: 4.6397\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6389 - mae: 4.6389\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6390 - mae: 4.6390\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6388 - mae: 4.6388\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6387 - mae: 4.6387\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6384 - mae: 4.6384\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6383 - mae: 4.6383\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6380 - mae: 4.6380\n",
      "Epoch 190/200\n",
      " 289/1548 [====>.........................] - ETA: 4s - loss: 4.4899 - mae: 4.4899"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7351 - mae: 6.7351\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7964 - mae: 6.7964\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6585 - mae: 6.6585\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6295 - mae: 6.6295\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.6820 - mae: 6.6820\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.7223 - mae: 6.7223\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.5380 - mae: 6.5380\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.5593 - mae: 6.5593\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.5358 - mae: 6.5358\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4285 - mae: 6.4285\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4660 - mae: 6.4660\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.5208 - mae: 6.5208\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4248 - mae: 6.4248\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.6077 - mae: 6.6077\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4398 - mae: 6.4398\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 6.4323 - mae: 6.4323\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.9367 - mae: 5.9367\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7325 - mae: 5.7325\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6097 - mae: 5.6097\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.5324 - mae: 5.5324\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4648 - mae: 5.4648\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4571 - mae: 5.4571\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4014 - mae: 5.4014\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.3680 - mae: 5.3680\n",
      "Epoch 62/200\n",
      " 532/1548 [=========>....................] - ETA: 4s - loss: 5.4856 - mae: 5.4856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1387 - mae: 6.1387\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0877 - mae: 6.0877\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0785 - mae: 6.0785\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0357 - mae: 6.0357\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0325 - mae: 6.0325\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9897 - mae: 5.9897\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9609 - mae: 5.9609\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9205 - mae: 5.9205\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9193 - mae: 5.9193\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9002 - mae: 5.9002\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8541 - mae: 5.8541\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8553 - mae: 5.8553\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8643 - mae: 5.8643\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8229 - mae: 5.8229\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.7861 - mae: 5.7861\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7465 - mae: 5.7465\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7274 - mae: 5.7274\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7144 - mae: 5.7144\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6779 - mae: 5.6779\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6786 - mae: 5.6786\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6475 - mae: 5.6475\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6443 - mae: 5.6443\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5832 - mae: 5.5832\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5639 - mae: 5.5639\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5787 - mae: 5.5787\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5423 - mae: 5.5423\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5428 - mae: 5.5428\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5043 - mae: 5.5043\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4450 - mae: 5.4450\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5333 - mae: 5.5333\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4497 - mae: 5.4497\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4186 - mae: 5.4186\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4266 - mae: 5.4266\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4572 - mae: 5.4572\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3887 - mae: 5.3887\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4109 - mae: 5.4109\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3719 - mae: 5.3719\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3357 - mae: 5.3357\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3138 - mae: 5.3138\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3725 - mae: 5.3725\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2914 - mae: 5.2914\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3193 - mae: 5.3193\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2795 - mae: 5.2795\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2725 - mae: 5.2725\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2564 - mae: 5.2564\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2152 - mae: 5.2152\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2056 - mae: 5.2056\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2046 - mae: 5.2046\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2181 - mae: 5.2181\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1764 - mae: 5.1764\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2099 - mae: 5.2099\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1499 - mae: 5.1499\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1196 - mae: 5.1196\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.1663 - mae: 5.1663\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1308 - mae: 5.1308\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0838 - mae: 5.0838\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1123 - mae: 5.1123\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0459 - mae: 5.0459\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0767 - mae: 5.0767\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0718 - mae: 5.0718\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0219 - mae: 5.0219\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0382 - mae: 5.0382\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0294 - mae: 5.0294\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0369 - mae: 5.0369\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8847 - mae: 4.8847\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7935 - mae: 4.7935\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7516 - mae: 4.7516\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7090 - mae: 4.7090\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6999 - mae: 4.6999\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6806 - mae: 4.6806\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6739 - mae: 4.6739\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6620 - mae: 4.6620\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.6490 - mae: 4.6490\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6370 - mae: 4.6370\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6315 - mae: 4.6315\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6248 - mae: 4.6248\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6173 - mae: 4.6173\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6121 - mae: 4.6121\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6016 - mae: 4.6016\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5953 - mae: 4.5953\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6001 - mae: 4.6001\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5900 - mae: 4.5900\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5795 - mae: 4.5795\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5835 - mae: 4.5835\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5796 - mae: 4.5796\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5704 - mae: 4.5704\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5710 - mae: 4.5710\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5646 - mae: 4.5646\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5602 - mae: 4.5602\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5626 - mae: 4.5626\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5549 - mae: 4.5549\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.5536 - mae: 4.5536\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5493 - mae: 4.5493\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5490 - mae: 4.5490\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5442 - mae: 4.5442\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5455 - mae: 4.5455\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5359 - mae: 4.5359\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5429 - mae: 4.5429\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5360 - mae: 4.5360\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5329 - mae: 4.5329\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5315 - mae: 4.5315\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5280 - mae: 4.5280\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5298 - mae: 4.5298\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5280 - mae: 4.5280\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5217 - mae: 4.5217\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5217 - mae: 4.5217\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5244 - mae: 4.5244\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5158 - mae: 4.5158\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5150 - mae: 4.5150\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5144 - mae: 4.5144\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5101 - mae: 4.5101\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5081 - mae: 4.5081\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5078 - mae: 4.5078\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5073 - mae: 4.5073\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5063 - mae: 4.5063\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5021 - mae: 4.5021\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4984 - mae: 4.4984\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4982 - mae: 4.4982\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4940 - mae: 4.4940\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4943 - mae: 4.4943\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4956 - mae: 4.4956\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4918 - mae: 4.4918\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4862 - mae: 4.4862\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4847 - mae: 4.4847\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4869 - mae: 4.4869\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4843 - mae: 4.4843\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4819 - mae: 4.4819\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4778 - mae: 4.4778\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4749 - mae: 4.4749\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4751 - mae: 4.4751\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4696 - mae: 4.4696\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4741 - mae: 4.4741\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4700 - mae: 4.4700\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4666 - mae: 4.4666\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4659 - mae: 4.4659\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4643 - mae: 4.4643\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4583 - mae: 4.4583\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4595 - mae: 4.4595\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4562 - mae: 4.4562\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4611 - mae: 4.4611\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4510 - mae: 4.4510\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4536 - mae: 4.4536\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4519 - mae: 4.4519\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4465 - mae: 4.4465\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4450 - mae: 4.4450\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4440 - mae: 4.4440\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4471 - mae: 4.4471\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4375 - mae: 4.4375\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4378 - mae: 4.4378\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4406 - mae: 4.4406\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4338 - mae: 4.4338\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4348 - mae: 4.4348\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4323 - mae: 4.4323\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4369 - mae: 4.4369\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4284 - mae: 4.4284\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4288 - mae: 4.4288\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4288 - mae: 4.4288\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4245 - mae: 4.4245\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4268 - mae: 4.4268\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4202 - mae: 4.4202\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4220 - mae: 4.4220\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4212 - mae: 4.4212\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4192 - mae: 4.4192\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4187 - mae: 4.4187\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4186 - mae: 4.4186\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4179 - mae: 4.4179\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4170 - mae: 4.4170\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 4.4100 - mae: 4.4100\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4155 - mae: 4.4155\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4098 - mae: 4.4098\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 9.6832 - mae: 9.6832\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6247 - mae: 8.6247\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2034 - mae: 8.2034\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0756 - mae: 8.0756\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0550 - mae: 8.0550\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9379 - mae: 7.9379\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9565 - mae: 7.9565\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9735 - mae: 7.9735\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6549 - mae: 7.6549\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7537 - mae: 7.7537\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6191 - mae: 7.6191\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5797 - mae: 7.5797\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4999 - mae: 7.4999\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3704 - mae: 7.3704\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3174 - mae: 7.3174\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2966 - mae: 7.2966\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2537 - mae: 7.2537\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3249 - mae: 7.3249\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1416 - mae: 7.1416\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1779 - mae: 7.1779\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1189 - mae: 7.1189\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1203 - mae: 7.1203\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9687 - mae: 6.9687\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0712 - mae: 7.0712\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0020 - mae: 7.0020\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0726 - mae: 7.0726\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4008 - mae: 6.4008\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2309 - mae: 6.2309\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1129 - mae: 6.1129\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0515 - mae: 6.0515\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9838 - mae: 5.9838\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9382 - mae: 5.9382\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8986 - mae: 5.8986\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.8511 - mae: 5.8511\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8053 - mae: 5.8053\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7843 - mae: 5.7843\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7600 - mae: 5.7600\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7129 - mae: 5.7129\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7021 - mae: 5.7021\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6744 - mae: 5.6744\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6393 - mae: 5.6393\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6262 - mae: 5.6262\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6028 - mae: 5.6028\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5666 - mae: 5.5666\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5537 - mae: 5.5537\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5412 - mae: 5.5412\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5030 - mae: 5.5030\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5004 - mae: 5.5004\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4785 - mae: 5.4785\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4598 - mae: 5.4598\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4433 - mae: 5.4433\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4289 - mae: 5.4289\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 7s 4ms/step - loss: 5.4083 - mae: 5.4083\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3941 - mae: 5.3941\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3935 - mae: 5.3935\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3687 - mae: 5.3687\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3485 - mae: 5.3485\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3326 - mae: 5.3326\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3324 - mae: 5.3324\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3291 - mae: 5.3291\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2871 - mae: 5.2871\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3179 - mae: 5.3179\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2828 - mae: 5.2828\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2650 - mae: 5.2650\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2528 - mae: 5.2528\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2462 - mae: 5.2462\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2339 - mae: 5.2339\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2207 - mae: 5.2207\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2091 - mae: 5.2091\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1948 - mae: 5.1948\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1897 - mae: 5.1897\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1772 - mae: 5.1772\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1701 - mae: 5.1701\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1545 - mae: 5.1545\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1313 - mae: 5.1313\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1412 - mae: 5.1412\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1207 - mae: 5.1207\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1363 - mae: 5.1363\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1050 - mae: 5.1050\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0866 - mae: 5.0866\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0842 - mae: 5.0842\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0789 - mae: 5.0789\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0631 - mae: 5.0631\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0649 - mae: 5.0649\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0407 - mae: 5.0407\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0380 - mae: 5.0380\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0324 - mae: 5.0324\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0418 - mae: 5.0418\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0321 - mae: 5.0321\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9868 - mae: 4.9868\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9906 - mae: 4.9906\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0145 - mae: 5.0145\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9852 - mae: 4.9852\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9854 - mae: 4.9854\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9739 - mae: 4.9739\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9759 - mae: 4.9759\n",
      "Epoch 98/200\n",
      " 703/1548 [============>.................] - ETA: 3s - loss: 4.9021 - mae: 4.9021"
     ]
    }
   ],
   "source": [
    "# Construct neural network model\n",
    "# Record MAE\n",
    "MAE = np.zeros([kf*10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    for initial_num in range(10,210,20):\n",
    "        # Define Sequential model with 4 hidden layers\n",
    "        model_one_layers = keras.Sequential([\n",
    "            layers.Dense(77, activation = \"relu\", name = \"input\", input_dim = 77),\n",
    "            layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "            layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "            layers.Dense(10, activation = \"relu\", name = \"layer3\"),\n",
    "            layers.Dense(initial_num, activation = \"relu\", name = \"layer4\"),\n",
    "            layers.Dense(1, name = \"output\")])\n",
    "        # ReduceLROnPlateau\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                    factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                    patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                    verbose = 1)\n",
    "        # Optimizer for Adam\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "        # Train the model\n",
    "        history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "        # Prediction\n",
    "        test_predictions = model_one_layers.predict(test_X)\n",
    "        # MAE\n",
    "        model_error = abs((test_predictions.ravel() - test_Y))\n",
    "        MAE[i] = model_error.mean()\n",
    "        i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_forth_layer.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b93fb6",
   "metadata": {},
   "source": [
    "## The 10-fold CV MAE of the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f8b31d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAE_first = pd.read_csv(\"MAE_first_layer.csv\")\n",
    "MAE_first_result = pd.DataFrame(np.mat(np.array(MAE_first).reshape(10,10)))\n",
    "MAE_second = pd.read_csv(\"MAE_second_layer.csv\")\n",
    "MAE_second_result = pd.DataFrame(np.mat(np.array(MAE_second).reshape(10,10)))\n",
    "MAE_third = pd.read_csv(\"MAE_third_layer.csv\")\n",
    "MAE_third_result = pd.DataFrame(np.mat(np.array(MAE_third).reshape(10,10)))\n",
    "MAE_forth = pd.read_csv(\"MAE_forth_layer.csv\")\n",
    "MAE_forth_result = pd.DataFrame(np.mat(np.array(MAE_forth).reshape(10,10)))\n",
    "plt.plot(range(10,210,20), MAE_first_result.mean(),  c = 'r', lw = '2', ls = '--', marker = 'o', ms = 5, label = 'First')\n",
    "plt.plot(range(10,210,20), MAE_second_result.mean(), c = 'b', lw = '2', ls = '--', marker = 'o', ms = 5, label = 'Second')\n",
    "plt.plot(range(10,210,20), MAE_third_result.mean(),  c = 'g', lw = '2', ls = '--', marker = 'o', ms = 5, label = 'Third')\n",
    "plt.plot(range(10,210,20), MAE_forth_result.mean(),  c = 'y', lw = '2', ls = '--', marker = 'o', ms = 5, label = 'Forth')\n",
    "plt.legend(loc='center right') # Legend\n",
    "plt.xlabel('The number of Neurons', fontsize = 10)\n",
    "plt.ylabel('Mean Absolute Error', fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d37af",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071122a",
   "metadata": {},
   "source": [
    "The two hidden layers have 150 and 130 neurons respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e9d541fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.6199 - mae: 9.6199\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6091 - mae: 8.6091\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3322 - mae: 8.3322\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1234 - mae: 8.1234\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0133 - mae: 8.0133\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8810 - mae: 7.8810\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8040 - mae: 7.8040\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6959 - mae: 7.6959\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6139 - mae: 7.6139\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5654 - mae: 7.5654\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5007 - mae: 7.5007\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5410 - mae: 7.5410\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4719 - mae: 7.4719\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4105 - mae: 7.4105\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3268 - mae: 7.3268\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2818 - mae: 7.2818\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2807 - mae: 7.2807\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2419 - mae: 7.2419\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1196 - mae: 7.1196\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1490 - mae: 7.1490\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0496 - mae: 7.0496\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0002 - mae: 7.0002\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9438 - mae: 6.9438\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9821 - mae: 6.9821\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9146 - mae: 6.9146\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9907 - mae: 6.9907\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8954 - mae: 6.8954\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7443 - mae: 6.7443\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7506 - mae: 6.7506\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6956 - mae: 6.6956\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6271 - mae: 6.6271\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6419 - mae: 6.6419\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6428 - mae: 6.6428\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5891 - mae: 6.5891\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4364 - mae: 6.4364\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5471 - mae: 6.5471\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4933 - mae: 6.4933\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5050 - mae: 6.5050\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0648 - mae: 6.0648\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8412 - mae: 5.8412\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7505 - mae: 5.7505\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7006 - mae: 5.7006\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6468 - mae: 5.6468\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5882 - mae: 5.5882\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5649 - mae: 5.5649\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5313 - mae: 5.5313\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5074 - mae: 5.5074\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4924 - mae: 5.4924\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4523 - mae: 5.4523\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4474 - mae: 5.4474\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4198 - mae: 5.4198\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4031 - mae: 5.4031\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3797 - mae: 5.3797\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3799 - mae: 5.3799\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3694 - mae: 5.3694\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3467 - mae: 5.3467\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3473 - mae: 5.3473\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3136 - mae: 5.3136\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3138 - mae: 5.3138\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2953 - mae: 5.2953\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2846 - mae: 5.2846\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2746 - mae: 5.2746\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2630 - mae: 5.2630\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2430 - mae: 5.2430\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2481 - mae: 5.2481\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2326 - mae: 5.2326\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2204 - mae: 5.2204\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2133 - mae: 5.2133\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1802 - mae: 5.1802\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1952 - mae: 5.1952\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1822 - mae: 5.1822\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1720 - mae: 5.1720\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1637 - mae: 5.1637\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1517 - mae: 5.1517\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1392 - mae: 5.1392\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1306 - mae: 5.1306\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1131 - mae: 5.1131\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1150 - mae: 5.1150\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1110 - mae: 5.1110\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0948 - mae: 5.0948\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0980 - mae: 5.0980\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0831 - mae: 5.0831\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0745 - mae: 5.0745\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0642 - mae: 5.0642\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0627 - mae: 5.0627\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0362 - mae: 5.0362\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0297 - mae: 5.0297\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0183 - mae: 5.0183\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0121 - mae: 5.0121\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0090 - mae: 5.0090\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9932 - mae: 4.9932\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9921 - mae: 4.9921\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9831 - mae: 4.9831\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9716 - mae: 4.9716\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9837 - mae: 4.9837\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9566 - mae: 4.9566\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9448 - mae: 4.9448\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9387 - mae: 4.9387\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9262 - mae: 4.9262\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8982 - mae: 4.8982\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9296 - mae: 4.9296\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9003 - mae: 4.9003\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9047 - mae: 4.9047\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8064 - mae: 4.8064\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7811 - mae: 4.7811\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7714 - mae: 4.7714\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7585 - mae: 4.7585\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7514 - mae: 4.7514\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7453 - mae: 4.7453\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7393 - mae: 4.7393\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7337 - mae: 4.7337\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7292 - mae: 4.7292\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7269 - mae: 4.7269\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7225 - mae: 4.7225\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7193 - mae: 4.7193\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7155 - mae: 4.7155\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7150 - mae: 4.7150\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7136 - mae: 4.7136\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7105 - mae: 4.7105\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7075 - mae: 4.7075\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7075 - mae: 4.7075\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7066 - mae: 4.7066\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7040 - mae: 4.7040\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7011 - mae: 4.7011\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7011 - mae: 4.7011\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7002 - mae: 4.7002\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6978 - mae: 4.6978\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6952 - mae: 4.6952\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6965 - mae: 4.6965\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6940 - mae: 4.6940\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6895 - mae: 4.6895\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6928 - mae: 4.6928\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6906 - mae: 4.6906\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6876 - mae: 4.6876\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6883 - mae: 4.6883\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6870 - mae: 4.6870\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6847 - mae: 4.6847\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6844 - mae: 4.6844\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6835 - mae: 4.6835\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6814 - mae: 4.6814\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6825 - mae: 4.6825\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6799 - mae: 4.6799\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6777 - mae: 4.6777\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6760 - mae: 4.6760\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6773 - mae: 4.6773\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6758 - mae: 4.6758\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6754 - mae: 4.6754\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6712 - mae: 4.6712\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6705 - mae: 4.6705\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6740 - mae: 4.6740\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6722 - mae: 4.6722\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6680 - mae: 4.6680\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6698 - mae: 4.6698\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6665 - mae: 4.6665\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6692 - mae: 4.6692\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6629 - mae: 4.6629\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6660 - mae: 4.6660\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6641 - mae: 4.6641\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6621 - mae: 4.6621\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6632 - mae: 4.6632\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6616 - mae: 4.6616\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6595 - mae: 4.6595\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6580 - mae: 4.6580\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6599 - mae: 4.6599\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6575 - mae: 4.6575\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6568 - mae: 4.6568\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6538 - mae: 4.6538\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6548 - mae: 4.6548\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6526 - mae: 4.6526\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6521 - mae: 4.6521\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6518 - mae: 4.6518\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6486 - mae: 4.6486\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6517 - mae: 4.6517\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6499 - mae: 4.6499\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6492 - mae: 4.6492\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6370 - mae: 4.6370\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6350 - mae: 4.6350\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6337 - mae: 4.6337\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6326 - mae: 4.6326\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6317 - mae: 4.6317\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6313 - mae: 4.6313\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6307 - mae: 4.6307\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6306 - mae: 4.6306\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6300 - mae: 4.6300\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6296 - mae: 4.6296\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6294 - mae: 4.6294\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6294 - mae: 4.6294\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6289 - mae: 4.6289\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6285 - mae: 4.6285\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6288 - mae: 4.6288\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6282 - mae: 4.6282\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6281 - mae: 4.6281\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6278 - mae: 4.6278\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6281 - mae: 4.6281\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6277 - mae: 4.6277\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6274 - mae: 4.6274\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6274 - mae: 4.6274\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3300 - mae: 9.3300\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3884 - mae: 8.3884\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0618 - mae: 8.0618\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9166 - mae: 7.9166\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7835 - mae: 7.7835\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6951 - mae: 7.6951\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5866 - mae: 7.5866\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4970 - mae: 7.4970\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4468 - mae: 7.4468\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4267 - mae: 7.4267\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2917 - mae: 7.2917\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2408 - mae: 7.2408\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2061 - mae: 7.2061\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1331 - mae: 7.1331\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0941 - mae: 7.0941\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0695 - mae: 7.0695\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0210 - mae: 7.0210\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9322 - mae: 6.9322\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9434 - mae: 6.9434\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9331 - mae: 6.9331\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8984 - mae: 6.8984\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7628 - mae: 6.7628\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6714 - mae: 6.6714\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6945 - mae: 6.6945\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5861 - mae: 6.5861\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6031 - mae: 6.6031\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5890 - mae: 6.5890\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5034 - mae: 6.5034\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3899 - mae: 6.3899\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7202 - mae: 6.7202\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4364 - mae: 6.4364\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4934 - mae: 6.4934\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9701 - mae: 5.9701\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7741 - mae: 5.7741\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6790 - mae: 5.6790\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6369 - mae: 5.6369\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5823 - mae: 5.5823\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5413 - mae: 5.5413\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5087 - mae: 5.5087\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4862 - mae: 5.4862\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4439 - mae: 5.4439\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4347 - mae: 5.4347\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4119 - mae: 5.4119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3820 - mae: 5.3820\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3769 - mae: 5.3769\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3560 - mae: 5.3560\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3307 - mae: 5.3307\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3146 - mae: 5.3146\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3003 - mae: 5.3003\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2889 - mae: 5.2889\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2533 - mae: 5.2533\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2441 - mae: 5.2441\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2387 - mae: 5.2387\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2187 - mae: 5.2187\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2181 - mae: 5.2181\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1934 - mae: 5.1934\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1783 - mae: 5.1783\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1575 - mae: 5.1575\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1566 - mae: 5.1566\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1520 - mae: 5.1520\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1053 - mae: 5.1053\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1209 - mae: 5.1209\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1011 - mae: 5.1011\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0880 - mae: 5.0880\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0721 - mae: 5.0721\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0668 - mae: 5.0668\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0457 - mae: 5.0457\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0228 - mae: 5.0228\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0232 - mae: 5.0232\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0183 - mae: 5.0183\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9922 - mae: 4.9922\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0002 - mae: 5.0002\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9820 - mae: 4.9820\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9766 - mae: 4.9766\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9644 - mae: 4.9644\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9660 - mae: 4.9660\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9500 - mae: 4.9500\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9169 - mae: 4.9169\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9275 - mae: 4.9275\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9033 - mae: 4.9033\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9121 - mae: 4.9121\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8869 - mae: 4.8869\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8970 - mae: 4.8970\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8841 - mae: 4.8841\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8830 - mae: 4.8830\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8612 - mae: 4.8612\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8747 - mae: 4.8747\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8422 - mae: 4.8422\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8342 - mae: 4.8342\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8453 - mae: 4.8453\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8225 - mae: 4.8225\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8238 - mae: 4.8238\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8219 - mae: 4.8219\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8017 - mae: 4.8017\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7980 - mae: 4.7980\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8113 - mae: 4.8113\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7790 - mae: 4.7790\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7878 - mae: 4.7878\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7845 - mae: 4.7845\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7566 - mae: 4.7566\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7679 - mae: 4.7679\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7569 - mae: 4.7569\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7552 - mae: 4.7552\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7494 - mae: 4.7494\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7384 - mae: 4.7384\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7308 - mae: 4.7308\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7326 - mae: 4.7326\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7194 - mae: 4.7194\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7325 - mae: 4.7325\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7035 - mae: 4.7035\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7096 - mae: 4.7096\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6946 - mae: 4.6946\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7171 - mae: 4.7171\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6871 - mae: 4.6871\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6876 - mae: 4.6876\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6813 - mae: 4.6813\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6852 - mae: 4.6852\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6511 - mae: 4.6511\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6688 - mae: 4.6688\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6715 - mae: 4.6715\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6612 - mae: 4.6612\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5703 - mae: 4.5703\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5290 - mae: 4.5290\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5101 - mae: 4.5101\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5044 - mae: 4.5044\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4982 - mae: 4.4982\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4885 - mae: 4.4885\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4810 - mae: 4.4810\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4790 - mae: 4.4790\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4773 - mae: 4.4773\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4710 - mae: 4.4710\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4673 - mae: 4.4673\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4674 - mae: 4.4674\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4600 - mae: 4.4600\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4627 - mae: 4.4627\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4559 - mae: 4.4559\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4563 - mae: 4.4563\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4546 - mae: 4.4546\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4507 - mae: 4.4507\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4499 - mae: 4.4499\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4506 - mae: 4.4506\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4474 - mae: 4.4474\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4429 - mae: 4.4429\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4459 - mae: 4.4459\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4418 - mae: 4.4418\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4413 - mae: 4.4413\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4415 - mae: 4.4415\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4412 - mae: 4.4412\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4359 - mae: 4.4359\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4362 - mae: 4.4362\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4350 - mae: 4.4350\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4338 - mae: 4.4338\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4350 - mae: 4.4350\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4320 - mae: 4.4320\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4318 - mae: 4.4318\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4301 - mae: 4.4301\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4305 - mae: 4.4305\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4275 - mae: 4.4275\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4281 - mae: 4.4281\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4267 - mae: 4.4267\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4280 - mae: 4.4280\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4242 - mae: 4.4242\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4229 - mae: 4.4229\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4247 - mae: 4.4247\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4227 - mae: 4.4227\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4206 - mae: 4.4206\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4209 - mae: 4.4209\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4183 - mae: 4.4183\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4210 - mae: 4.4210\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4160 - mae: 4.4160\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4209 - mae: 4.4209\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4161 - mae: 4.4161\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4153 - mae: 4.4153\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4146 - mae: 4.4146\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4163 - mae: 4.4163\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4143 - mae: 4.4143\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4146 - mae: 4.4146\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4119 - mae: 4.4119\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4127 - mae: 4.4127\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4116 - mae: 4.4116\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4104 - mae: 4.4104\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4089 - mae: 4.4089\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4103 - mae: 4.4103\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4068 - mae: 4.4068\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4086 - mae: 4.4086\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4070 - mae: 4.4070\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4056 - mae: 4.4056\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4052 - mae: 4.4052\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4060 - mae: 4.4060\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4048 - mae: 4.4048\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4041 - mae: 4.4041\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4021 - mae: 4.4021\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4025 - mae: 4.4025\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4018 - mae: 4.4018\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4024 - mae: 4.4024\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.3996 - mae: 4.3996\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4011 - mae: 4.4011\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.3986 - mae: 4.3986\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3700 - mae: 9.3700\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6565 - mae: 8.6565\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4425 - mae: 8.4425\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2048 - mae: 8.2048\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0037 - mae: 8.0037\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0032 - mae: 8.0032\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9238 - mae: 7.9238\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7498 - mae: 7.7498\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6713 - mae: 7.6713\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6471 - mae: 7.6471\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4673 - mae: 7.4673\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5639 - mae: 7.5639\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4374 - mae: 7.4374\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4793 - mae: 7.4793\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3805 - mae: 7.3805\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2566 - mae: 7.2566\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3181 - mae: 7.3181\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1586 - mae: 7.1586\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0387 - mae: 7.0387\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1559 - mae: 7.1559\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0872 - mae: 7.0872\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9977 - mae: 6.9977\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0288 - mae: 7.0288\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9540 - mae: 6.9540\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8568 - mae: 6.8568\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9024 - mae: 6.9024\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8587 - mae: 6.8587\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8463 - mae: 6.8463\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8282 - mae: 6.8282\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8092 - mae: 6.8092\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7524 - mae: 6.7524\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7276 - mae: 6.7276\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6191 - mae: 6.6191\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5740 - mae: 6.5740\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6681 - mae: 6.6681\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6076 - mae: 6.6076\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6841 - mae: 6.6841\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0942 - mae: 6.0942\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8877 - mae: 5.8877\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8282 - mae: 5.8282\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7545 - mae: 5.7545\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7147 - mae: 5.7147\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6766 - mae: 5.6766\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6335 - mae: 5.6335\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6272 - mae: 5.6272\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5902 - mae: 5.5902\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5812 - mae: 5.5812\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5354 - mae: 5.5354\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5360 - mae: 5.5360\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5122 - mae: 5.5122\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4895 - mae: 5.4895\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4806 - mae: 5.4806\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4579 - mae: 5.4579\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4471 - mae: 5.4471\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4276 - mae: 5.4276\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4335 - mae: 5.4335\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4128 - mae: 5.4128\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3923 - mae: 5.3923\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3965 - mae: 5.3965\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3633 - mae: 5.3633\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3489 - mae: 5.3489\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3450 - mae: 5.3450\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3468 - mae: 5.3468\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3160 - mae: 5.3160\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3006 - mae: 5.3006\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3054 - mae: 5.3054\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2865 - mae: 5.2865\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2691 - mae: 5.2691\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2789 - mae: 5.2789\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2672 - mae: 5.2672\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2405 - mae: 5.2405\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2508 - mae: 5.2508\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2371 - mae: 5.2371\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2105 - mae: 5.2105\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2164 - mae: 5.2164\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2038 - mae: 5.2038\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2012 - mae: 5.2012\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1882 - mae: 5.1882\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1751 - mae: 5.1751\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1657 - mae: 5.1657\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1628 - mae: 5.1628\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1439 - mae: 5.1439\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1450 - mae: 5.1450\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1487 - mae: 5.1487\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1366 - mae: 5.1366\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1339 - mae: 5.1339\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1308 - mae: 5.1308\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1186 - mae: 5.1186\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1173 - mae: 5.1173\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1084 - mae: 5.1084\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1130 - mae: 5.1130\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0918 - mae: 5.0918\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0999 - mae: 5.0999\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0657 - mae: 5.0657\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0781 - mae: 5.0781\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0739 - mae: 5.0739\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0736 - mae: 5.0736\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9839 - mae: 4.9839\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9524 - mae: 4.9524\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9400 - mae: 4.9400\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9317 - mae: 4.9317\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9259 - mae: 4.9259\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9195 - mae: 4.9195\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9140 - mae: 4.9140\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9126 - mae: 4.9126\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9094 - mae: 4.9094\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9048 - mae: 4.9048\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9049 - mae: 4.9049\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9022 - mae: 4.9022\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8997 - mae: 4.8997\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8993 - mae: 4.8993\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8935 - mae: 4.8935\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8931 - mae: 4.8931\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8927 - mae: 4.8927\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8905 - mae: 4.8905\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8890 - mae: 4.8890\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8876 - mae: 4.8876\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8873 - mae: 4.8873\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8849 - mae: 4.8849\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8835 - mae: 4.8835\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8837 - mae: 4.8837\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8824 - mae: 4.8824\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8807 - mae: 4.8807\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8802 - mae: 4.8802\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8771 - mae: 4.8771\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8798 - mae: 4.8798\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8757 - mae: 4.8757\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8777 - mae: 4.8777\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8762 - mae: 4.8762\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8723 - mae: 4.8723\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8712 - mae: 4.8712\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8747 - mae: 4.8747\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8727 - mae: 4.8727\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8708 - mae: 4.8708\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8697 - mae: 4.8697\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8689 - mae: 4.8689\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8677 - mae: 4.8677\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8659 - mae: 4.8659\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8678 - mae: 4.8678\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8643 - mae: 4.8643\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8652 - mae: 4.8652\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8638 - mae: 4.8638\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8642 - mae: 4.8642\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8597 - mae: 4.8597\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8632 - mae: 4.8632\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8595 - mae: 4.8595\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8600 - mae: 4.8600\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8588 - mae: 4.8588\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8604 - mae: 4.8604\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8564 - mae: 4.8564\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8568 - mae: 4.8568\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8578 - mae: 4.8578\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8548 - mae: 4.8548\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8546 - mae: 4.8546\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8556 - mae: 4.8556\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8536 - mae: 4.8536\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8533 - mae: 4.8533\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8505 - mae: 4.8505\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8517 - mae: 4.8517\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8490 - mae: 4.8490\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8528 - mae: 4.8528\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8497 - mae: 4.8497\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8466 - mae: 4.8466\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8489 - mae: 4.8489\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8460 - mae: 4.8460\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8457 - mae: 4.8457\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8447 - mae: 4.8447\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8459 - mae: 4.8459\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8432 - mae: 4.8432\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8446 - mae: 4.8446\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8447 - mae: 4.8447\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8425 - mae: 4.8425\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8416 - mae: 4.8416\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8407 - mae: 4.8407\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8425 - mae: 4.8425\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8373 - mae: 4.8373\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8418 - mae: 4.8418\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8369 - mae: 4.8369\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8384 - mae: 4.8384\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8362 - mae: 4.8362\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8346 - mae: 4.8346\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8379 - mae: 4.8379\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8346 - mae: 4.8346\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8349 - mae: 4.8349\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8264 - mae: 4.8264\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8240 - mae: 4.8240\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8225 - mae: 4.8225\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8210 - mae: 4.8210\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8199 - mae: 4.8199\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8197 - mae: 4.8197\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8188 - mae: 4.8188\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8183 - mae: 4.8183\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8179 - mae: 4.8179\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8178 - mae: 4.8178\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8172 - mae: 4.8172\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8174 - mae: 4.8174\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8167 - mae: 4.8167\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8163 - mae: 4.8163\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.2665 - mae: 9.2665\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4999 - mae: 8.4999\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2628 - mae: 8.2628\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0718 - mae: 8.0718\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 7.9510 - mae: 7.9510\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9029 - mae: 7.9029\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7169 - mae: 7.7169\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6097 - mae: 7.6097\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6693 - mae: 7.6693\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6330 - mae: 7.6330\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4741 - mae: 7.4741\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4353 - mae: 7.4353\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3964 - mae: 7.3964\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3681 - mae: 7.3681\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2167 - mae: 7.2167\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1638 - mae: 7.1638\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0280 - mae: 7.0280\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1745 - mae: 7.1745\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1181 - mae: 7.1181\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9746 - mae: 6.9746\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8882 - mae: 6.8882\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8398 - mae: 6.8398\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7747 - mae: 6.7747\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8840 - mae: 6.8840\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8338 - mae: 6.8338\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7516 - mae: 6.7516\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6518 - mae: 6.6518\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6664 - mae: 6.6664\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6554 - mae: 6.6554\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5992 - mae: 6.5992\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5694 - mae: 6.5694\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6310 - mae: 6.6310\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6740 - mae: 6.6740\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5351 - mae: 6.5351\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5342 - mae: 6.5342\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4820 - mae: 6.4820\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4603 - mae: 6.4603\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5136 - mae: 6.5136\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3849 - mae: 6.3849\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3225 - mae: 6.3225\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5010 - mae: 6.5010\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3362 - mae: 6.3362\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3190 - mae: 6.3190\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2990 - mae: 6.2990\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3953 - mae: 6.3953\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2928 - mae: 6.2928\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2065 - mae: 6.2065\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2705 - mae: 6.2705\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0516 - mae: 6.0516\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1759 - mae: 6.1759\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1667 - mae: 6.1667\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1732 - mae: 6.1732\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7061 - mae: 5.7061\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4873 - mae: 5.4873\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3840 - mae: 5.3840\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3164 - mae: 5.3164\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2965 - mae: 5.2965\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2396 - mae: 5.2396\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2217 - mae: 5.2217\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1941 - mae: 5.1941\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1606 - mae: 5.1606\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1492 - mae: 5.1492\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1297 - mae: 5.1297\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1173 - mae: 5.1173\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0983 - mae: 5.0983\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0945 - mae: 5.0945\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0702 - mae: 5.0702\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0494 - mae: 5.0494\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0406 - mae: 5.0406\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0365 - mae: 5.0365\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0130 - mae: 5.0130\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0131 - mae: 5.0131\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0155 - mae: 5.0155\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9973 - mae: 4.9973\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9787 - mae: 4.9787\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9913 - mae: 4.9913\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9686 - mae: 4.9686\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9674 - mae: 4.9674\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9432 - mae: 4.9432\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9434 - mae: 4.9434\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9396 - mae: 4.9396\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9219 - mae: 4.9219\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9230 - mae: 4.9230\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9169 - mae: 4.9169\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9049 - mae: 4.9049\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9033 - mae: 4.9033\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9080 - mae: 4.9080\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8787 - mae: 4.8787\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8847 - mae: 4.8847\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8754 - mae: 4.8754\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8777 - mae: 4.8777\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8654 - mae: 4.8654\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8489 - mae: 4.8489\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8627 - mae: 4.8627\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8551 - mae: 4.8551\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8404 - mae: 4.8404\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8298 - mae: 4.8298\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8261 - mae: 4.8261\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8331 - mae: 4.8331\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8160 - mae: 4.8160\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8135 - mae: 4.8135\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8003 - mae: 4.8003\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7985 - mae: 4.7985\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8003 - mae: 4.8003\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7945 - mae: 4.7945\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7864 - mae: 4.7864\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7800 - mae: 4.7800\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7617 - mae: 4.7617\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7738 - mae: 4.7738\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7639 - mae: 4.7639\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7601 - mae: 4.7601\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7485 - mae: 4.7485\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7533 - mae: 4.7533\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7474 - mae: 4.7474\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7407 - mae: 4.7407\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7337 - mae: 4.7337\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7311 - mae: 4.7311\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7331 - mae: 4.7331\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7197 - mae: 4.7197\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7188 - mae: 4.7188\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7009 - mae: 4.7009\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7055 - mae: 4.7055\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6942 - mae: 4.6942\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6947 - mae: 4.6947\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7050 - mae: 4.7050\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6859 - mae: 4.6859\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6834 - mae: 4.6834\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6754 - mae: 4.6754\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6764 - mae: 4.6764\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6673 - mae: 4.6673\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6694 - mae: 4.6694\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6658 - mae: 4.6658\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6589 - mae: 4.6589\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6587 - mae: 4.6587\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6669 - mae: 4.6669\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6482 - mae: 4.6482\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6443 - mae: 4.6443\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6491 - mae: 4.6491\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6417 - mae: 4.6417\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6464 - mae: 4.6464\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6523 - mae: 4.6523\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6394 - mae: 4.6394\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6353 - mae: 4.6353\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6341 - mae: 4.6341\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6221 - mae: 4.6221\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6312 - mae: 4.6312\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6186 - mae: 4.6186\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6240 - mae: 4.6240\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6268 - mae: 4.6268\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6204 - mae: 4.6204\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5806 - mae: 4.5806\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5408 - mae: 4.5408\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5196 - mae: 4.5196\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.5096 - mae: 4.5096\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4981 - mae: 4.4981\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4909 - mae: 4.4909\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4892 - mae: 4.4892\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4833 - mae: 4.4833\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4813 - mae: 4.4813\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4805 - mae: 4.4805\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4757 - mae: 4.4757\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4743 - mae: 4.4743\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4723 - mae: 4.4723\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4722 - mae: 4.4722\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4698 - mae: 4.4698\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4687 - mae: 4.4687\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4687 - mae: 4.4687\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4680 - mae: 4.4680\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4639 - mae: 4.4639\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4643 - mae: 4.4643\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4645 - mae: 4.4645\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4627 - mae: 4.4627\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4631 - mae: 4.4631\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4614 - mae: 4.4614\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4626 - mae: 4.4626\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4600 - mae: 4.4600\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4591 - mae: 4.4591\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4592 - mae: 4.4592\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4580 - mae: 4.4580\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4576 - mae: 4.4576\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4564 - mae: 4.4564\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4560 - mae: 4.4560\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4556 - mae: 4.4556\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4556 - mae: 4.4556\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4554 - mae: 4.4554\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4539 - mae: 4.4539\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4541 - mae: 4.4541\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4525 - mae: 4.4525\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4509 - mae: 4.4509\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4536 - mae: 4.4536\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4509 - mae: 4.4509\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4516 - mae: 4.4516\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4428 - mae: 4.4428\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4403 - mae: 4.4403\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4392 - mae: 4.4392\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4383 - mae: 4.4383\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4376 - mae: 4.4376\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4370 - mae: 4.4370\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.4367 - mae: 4.4367\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3262 - mae: 9.3262\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4343 - mae: 8.4343\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1619 - mae: 8.1619\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9678 - mae: 7.9678\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9563 - mae: 7.9563\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8487 - mae: 7.8487\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7801 - mae: 7.7801\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6243 - mae: 7.6243\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6598 - mae: 7.6598\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5279 - mae: 7.5279\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4273 - mae: 7.4273\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4853 - mae: 7.4853\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4036 - mae: 7.4036\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2235 - mae: 7.2235\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1888 - mae: 7.1888\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1483 - mae: 7.1483\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1453 - mae: 7.1453\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0903 - mae: 7.0903\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1930 - mae: 7.1930\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0801 - mae: 7.0801\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8858 - mae: 6.8858\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9550 - mae: 6.9550\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0393 - mae: 7.0393\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8574 - mae: 6.8574\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8118 - mae: 6.8118\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7799 - mae: 6.7799\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8232 - mae: 6.8232\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8117 - mae: 6.8117\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7708 - mae: 6.7708\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9462 - mae: 6.9462\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6766 - mae: 6.6766\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6508 - mae: 6.6508\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6425 - mae: 6.6425\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7626 - mae: 6.7626\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5964 - mae: 6.5964\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6322 - mae: 6.6322\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5348 - mae: 6.5348\n",
      "Epoch 39/200\n",
      " 318/1548 [=====>........................] - ETA: 4s - loss: 6.3538 - mae: 6.3538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8812 - mae: 4.8812\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8852 - mae: 4.8852\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8712 - mae: 4.8712\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8521 - mae: 4.8521\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8432 - mae: 4.8432\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8596 - mae: 4.8596\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8305 - mae: 4.8305\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8354 - mae: 4.8354\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8369 - mae: 4.8369\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8101 - mae: 4.8101\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8410 - mae: 4.8410\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8128 - mae: 4.8128\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8127 - mae: 4.8127\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7348 - mae: 4.7348\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7051 - mae: 4.7051\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6850 - mae: 4.6850\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6765 - mae: 4.6765\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6663 - mae: 4.6663\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6593 - mae: 4.6593\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6494 - mae: 4.6494\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6428 - mae: 4.6428\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6390 - mae: 4.6390\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6383 - mae: 4.6383\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6329 - mae: 4.6329\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6333 - mae: 4.6333\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6282 - mae: 4.6282\n",
      "Epoch 138/200\n",
      "1056/1548 [===================>..........] - ETA: 1s - loss: 4.6289 - mae: 4.6289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5569 - mae: 7.5569\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3345 - mae: 7.3345\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3138 - mae: 7.3138\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3472 - mae: 7.3472\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3092 - mae: 7.3092\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1204 - mae: 7.1204\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1788 - mae: 7.1788\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1433 - mae: 7.1433\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8951 - mae: 6.8951\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9667 - mae: 6.9667\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9358 - mae: 6.9358\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9584 - mae: 6.9584\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2978 - mae: 6.2978\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1508 - mae: 6.1508\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0579 - mae: 6.0579\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0073 - mae: 6.0073\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9418 - mae: 5.9418\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9132 - mae: 5.9132\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8813 - mae: 5.8813\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8637 - mae: 5.8637\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8325 - mae: 5.8325\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7829 - mae: 5.7829\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7798 - mae: 5.7798\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7544 - mae: 5.7544\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7316 - mae: 5.7316\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7123 - mae: 5.7123\n",
      "Epoch 38/200\n",
      " 677/1548 [============>.................] - ETA: 3s - loss: 5.8798 - mae: 5.8798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1787 - mae: 5.1787\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1951 - mae: 5.1951\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1494 - mae: 5.1494\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1760 - mae: 5.1760\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1514 - mae: 5.1514\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1448 - mae: 5.1448\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1449 - mae: 5.1449\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1198 - mae: 5.1198\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1194 - mae: 5.1194\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1078 - mae: 5.1078\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0943 - mae: 5.0943\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0996 - mae: 5.0996\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0925 - mae: 5.0925\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0673 - mae: 5.0673\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0845 - mae: 5.0845\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0706 - mae: 5.0706\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0731 - mae: 5.0731\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9487 - mae: 4.9487\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9194 - mae: 4.9194\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9081 - mae: 4.9081\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8971 - mae: 4.8971\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8909 - mae: 4.8909\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8863 - mae: 4.8863\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8798 - mae: 4.8798\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8726 - mae: 4.8726\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8741 - mae: 4.8741\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8679 - mae: 4.8679\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8677 - mae: 4.8677\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8605 - mae: 4.8605\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8595 - mae: 4.8595\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8561 - mae: 4.8561\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8560 - mae: 4.8560\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8494 - mae: 4.8494\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8480 - mae: 4.8480\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8478 - mae: 4.8478\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8444 - mae: 4.8444\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8419 - mae: 4.8419\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8420 - mae: 4.8420\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8410 - mae: 4.8410\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8390 - mae: 4.8390\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8349 - mae: 4.8349\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8360 - mae: 4.8360\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8343 - mae: 4.8343\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8293 - mae: 4.8293\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8318 - mae: 4.8318\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8278 - mae: 4.8278\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8274 - mae: 4.8274\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8245 - mae: 4.8245\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8274 - mae: 4.8274\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8204 - mae: 4.8204\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8220 - mae: 4.8220\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8203 - mae: 4.8203\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8176 - mae: 4.8176\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8180 - mae: 4.8180\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8166 - mae: 4.8166\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8133 - mae: 4.8133\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8146 - mae: 4.8146\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8126 - mae: 4.8126\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8100 - mae: 4.8100\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8101 - mae: 4.8101\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8084 - mae: 4.8084\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8092 - mae: 4.8092\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8047 - mae: 4.8047\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8042 - mae: 4.8042\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8031 - mae: 4.8031\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8056 - mae: 4.8056\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7995 - mae: 4.7995\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8019 - mae: 4.8019\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7957 - mae: 4.7957\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7993 - mae: 4.7993\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7969 - mae: 4.7969\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7956 - mae: 4.7956\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7852 - mae: 4.7852\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7812 - mae: 4.7812\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7795 - mae: 4.7795\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7776 - mae: 4.7776\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7771 - mae: 4.7771\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7762 - mae: 4.7762\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7752 - mae: 4.7752\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7747 - mae: 4.7747\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7743 - mae: 4.7743\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7740 - mae: 4.7740\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7733 - mae: 4.7733\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7732 - mae: 4.7732\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7727 - mae: 4.7727\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7726 - mae: 4.7726\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7723 - mae: 4.7723\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7723 - mae: 4.7723\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7720 - mae: 4.7720\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7715 - mae: 4.7715\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7714 - mae: 4.7714\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7712 - mae: 4.7712\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7711 - mae: 4.7711\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7706 - mae: 4.7706\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7707 - mae: 4.7707\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7704 - mae: 4.7704\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7705 - mae: 4.7705\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7700 - mae: 4.7700\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7699 - mae: 4.7699\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7697 - mae: 4.7697\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7695 - mae: 4.7695\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7696 - mae: 4.7696\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7695 - mae: 4.7695\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7691 - mae: 4.7691\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7692 - mae: 4.7692\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7688 - mae: 4.7688\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7687 - mae: 4.7687\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7686 - mae: 4.7686\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7684 - mae: 4.7684\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7684 - mae: 4.7684\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7679 - mae: 4.7679\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7681 - mae: 4.7681\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7677 - mae: 4.7677\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7676 - mae: 4.7676\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7676 - mae: 4.7676\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7674 - mae: 4.7674\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7675 - mae: 4.7675\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7670 - mae: 4.7670\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7670 - mae: 4.7670\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7669 - mae: 4.7669\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7670 - mae: 4.7670\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7655 - mae: 4.7655\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7651 - mae: 4.7651\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7649 - mae: 4.7649\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7648 - mae: 4.7648\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4848 - mae: 9.4848\n",
      "Epoch 2/200\n",
      "1431/1548 [==========================>...] - ETA: 0s - loss: 8.7908 - mae: 8.7908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2738 - mae: 5.2738\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2600 - mae: 5.2600\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2715 - mae: 5.2715\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2516 - mae: 5.2516\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2381 - mae: 5.2381\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2393 - mae: 5.2393\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2361 - mae: 5.2361\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2231 - mae: 5.2231\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2067 - mae: 5.2067\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2067 - mae: 5.2067\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1956 - mae: 5.1956\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1845 - mae: 5.1845\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1811 - mae: 5.1811\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1608 - mae: 5.1608\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1938 - mae: 5.1938\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1431 - mae: 5.1431\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1460 - mae: 5.1460\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1463 - mae: 5.1463\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1309 - mae: 5.1309\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1336 - mae: 5.1336\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1177 - mae: 5.1177\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1170 - mae: 5.1170\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0787 - mae: 5.0787\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0986 - mae: 5.0986\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0923 - mae: 5.0923\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0842 - mae: 5.0842\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 101/200\n",
      "1361/1548 [=========================>....] - ETA: 0s - loss: 5.0214 - mae: 5.0214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8090 - mae: 4.8090\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8010 - mae: 4.8010\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7968 - mae: 4.7968\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7947 - mae: 4.7947\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7929 - mae: 4.7929\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7919 - mae: 4.7919\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7904 - mae: 4.7904\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7899 - mae: 4.7899\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7891 - mae: 4.7891\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7884 - mae: 4.7884\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7881 - mae: 4.7881\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7875 - mae: 4.7875\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7876 - mae: 4.7876\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7872 - mae: 4.7872\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7870 - mae: 4.7870\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7863 - mae: 4.7863\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7868 - mae: 4.7868\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7864 - mae: 4.7864\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7863 - mae: 4.7863\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7848 - mae: 4.7848\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7844 - mae: 4.7844\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7842 - mae: 4.7842\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7841 - mae: 4.7841\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7840 - mae: 4.7840\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7840 - mae: 4.7840\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7839 - mae: 4.7839\n",
      "Epoch 1/200\n",
      " 877/1548 [===============>..............] - ETA: 2s - loss: 10.3003 - mae: 10.3003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1843 - mae: 5.1843\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1793 - mae: 5.1793\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1367 - mae: 5.1367\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1482 - mae: 5.1482\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1216 - mae: 5.1216\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1125 - mae: 5.1125\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1036 - mae: 5.1036\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1133 - mae: 5.1133\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0781 - mae: 5.0781\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0818 - mae: 5.0818\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0871 - mae: 5.0871\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0566 - mae: 5.0566\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0437 - mae: 5.0437\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0272 - mae: 5.0272\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0553 - mae: 5.0553\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0128 - mae: 5.0128\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9961 - mae: 4.9961\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9902 - mae: 4.9902\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0156 - mae: 5.0156\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0116 - mae: 5.0116\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9706 - mae: 4.9706\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9624 - mae: 4.9624\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9869 - mae: 4.9869\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9507 - mae: 4.9507\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9631 - mae: 4.9631\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9655 - mae: 4.9655\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9429 - mae: 4.9429\n",
      "Epoch 101/200\n",
      " 335/1548 [=====>........................] - ETA: 4s - loss: 4.8447 - mae: 4.8447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6204 - mae: 4.6204\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6200 - mae: 4.6200\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6201 - mae: 4.6201\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6201 - mae: 4.6201\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6200 - mae: 4.6200\n",
      "\n",
      "Epoch 00178: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6183 - mae: 4.6183\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6180 - mae: 4.6180\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6178 - mae: 4.6178\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6177 - mae: 4.6177\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6177 - mae: 4.6177\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6176 - mae: 4.6176\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6176 - mae: 4.6176\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6175 - mae: 4.6175\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6175 - mae: 4.6175\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6174 - mae: 4.6174\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6174 - mae: 4.6174\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6174 - mae: 4.6174\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6173 - mae: 4.6173\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6173 - mae: 4.6173\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6173 - mae: 4.6173\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6171 - mae: 4.6171\n",
      "Epoch 200/200\n",
      "1249/1548 [=======================>......] - ETA: 1s - loss: 4.5425 - mae: 4.5425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2136 - mae: 5.2136\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2218 - mae: 5.2218\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1949 - mae: 5.1949\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2057 - mae: 5.2057\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1920 - mae: 5.1920\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1661 - mae: 5.1661\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1611 - mae: 5.1611\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1671 - mae: 5.1671\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1458 - mae: 5.1458\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1412 - mae: 5.1412\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1400 - mae: 5.1400\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1321 - mae: 5.1321\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1159 - mae: 5.1159\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1163 - mae: 5.1163\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1027 - mae: 5.1027\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1105 - mae: 5.1105\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0967 - mae: 5.0967\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0880 - mae: 5.0880\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0874 - mae: 5.0874\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0704 - mae: 5.0704\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0796 - mae: 5.0796\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0504 - mae: 5.0504\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0465 - mae: 5.0465\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0549 - mae: 5.0549\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0383 - mae: 5.0383\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0402 - mae: 5.0402\n",
      "Epoch 100/200\n",
      " 729/1548 [=============>................] - ETA: 3s - loss: 4.8789 - mae: 4.8789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6657 - mae: 4.6657\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6654 - mae: 4.6654\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6660 - mae: 4.6660\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6638 - mae: 4.6638\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6618 - mae: 4.6618\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6625 - mae: 4.6625\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6608 - mae: 4.6608\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6610 - mae: 4.6610\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6580 - mae: 4.6580\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6588 - mae: 4.6588\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6545 - mae: 4.6545\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6563 - mae: 4.6563\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6556 - mae: 4.6556\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6520 - mae: 4.6520\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6547 - mae: 4.6547\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6514 - mae: 4.6514\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6530 - mae: 4.6530\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6518 - mae: 4.6518\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6499 - mae: 4.6499\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6477 - mae: 4.6477\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 5s 4ms/step - loss: 4.6493 - mae: 4.6493\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 4.6471 - mae: 4.6471\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 4.6465 - mae: 4.6465\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 4.6468 - mae: 4.6468\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6439 - mae: 4.6439\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6446 - mae: 4.6446\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6421 - mae: 4.6421\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6419 - mae: 4.6419\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6412 - mae: 4.6412\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4199 - mae: 9.4199\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5781 - mae: 8.5781\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1844 - mae: 8.1844\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9424 - mae: 7.9424\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8290 - mae: 7.8290\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7482 - mae: 7.7482\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6819 - mae: 7.6819\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5957 - mae: 7.5957\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4677 - mae: 7.4677\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4817 - mae: 7.4817\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4065 - mae: 7.4065\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3390 - mae: 7.3390\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2499 - mae: 7.2499\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2578 - mae: 7.2578\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2438 - mae: 7.2438\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1284 - mae: 7.1284\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0667 - mae: 7.0667\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0126 - mae: 7.0126\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8798 - mae: 6.8798\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9226 - mae: 6.9226\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8609 - mae: 6.8609\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8889 - mae: 6.8889\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7683 - mae: 6.7683\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7195 - mae: 6.7195\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6581 - mae: 6.6581\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7415 - mae: 6.7415\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6696 - mae: 6.6696\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5940 - mae: 6.5940\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6438 - mae: 6.6438\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5968 - mae: 6.5968\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4701 - mae: 6.4701\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5528 - mae: 6.5528\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5381 - mae: 6.5381\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3559 - mae: 6.3559\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4894 - mae: 6.4894\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5425 - mae: 6.5425\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4295 - mae: 6.4295\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9271 - mae: 5.9271\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7500 - mae: 5.7500\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6738 - mae: 5.6738\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6301 - mae: 5.6301\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6044 - mae: 5.6044\n",
      "Epoch 44/200\n",
      " 697/1548 [============>.................] - ETA: 3s - loss: 5.4469 - mae: 5.4469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8723 - mae: 4.8723\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8549 - mae: 4.8549\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8570 - mae: 4.8570\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8444 - mae: 4.8444\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8479 - mae: 4.8479\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8360 - mae: 4.8360\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8486 - mae: 4.8486\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8403 - mae: 4.8403\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8177 - mae: 4.8177\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8250 - mae: 4.8250\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8038 - mae: 4.8038\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8062 - mae: 4.8062\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7979 - mae: 4.7979\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7870 - mae: 4.7870\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7988 - mae: 4.7988\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7926 - mae: 4.7926\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7923 - mae: 4.7923\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7556 - mae: 4.7556\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6898 - mae: 4.6898\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6688 - mae: 4.6688\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6506 - mae: 4.6506\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6412 - mae: 4.6412\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6350 - mae: 4.6350\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6286 - mae: 4.6286\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6259 - mae: 4.6259\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.6231 - mae: 4.6231\n",
      "Epoch 149/200\n",
      " 734/1548 [=============>................] - ETA: 3s - loss: 4.6596 - mae: 4.6596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct neural network model\n",
    "kf = 10\n",
    "p = 78\n",
    "KF = KFold(n_splits = kf,shuffle=True,random_state=7)\n",
    "MAE = np.zeros([kf])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Define Sequential model with 2 hidden layers\n",
    "    model_one_layers = keras.Sequential([\n",
    "        layers.Dense(77, activation = \"relu\", name = \"input\", input_dim = 77),\n",
    "        layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "        layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "        layers.Dense(1, name = \"output\")])\n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                verbose = 1)\n",
    "    # Optimizer for Adam\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "    model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "    # Train the model\n",
    "    history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "    # Prediction\n",
    "    test_predictions = model_one_layers.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel() - test_Y))\n",
    "    MAE[i] = model_error.mean()\n",
    "    i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_final_model.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1703bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1787\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 77)                6006      \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 150)               11700     \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 130)               19630     \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 1)                 131       \n",
      "=================================================================\n",
      "Total params: 37,467\n",
      "Trainable params: 37,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#æ˜¾ç¤ºç½‘ç»œç»“æž„\n",
    "model_one_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "91cdc743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ç»˜åˆ¶lossæ›²çº¿\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [MAE]')\n",
    "plt.plot(hist['epoch'], hist['mae'],label='mae')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da943474",
   "metadata": {},
   "source": [
    "# The Importance of Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64782647",
   "metadata": {},
   "source": [
    "The leave-one-feature-out method is adopted to measure the importance of factors \\citep{li2022predicting}. First, we regard the model with all factors as the basic model. Second, we train the model by leaving one feature out and record the 10-fold CV MAE. Third, the absolute difference of the 10-fold CV MAE between the leave-one-feature-out model and the basic model is calculated. Finally, we normalize the absolute difference and transform it into a value between 0-100. The larger the value, the more important the factor is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81531b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4904 - mae: 9.4904\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5817 - mae: 8.5817\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3385 - mae: 8.3385\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0906 - mae: 8.0906\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0064 - mae: 8.0064\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8133 - mae: 7.8133\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8461 - mae: 7.8461\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6884 - mae: 7.6884\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6286 - mae: 7.6286\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6377 - mae: 7.6377\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5127 - mae: 7.5127\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4579 - mae: 7.4579\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3877 - mae: 7.3877\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2920 - mae: 7.2920\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2920 - mae: 7.2920\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1145 - mae: 7.1145\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1367 - mae: 7.1367\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1146 - mae: 7.1146\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0539 - mae: 7.0539\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9939 - mae: 6.9939\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9692 - mae: 6.9692\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0071 - mae: 7.0071\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7831 - mae: 6.7831\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8365 - mae: 6.8365\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8434 - mae: 6.8434\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6704 - mae: 6.6704\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7772 - mae: 6.7772\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6921 - mae: 6.6921\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7001 - mae: 6.7001\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4375 - mae: 6.4375\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1310 - mae: 6.1310\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9888 - mae: 5.9888\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9193 - mae: 5.9193\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8518 - mae: 5.8518\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8209 - mae: 5.8209\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7785 - mae: 5.7785\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7453 - mae: 5.7453\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7083 - mae: 5.7083\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6889 - mae: 5.6889\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6544 - mae: 5.6544\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6546 - mae: 5.6546\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6128 - mae: 5.6128\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6094 - mae: 5.6094\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5951 - mae: 5.5951\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5794 - mae: 5.5794\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5682 - mae: 5.5682\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5491 - mae: 5.5491\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5471 - mae: 5.5471\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5183 - mae: 5.5183\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.5151 - mae: 5.5151\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4893 - mae: 5.4893\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4974 - mae: 5.4974\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4756 - mae: 5.4756\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4713 - mae: 5.4713\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4612 - mae: 5.4612\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4335 - mae: 5.4335\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4307 - mae: 5.4307\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4085 - mae: 5.4085\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4113 - mae: 5.4113\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.4140 - mae: 5.4140\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3938 - mae: 5.3938\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3718 - mae: 5.3718\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3697 - mae: 5.3697\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3554 - mae: 5.3554\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3433 - mae: 5.3433\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3271 - mae: 5.3271\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3201 - mae: 5.3201\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3101 - mae: 5.3101\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.3257 - mae: 5.3257\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2848 - mae: 5.2848\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2871 - mae: 5.2871\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2786 - mae: 5.2786\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2632 - mae: 5.2632\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2713 - mae: 5.2713\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2452 - mae: 5.2452\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2424 - mae: 5.2424\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2338 - mae: 5.2338\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2468 - mae: 5.2468\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2164 - mae: 5.2164\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2154 - mae: 5.2154\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.2074 - mae: 5.2074\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1905 - mae: 5.1905\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1845 - mae: 5.1845\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1794 - mae: 5.1794\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1864 - mae: 5.1864\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1645 - mae: 5.1645\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1455 - mae: 5.1455\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1417 - mae: 5.1417\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1490 - mae: 5.1490\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1589 - mae: 5.1589\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1357 - mae: 5.1357\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1337 - mae: 5.1337\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1194 - mae: 5.1194\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1086 - mae: 5.1086\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1057 - mae: 5.1057\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1055 - mae: 5.1055\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0725 - mae: 5.0725\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.1032 - mae: 5.1032\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0822 - mae: 5.0822\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.0920 - mae: 5.0920\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9789 - mae: 4.9789\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9417 - mae: 4.9417\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9287 - mae: 4.9287\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9166 - mae: 4.9166\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9115 - mae: 4.9115\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9081 - mae: 4.9081\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9005 - mae: 4.9005\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.9004 - mae: 4.9004\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8921 - mae: 4.8921\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8892 - mae: 4.8892\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8881 - mae: 4.8881\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8849 - mae: 4.8849\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8829 - mae: 4.8829\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8790 - mae: 4.8790\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8799 - mae: 4.8799\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8737 - mae: 4.8737\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8745 - mae: 4.8745\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8718 - mae: 4.8718\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8716 - mae: 4.8716\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8684 - mae: 4.8684\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8649 - mae: 4.8649\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8664 - mae: 4.8664\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8623 - mae: 4.8623\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8642 - mae: 4.8642\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8613 - mae: 4.8613\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8618 - mae: 4.8618\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8565 - mae: 4.8565\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8589 - mae: 4.8589\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8552 - mae: 4.8552\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8542 - mae: 4.8542\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8540 - mae: 4.8540\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8502 - mae: 4.8502\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8528 - mae: 4.8528\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8471 - mae: 4.8471\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8467 - mae: 4.8467\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8464 - mae: 4.8464\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8458 - mae: 4.8458\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8443 - mae: 4.8443\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8417 - mae: 4.8417\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8424 - mae: 4.8424\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8396 - mae: 4.8396\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8400 - mae: 4.8400\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8358 - mae: 4.8358\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8401 - mae: 4.8401\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8361 - mae: 4.8361\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8349 - mae: 4.8349\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8346 - mae: 4.8346\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8318 - mae: 4.8318\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8338 - mae: 4.8338\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8300 - mae: 4.8300\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8316 - mae: 4.8316\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8277 - mae: 4.8277\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8282 - mae: 4.8282\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8267 - mae: 4.8267\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8256 - mae: 4.8256\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8230 - mae: 4.8230\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8244 - mae: 4.8244\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8229 - mae: 4.8229\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8221 - mae: 4.8221\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8201 - mae: 4.8201\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8212 - mae: 4.8212\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8179 - mae: 4.8179\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8176 - mae: 4.8176\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8192 - mae: 4.8192\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8167 - mae: 4.8167\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8161 - mae: 4.8161\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8141 - mae: 4.8141\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8145 - mae: 4.8145\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8118 - mae: 4.8118\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8130 - mae: 4.8130\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8100 - mae: 4.8100\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8107 - mae: 4.8107\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8068 - mae: 4.8068\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8084 - mae: 4.8084\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8082 - mae: 4.8082\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8051 - mae: 4.8051\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8034 - mae: 4.8034\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8050 - mae: 4.8050\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8041 - mae: 4.8041\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8017 - mae: 4.8017\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8015 - mae: 4.8015\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.8015 - mae: 4.8015\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7994 - mae: 4.7994\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7958 - mae: 4.7958\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7991 - mae: 4.7991\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7966 - mae: 4.7966\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7970 - mae: 4.7970\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7863 - mae: 4.7863\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7828 - mae: 4.7828\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7808 - mae: 4.7808\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7792 - mae: 4.7792\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7782 - mae: 4.7782\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 4.7776 - mae: 4.7776\n",
      "Epoch 194/200\n",
      " 705/1548 [============>.................] - ETA: 3s - loss: 4.7144 - mae: 4.7144"
     ]
    }
   ],
   "source": [
    "# Construct neural network model\n",
    "kf = 10\n",
    "MAE = np.zeros([kf*77])\n",
    "i = 0\n",
    "KF = KFold(n_splits = kf, shuffle=True, random_state=7)\n",
    "for p in range(1,78):\n",
    "    print(p)\n",
    "    for train_index,test_index in KF.split(data):\n",
    "        train_X = data[train_index, :]\n",
    "        train_X = train_X[:, [_ for _ in range(1,78) if _ != p]]\n",
    "        train_Y = data[train_index, 0]\n",
    "        test_X = data[test_index, :]\n",
    "        test_X = test_X[:, [_ for _ in range(1,78) if _ != p]]\n",
    "        test_Y = data[test_index, 0]\n",
    "        # Define Sequential model with 2 hidden layers\n",
    "        model_one_layers = keras.Sequential([\n",
    "            layers.Dense(76, activation = \"relu\", name = \"input\", input_dim = 76),\n",
    "            layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "            layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "            layers.Dense(1, name = \"output\")])\n",
    "        # ReduceLROnPlateau\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                    factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                    patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                    verbose = 1)\n",
    "        # Optimizer for Adam\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "        model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "        # Train the model\n",
    "        history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "        # Prediction\n",
    "        test_predictions = model_one_layers.predict(test_X)\n",
    "        # MAE\n",
    "        model_error = abs((test_predictions.ravel()-test_Y))\n",
    "        MAE[i] = model_error.mean()\n",
    "        i = i + 1\n",
    "# ä¿å­˜ç»“æžœ\n",
    "MAE_leave_one_feature_out = pd.DataFrame(list(MAE))\n",
    "MAE_leave_one_feature_out.to_csv(\"MAE_Leave_one_feature_out.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a3df",
   "metadata": {},
   "source": [
    "# Comparison with other methods\n",
    "## 9 commonly used methods\n",
    "we select 9 commonly used methods to compare with our model, including XGBoost, gradient boosting, support vector regression, random forest, LightGBM, $k$-nearest neighbor regression, LASSO, elastic net and linear regression. For each method, we report the MAE on each validation set generated by 10-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "464a06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad78de",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec4c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_SVR = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    svr = make_pipeline( SVR(kernel='linear')).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = svr.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_SVR[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e61bbf",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a55106",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LR = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    LR = make_pipeline(LinearRegression()).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = LR.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_LR[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c876e12",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c22849",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_Xgboost = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    model_xgb = xgb.XGBRegressor(booster='gbtree',colsample_bytree=0.8, gamma = 0,\n",
    "                             learning_rate=0.1, max_depth=5,\n",
    "                             n_estimators=500,min_child_weight=1,\n",
    "                             reg_alpha=0, reg_lambda=1,\n",
    "                             subsample=0.8,\n",
    "                             random_state =42).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = model_xgb.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_Xgboost[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba3d40",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "db99e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LASSO = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    lasso = make_pipeline( Lasso(alpha =0.0005, random_state=1,max_iter=10000000, positive=True)).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = lasso.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_LASSO[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7cebc",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ElasticNet = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    ENet = make_pipeline(ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3,max_iter=10000000)).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = ENet.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_ElasticNet[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a00657",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_GB = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=500, learning_rate=0.02,\n",
    "                                    max_depth=5, max_features=7,\n",
    "                                    min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = GBoost.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_GB[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a5021",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d65e46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LGBM = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                               learning_rate=0.05, n_estimators=500).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = model_lgb.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_LGBM[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20693039",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c008ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_RF = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    rf = RandomForestRegressor(n_estimators= 50, max_depth=25, min_samples_split=20,\n",
    "                               min_samples_leaf=10,max_features='sqrt' ,oob_score=True, \n",
    "                               random_state=10).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = rf.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_RF[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073177ca",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "da880d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_KNN = np.zeros([10])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Train the model\n",
    "    knn = KNeighborsRegressor(n_neighbors=3).fit(train_X, train_Y)\n",
    "    # Prediction\n",
    "    test_predictions = knn.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel()-test_Y))\n",
    "    score_KNN[i] = model_error.mean()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "38e19031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_SVR</th>\n",
       "      <th>score_LASSO</th>\n",
       "      <th>score_ElasticNet</th>\n",
       "      <th>score_GB</th>\n",
       "      <th>score_Xgboost</th>\n",
       "      <th>score_LGBM</th>\n",
       "      <th>score_RF</th>\n",
       "      <th>score_KNN</th>\n",
       "      <th>score_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.060508</td>\n",
       "      <td>11.376153</td>\n",
       "      <td>11.611226</td>\n",
       "      <td>7.881905</td>\n",
       "      <td>7.827563</td>\n",
       "      <td>9.344578</td>\n",
       "      <td>8.839938</td>\n",
       "      <td>10.990551</td>\n",
       "      <td>11.626615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.977483</td>\n",
       "      <td>12.349789</td>\n",
       "      <td>12.610718</td>\n",
       "      <td>9.784419</td>\n",
       "      <td>8.897829</td>\n",
       "      <td>10.450583</td>\n",
       "      <td>10.411239</td>\n",
       "      <td>12.060694</td>\n",
       "      <td>12.625850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.022834</td>\n",
       "      <td>12.112551</td>\n",
       "      <td>12.186845</td>\n",
       "      <td>8.449269</td>\n",
       "      <td>8.518780</td>\n",
       "      <td>9.883509</td>\n",
       "      <td>9.607925</td>\n",
       "      <td>11.384094</td>\n",
       "      <td>12.194539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.957908</td>\n",
       "      <td>12.269644</td>\n",
       "      <td>12.466566</td>\n",
       "      <td>8.433555</td>\n",
       "      <td>8.744953</td>\n",
       "      <td>9.851523</td>\n",
       "      <td>9.585174</td>\n",
       "      <td>11.186625</td>\n",
       "      <td>12.481218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.466605</td>\n",
       "      <td>12.401840</td>\n",
       "      <td>12.751434</td>\n",
       "      <td>9.922363</td>\n",
       "      <td>8.944327</td>\n",
       "      <td>10.143121</td>\n",
       "      <td>10.589575</td>\n",
       "      <td>12.143342</td>\n",
       "      <td>12.769020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.098736</td>\n",
       "      <td>12.761651</td>\n",
       "      <td>12.976705</td>\n",
       "      <td>8.521907</td>\n",
       "      <td>9.081119</td>\n",
       "      <td>10.309671</td>\n",
       "      <td>10.169187</td>\n",
       "      <td>11.157640</td>\n",
       "      <td>12.986860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.133772</td>\n",
       "      <td>11.684322</td>\n",
       "      <td>11.869645</td>\n",
       "      <td>8.347290</td>\n",
       "      <td>9.061282</td>\n",
       "      <td>9.630114</td>\n",
       "      <td>9.444207</td>\n",
       "      <td>11.072883</td>\n",
       "      <td>11.884542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.810542</td>\n",
       "      <td>12.100788</td>\n",
       "      <td>12.199119</td>\n",
       "      <td>9.215249</td>\n",
       "      <td>8.708297</td>\n",
       "      <td>9.846567</td>\n",
       "      <td>10.060862</td>\n",
       "      <td>11.742033</td>\n",
       "      <td>12.212592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.997689</td>\n",
       "      <td>11.274594</td>\n",
       "      <td>11.247754</td>\n",
       "      <td>7.352334</td>\n",
       "      <td>7.709153</td>\n",
       "      <td>8.735782</td>\n",
       "      <td>8.634912</td>\n",
       "      <td>10.879438</td>\n",
       "      <td>11.259097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.149973</td>\n",
       "      <td>12.411586</td>\n",
       "      <td>12.668067</td>\n",
       "      <td>8.559569</td>\n",
       "      <td>8.410199</td>\n",
       "      <td>10.340039</td>\n",
       "      <td>9.500519</td>\n",
       "      <td>12.103235</td>\n",
       "      <td>12.679618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score_SVR  score_LASSO  score_ElasticNet  score_GB  score_Xgboost  \\\n",
       "0   8.060508    11.376153         11.611226  7.881905       7.827563   \n",
       "1   9.977483    12.349789         12.610718  9.784419       8.897829   \n",
       "2   9.022834    12.112551         12.186845  8.449269       8.518780   \n",
       "3   8.957908    12.269644         12.466566  8.433555       8.744953   \n",
       "4   9.466605    12.401840         12.751434  9.922363       8.944327   \n",
       "5   9.098736    12.761651         12.976705  8.521907       9.081119   \n",
       "6   8.133772    11.684322         11.869645  8.347290       9.061282   \n",
       "7   8.810542    12.100788         12.199119  9.215249       8.708297   \n",
       "8   7.997689    11.274594         11.247754  7.352334       7.709153   \n",
       "9   9.149973    12.411586         12.668067  8.559569       8.410199   \n",
       "\n",
       "   score_LGBM   score_RF  score_KNN   score_LR  \n",
       "0    9.344578   8.839938  10.990551  11.626615  \n",
       "1   10.450583  10.411239  12.060694  12.625850  \n",
       "2    9.883509   9.607925  11.384094  12.194539  \n",
       "3    9.851523   9.585174  11.186625  12.481218  \n",
       "4   10.143121  10.589575  12.143342  12.769020  \n",
       "5   10.309671  10.169187  11.157640  12.986860  \n",
       "6    9.630114   9.444207  11.072883  11.884542  \n",
       "7    9.846567  10.060862  11.742033  12.212592  \n",
       "8    8.735782   8.634912  10.879438  11.259097  \n",
       "9   10.340039   9.500519  12.103235  12.679618  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save result\n",
    "result = pd.DataFrame(list(zip(score_SVR, score_LASSO, score_ElasticNet, score_GB, score_Xgboost, score_LGBM, score_RF, score_KNN, score_LR)))\n",
    "result.columns = ['score_SVR','score_LASSO','score_ElasticNet','score_GB','score_Xgboost','score_LGBM','score_RF','score_KNN','score_LR'] \n",
    "result.to_csv(\"Citation_count_pre_result.csv\", sep = \",\", index = False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d062c6",
   "metadata": {},
   "source": [
    "## Two comparative models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126b8a5",
   "metadata": {},
   "source": [
    "To evaluate the performance of the network-related and topic-related factors, we create two comparative models. Refer to Model I as the basic model, which contains all the factors. Then, Model II contains only traditional factors but without network-related factors. Model III is similar to Model I, except that the topic-related factors used are extracted by the Latent Dirichlet Allocation (LDA) topic model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7e81d",
   "metadata": {},
   "source": [
    "### Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.9418 - mae: 9.9418\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.1496 - mae: 9.1496\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.8488 - mae: 8.8488\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7972 - mae: 8.7972\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6730 - mae: 8.6730\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5526 - mae: 8.5526\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4750 - mae: 8.4750\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4019 - mae: 8.4019\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3332 - mae: 8.3332\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2499 - mae: 8.2499\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2223 - mae: 8.2223\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1846 - mae: 8.1846\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1271 - mae: 8.1271\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0982 - mae: 8.0982\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0650 - mae: 8.0650\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0408 - mae: 8.0408\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0517 - mae: 8.0517\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0911 - mae: 8.0911\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0278 - mae: 8.0278\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0318 - mae: 8.0318\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9760 - mae: 7.9760\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0261 - mae: 8.0261\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9824 - mae: 7.9824\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9023 - mae: 7.9023\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9184 - mae: 7.9184\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9180 - mae: 7.9180\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9762 - mae: 7.9762\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5674 - mae: 7.5674\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4965 - mae: 7.4965\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4569 - mae: 7.4569\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4157 - mae: 7.4157\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3988 - mae: 7.3988\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3757 - mae: 7.3757\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3585 - mae: 7.3585\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3320 - mae: 7.3320\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3149 - mae: 7.3149\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3072 - mae: 7.3072\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2959 - mae: 7.2959\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2903 - mae: 7.2903\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2731 - mae: 7.2731\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2564 - mae: 7.2564\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2545 - mae: 7.2545\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2363 - mae: 7.2363\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2264 - mae: 7.2264\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2091 - mae: 7.2091\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1972 - mae: 7.1972\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1987 - mae: 7.1987\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1839 - mae: 7.1839\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1813 - mae: 7.1813\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1811 - mae: 7.1811\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1427 - mae: 7.1427\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1408 - mae: 7.1408\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1469 - mae: 7.1469\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1493 - mae: 7.1493\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1341 - mae: 7.1341\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1254 - mae: 7.1254\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1167 - mae: 7.1167\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0991 - mae: 7.0991\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1018 - mae: 7.1018\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0955 - mae: 7.0955\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0948 - mae: 7.0948\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0893 - mae: 7.0893\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0785 - mae: 7.0785\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0779 - mae: 7.0779\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0612 - mae: 7.0612\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0465 - mae: 7.0465\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0423 - mae: 7.0423\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0423 - mae: 7.0423\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0287 - mae: 7.0287\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9953 - mae: 6.9953\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0085 - mae: 7.0085\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9980 - mae: 6.9980\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0148 - mae: 7.0148\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9151 - mae: 6.9151\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8980 - mae: 6.8980\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8896 - mae: 6.8896\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8837 - mae: 6.8837\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8808 - mae: 6.8808\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8763 - mae: 6.8763\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8733 - mae: 6.8733\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8736 - mae: 6.8736\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8683 - mae: 6.8683\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8697 - mae: 6.8697\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8675 - mae: 6.8675\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8659 - mae: 6.8659\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8623 - mae: 6.8623\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8636 - mae: 6.8636\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8609 - mae: 6.8609\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8617 - mae: 6.8617\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8586 - mae: 6.8586\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8585 - mae: 6.8585\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8581 - mae: 6.8581\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8566 - mae: 6.8566\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8558 - mae: 6.8558\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8538 - mae: 6.8538\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8520 - mae: 6.8520\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8514 - mae: 6.8514\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8505 - mae: 6.8505\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8474 - mae: 6.8474\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8497 - mae: 6.8497\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8473 - mae: 6.8473\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8458 - mae: 6.8458\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8454 - mae: 6.8454\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8438 - mae: 6.8438\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8414 - mae: 6.8414\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8432 - mae: 6.8432\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8410 - mae: 6.8410\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8395 - mae: 6.8395\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8377 - mae: 6.8377\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8351 - mae: 6.8351\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8371 - mae: 6.8371\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8319 - mae: 6.8319\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8352 - mae: 6.8352\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8349 - mae: 6.8349\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8325 - mae: 6.8325\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8294 - mae: 6.8294\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8291 - mae: 6.8291\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8298 - mae: 6.8298\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8267 - mae: 6.8267\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8266 - mae: 6.8266\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8231 - mae: 6.8231\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8274 - mae: 6.8274\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8216 - mae: 6.8216\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8243 - mae: 6.8243\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8229 - mae: 6.8229\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8219 - mae: 6.8219\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8102 - mae: 6.8102\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8098 - mae: 6.8098\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8090 - mae: 6.8090\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8086 - mae: 6.8086\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8085 - mae: 6.8085\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8084 - mae: 6.8084\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8079 - mae: 6.8079\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8079 - mae: 6.8079\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8076 - mae: 6.8076\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8071 - mae: 6.8071\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8072 - mae: 6.8072\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8071 - mae: 6.8071\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8070 - mae: 6.8070\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8056 - mae: 6.8056\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8056 - mae: 6.8056\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8056 - mae: 6.8056\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8055 - mae: 6.8055\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8055 - mae: 6.8055\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8055 - mae: 6.8055\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8055 - mae: 6.8055\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 5s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-21.\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-22.\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-23.\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.999999682655227e-24.\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8053 - mae: 6.8053\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 9.999999998199588e-25.\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9691 - mae: 8.9691\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7443 - mae: 8.7443\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5896 - mae: 8.5896\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4579 - mae: 8.4579\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5279 - mae: 8.5279\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3395 - mae: 8.3395\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2323 - mae: 8.2323\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2031 - mae: 8.2031\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1154 - mae: 8.1154\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1146 - mae: 8.1146\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0765 - mae: 8.0765\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9257 - mae: 7.9257\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0096 - mae: 8.0096\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0524 - mae: 8.0524\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9801 - mae: 7.9801\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5621 - mae: 7.5621\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4696 - mae: 7.4696\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4399 - mae: 7.4399\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4052 - mae: 7.4052\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3957 - mae: 7.3957\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3748 - mae: 7.3748\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3586 - mae: 7.3586\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3558 - mae: 7.3558\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3394 - mae: 7.3394\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3249 - mae: 7.3249\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3133 - mae: 7.3133\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3086 - mae: 7.3086\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2870 - mae: 7.2870\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2877 - mae: 7.2877\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2845 - mae: 7.2845\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2781 - mae: 7.2781\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2678 - mae: 7.2678\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2600 - mae: 7.2600\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2607 - mae: 7.2607\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2380 - mae: 7.2380\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2383 - mae: 7.2383\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2384 - mae: 7.2384\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2238 - mae: 7.2238\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2180 - mae: 7.2180\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2089 - mae: 7.2089\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1976 - mae: 7.1976\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1946 - mae: 7.1946\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1956 - mae: 7.1956\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1833 - mae: 7.1833\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1842 - mae: 7.1842\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1824 - mae: 7.1824\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1722 - mae: 7.1722\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1787 - mae: 7.1787\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1735 - mae: 7.1735\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1720 - mae: 7.1720\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1638 - mae: 7.1638\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1543 - mae: 7.1543\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1613 - mae: 7.1613\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1562 - mae: 7.1562\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1459 - mae: 7.1459\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1438 - mae: 7.1438\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1359 - mae: 7.1359\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1330 - mae: 7.1330\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1385 - mae: 7.1385\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1193 - mae: 7.1193\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1256 - mae: 7.1256\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1029 - mae: 7.1029\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1213 - mae: 7.1213\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1159 - mae: 7.1159\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1042 - mae: 7.1042\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0464 - mae: 7.0464\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0344 - mae: 7.0344\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0289 - mae: 7.0289\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0259 - mae: 7.0259\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0245 - mae: 7.0245\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0235 - mae: 7.0235\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0216 - mae: 7.0216\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0192 - mae: 7.0192\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0189 - mae: 7.0189\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0177 - mae: 7.0177\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0159 - mae: 7.0159\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0170 - mae: 7.0170\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0152 - mae: 7.0152\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0156 - mae: 7.0156\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0136 - mae: 7.0136\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0125 - mae: 7.0125\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0114 - mae: 7.0114\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0113 - mae: 7.0113\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0115 - mae: 7.0115\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0089 - mae: 7.0089\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0084 - mae: 7.0084\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0073 - mae: 7.0073\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0084 - mae: 7.0084\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0062 - mae: 7.0062\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0067 - mae: 7.0067\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0060 - mae: 7.0060\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0061 - mae: 7.0061\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0035 - mae: 7.0035\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0033 - mae: 7.0033\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0024 - mae: 7.0024\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0024 - mae: 7.0024\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0021 - mae: 7.0021\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0017 - mae: 7.0017\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0007 - mae: 7.0007\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9998 - mae: 6.9998\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9995 - mae: 6.9995\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9987 - mae: 6.9987\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9992 - mae: 6.9992\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9978 - mae: 6.9978\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9988 - mae: 6.9988\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9967 - mae: 6.9967\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9974 - mae: 6.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9957 - mae: 6.9957\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9956 - mae: 6.9956\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9954 - mae: 6.9954\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9950 - mae: 6.9950\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9942 - mae: 6.9942\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9937 - mae: 6.9937\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9940 - mae: 6.9940\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9925 - mae: 6.9925\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9924 - mae: 6.9924\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9920 - mae: 6.9920\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9914 - mae: 6.9914\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9908 - mae: 6.9908\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9902 - mae: 6.9902\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9907 - mae: 6.9907\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9889 - mae: 6.9889\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9884 - mae: 6.9884\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9897 - mae: 6.9897\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9853 - mae: 6.9853\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9875 - mae: 6.9875\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9856 - mae: 6.9856\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9856 - mae: 6.9856\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9783 - mae: 6.9783\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9765 - mae: 6.9765\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9761 - mae: 6.9761\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9758 - mae: 6.9758\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9755 - mae: 6.9755\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9753 - mae: 6.9753\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9751 - mae: 6.9751\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9749 - mae: 6.9749\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9747 - mae: 6.9747\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9746 - mae: 6.9746\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9747 - mae: 6.9747\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9745 - mae: 6.9745\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9743 - mae: 6.9743\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9742 - mae: 6.9742\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9742 - mae: 6.9742\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9741 - mae: 6.9741\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9741 - mae: 6.9741\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9732 - mae: 6.9732\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9731 - mae: 6.9731\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9730 - mae: 6.9730\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9730 - mae: 6.9730\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9730 - mae: 6.9730\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9729 - mae: 6.9729\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9729 - mae: 6.9729\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 9.999998977483753e-16.\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 9.999998977483754e-17.\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 9.999998845134856e-18.\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.999999010570977e-19.\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 9.999999424161285e-20.\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 9.999999682655225e-21.\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9728 - mae: 6.9728\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.9629 - mae: 9.9629\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.1147 - mae: 9.1147\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.9059 - mae: 8.9059\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7494 - mae: 8.7494\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5513 - mae: 8.5513\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4841 - mae: 8.4841\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3637 - mae: 8.3637\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3899 - mae: 8.3899\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3128 - mae: 8.3128\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2894 - mae: 8.2894\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2627 - mae: 8.2627\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1648 - mae: 8.1648\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1814 - mae: 8.1814\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1034 - mae: 8.1034\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0774 - mae: 8.0774\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1227 - mae: 8.1227\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0235 - mae: 8.0235\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0976 - mae: 8.0976\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0143 - mae: 8.0143\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9494 - mae: 7.9494\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0478 - mae: 8.0478\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9737 - mae: 7.9737\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0009 - mae: 8.0009\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 24/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6917 - mae: 7.6917\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5784 - mae: 7.5784\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5359 - mae: 7.5359\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5110 - mae: 7.5110\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4822 - mae: 7.4822\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4673 - mae: 7.4673\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4482 - mae: 7.4482\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4556 - mae: 7.4556\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4352 - mae: 7.4352\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4224 - mae: 7.4224\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4140 - mae: 7.4140\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4021 - mae: 7.4021\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3745 - mae: 7.3745\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3876 - mae: 7.3876\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3756 - mae: 7.3756\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3596 - mae: 7.3596\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3467 - mae: 7.3467\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3568 - mae: 7.3568\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3242 - mae: 7.3242\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3186 - mae: 7.3186\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3191 - mae: 7.3191\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3167 - mae: 7.3167\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3055 - mae: 7.3055\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3009 - mae: 7.3009\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2646 - mae: 7.2646\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2986 - mae: 7.2986\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2824 - mae: 7.2824\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2787 - mae: 7.2787\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1949 - mae: 7.1949\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1863 - mae: 7.1863\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1848 - mae: 7.1848\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1814 - mae: 7.1814\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1807 - mae: 7.1807\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1779 - mae: 7.1779\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1761 - mae: 7.1761\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1694 - mae: 7.1694\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1711 - mae: 7.1711\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1726 - mae: 7.1726\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1704 - mae: 7.1704\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1589 - mae: 7.1589\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1583 - mae: 7.1583\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1579 - mae: 7.1579\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1577 - mae: 7.1577\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1574 - mae: 7.1574\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1573 - mae: 7.1573\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1572 - mae: 7.1572\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1568 - mae: 7.1568\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1567 - mae: 7.1567\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1566 - mae: 7.1566\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1564 - mae: 7.1564\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1564 - mae: 7.1564\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1562 - mae: 7.1562\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1561 - mae: 7.1561\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1558 - mae: 7.1558\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1556 - mae: 7.1556\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1556 - mae: 7.1556\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1554 - mae: 7.1554\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1552 - mae: 7.1552\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1549 - mae: 7.1549\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1550 - mae: 7.1550\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1549 - mae: 7.1549\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1545 - mae: 7.1545\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1546 - mae: 7.1546\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1545 - mae: 7.1545\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1544 - mae: 7.1544\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1542 - mae: 7.1542\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1540 - mae: 7.1540\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1539 - mae: 7.1539\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1538 - mae: 7.1538\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1537 - mae: 7.1537\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1534 - mae: 7.1534\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1534 - mae: 7.1534\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1532 - mae: 7.1532\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1532 - mae: 7.1532\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1530 - mae: 7.1530\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1528 - mae: 7.1528\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1526 - mae: 7.1526\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1526 - mae: 7.1526\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1526 - mae: 7.1526\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1523 - mae: 7.1523\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1521 - mae: 7.1521\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1521 - mae: 7.1521\n",
      "Epoch 106/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1519 - mae: 7.1519\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1519 - mae: 7.1519\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1517 - mae: 7.1517\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1514 - mae: 7.1514\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1513 - mae: 7.1513\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1513 - mae: 7.1513\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1510 - mae: 7.1510\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1507 - mae: 7.1507\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1507 - mae: 7.1507\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1506 - mae: 7.1506\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1505 - mae: 7.1505\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1503 - mae: 7.1503\n",
      "Epoch 119/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1502 - mae: 7.1502\n",
      "Epoch 120/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1500 - mae: 7.1500\n",
      "Epoch 121/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1498 - mae: 7.1498\n",
      "Epoch 122/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1496 - mae: 7.1496\n",
      "Epoch 123/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1496 - mae: 7.1496\n",
      "Epoch 124/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1495 - mae: 7.1495\n",
      "Epoch 125/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1492 - mae: 7.1492\n",
      "Epoch 126/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1494 - mae: 7.1494\n",
      "Epoch 127/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1490 - mae: 7.1490\n",
      "Epoch 128/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1490 - mae: 7.1490\n",
      "Epoch 129/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1489 - mae: 7.1489\n",
      "Epoch 130/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1487 - mae: 7.1487\n",
      "Epoch 131/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1486 - mae: 7.1486\n",
      "Epoch 132/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1484 - mae: 7.1484\n",
      "Epoch 133/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1484 - mae: 7.1484\n",
      "Epoch 134/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1483 - mae: 7.1483\n",
      "Epoch 135/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1481 - mae: 7.1481\n",
      "Epoch 136/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1479 - mae: 7.1479\n",
      "Epoch 137/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1478 - mae: 7.1478\n",
      "Epoch 138/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1478 - mae: 7.1478\n",
      "Epoch 139/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1476 - mae: 7.1476\n",
      "Epoch 140/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1474 - mae: 7.1474\n",
      "Epoch 141/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1473 - mae: 7.1473\n",
      "Epoch 142/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1472 - mae: 7.1472\n",
      "Epoch 143/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1471 - mae: 7.1471\n",
      "Epoch 144/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1469 - mae: 7.1469\n",
      "Epoch 145/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1469 - mae: 7.1469\n",
      "Epoch 146/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1467 - mae: 7.1467\n",
      "Epoch 147/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1466 - mae: 7.1466\n",
      "Epoch 148/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1465 - mae: 7.1465\n",
      "Epoch 149/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1463 - mae: 7.1463\n",
      "Epoch 150/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1462 - mae: 7.1462\n",
      "Epoch 151/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1460 - mae: 7.1460\n",
      "Epoch 152/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1457 - mae: 7.1457\n",
      "Epoch 153/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1459 - mae: 7.1459\n",
      "Epoch 154/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 155/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 156/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1454 - mae: 7.1454\n",
      "Epoch 157/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1453 - mae: 7.1453\n",
      "Epoch 158/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1452 - mae: 7.1452\n",
      "Epoch 159/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1450 - mae: 7.1450\n",
      "Epoch 160/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1450 - mae: 7.1450\n",
      "Epoch 161/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1448 - mae: 7.1448\n",
      "Epoch 162/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1448 - mae: 7.1448\n",
      "Epoch 163/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1445 - mae: 7.1445\n",
      "Epoch 164/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1444 - mae: 7.1444\n",
      "Epoch 165/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1443 - mae: 7.1443\n",
      "Epoch 166/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1443 - mae: 7.1443\n",
      "Epoch 167/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1441 - mae: 7.1441\n",
      "Epoch 168/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1440 - mae: 7.1440\n",
      "Epoch 169/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1439 - mae: 7.1439\n",
      "Epoch 170/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1437 - mae: 7.1437\n",
      "Epoch 171/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1436 - mae: 7.1436\n",
      "Epoch 172/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1435 - mae: 7.1435\n",
      "Epoch 173/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1433 - mae: 7.1433\n",
      "Epoch 174/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1433 - mae: 7.1433\n",
      "Epoch 175/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1430 - mae: 7.1430\n",
      "Epoch 176/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1431 - mae: 7.1431\n",
      "Epoch 177/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1428 - mae: 7.1428\n",
      "Epoch 178/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1426 - mae: 7.1426\n",
      "Epoch 179/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1426 - mae: 7.1426\n",
      "Epoch 180/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1424 - mae: 7.1424\n",
      "Epoch 181/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1423 - mae: 7.1423\n",
      "Epoch 182/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1423 - mae: 7.1423\n",
      "Epoch 183/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1421 - mae: 7.1421\n",
      "Epoch 184/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1420 - mae: 7.1420\n",
      "Epoch 185/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1419 - mae: 7.1419\n",
      "Epoch 186/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1418 - mae: 7.1418\n",
      "Epoch 187/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1416 - mae: 7.1416\n",
      "Epoch 188/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1415 - mae: 7.1415\n",
      "Epoch 189/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1414 - mae: 7.1414\n",
      "Epoch 190/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1412 - mae: 7.1412\n",
      "Epoch 191/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1412 - mae: 7.1412\n",
      "Epoch 192/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1411 - mae: 7.1411\n",
      "Epoch 193/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1408 - mae: 7.1408\n",
      "Epoch 194/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1407 - mae: 7.1407\n",
      "Epoch 195/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1406 - mae: 7.1406\n",
      "Epoch 196/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1406 - mae: 7.1406\n",
      "Epoch 197/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1404 - mae: 7.1404\n",
      "Epoch 198/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1403 - mae: 7.1403\n",
      "Epoch 199/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1401 - mae: 7.1401\n",
      "Epoch 200/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 1/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.7905 - mae: 9.7905\n",
      "Epoch 2/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.0358 - mae: 9.0358\n",
      "Epoch 3/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7825 - mae: 8.7825\n",
      "Epoch 4/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5846 - mae: 8.5846\n",
      "Epoch 5/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4696 - mae: 8.4696\n",
      "Epoch 6/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4504 - mae: 8.4504\n",
      "Epoch 7/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3016 - mae: 8.3016\n",
      "Epoch 8/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2920 - mae: 8.2920\n",
      "Epoch 9/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2736 - mae: 8.2736\n",
      "Epoch 10/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2217 - mae: 8.2217\n",
      "Epoch 11/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1037 - mae: 8.1037\n",
      "Epoch 12/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1051 - mae: 8.1051\n",
      "Epoch 13/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0993 - mae: 8.0993\n",
      "Epoch 14/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1201 - mae: 8.1201\n",
      "Epoch 15/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0541 - mae: 8.0541\n",
      "Epoch 16/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 17/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0261 - mae: 8.0261\n",
      "Epoch 18/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9625 - mae: 7.9625\n",
      "Epoch 19/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9876 - mae: 7.9876\n",
      "Epoch 20/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9519 - mae: 7.9519\n",
      "Epoch 21/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9384 - mae: 7.9384\n",
      "Epoch 22/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9514 - mae: 7.9514\n",
      "Epoch 23/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9863 - mae: 7.9863\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8966 - mae: 7.8966\n",
      "Epoch 25/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8720 - mae: 7.8720\n",
      "Epoch 26/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8504 - mae: 7.8504\n",
      "Epoch 27/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9746 - mae: 7.9746\n",
      "Epoch 28/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8011 - mae: 7.8011\n",
      "Epoch 29/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8532 - mae: 7.8532\n",
      "Epoch 30/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8736 - mae: 7.8736\n",
      "Epoch 31/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7537 - mae: 7.7537\n",
      "Epoch 32/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7540 - mae: 7.7540\n",
      "Epoch 33/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8306 - mae: 7.8306\n",
      "Epoch 34/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7705 - mae: 7.7705\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 35/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5051 - mae: 7.5051\n",
      "Epoch 36/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3997 - mae: 7.3997\n",
      "Epoch 37/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3563 - mae: 7.3563\n",
      "Epoch 38/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3248 - mae: 7.3248\n",
      "Epoch 39/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3126 - mae: 7.3126\n",
      "Epoch 40/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2947 - mae: 7.2947\n",
      "Epoch 41/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2861 - mae: 7.2861\n",
      "Epoch 42/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2708 - mae: 7.2708\n",
      "Epoch 43/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2595 - mae: 7.2595\n",
      "Epoch 44/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2585 - mae: 7.2585\n",
      "Epoch 45/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2423 - mae: 7.2423\n",
      "Epoch 46/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2453 - mae: 7.2453\n",
      "Epoch 47/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2303 - mae: 7.2303\n",
      "Epoch 48/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2202 - mae: 7.2202\n",
      "Epoch 49/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2231 - mae: 7.2231\n",
      "Epoch 50/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2218 - mae: 7.2218\n",
      "Epoch 51/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2056 - mae: 7.2056\n",
      "Epoch 52/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2006 - mae: 7.2006\n",
      "Epoch 53/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1899 - mae: 7.1899\n",
      "Epoch 54/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1900 - mae: 7.1900\n",
      "Epoch 55/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1827 - mae: 7.1827\n",
      "Epoch 56/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1762 - mae: 7.1762\n",
      "Epoch 57/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1810 - mae: 7.1810\n",
      "Epoch 58/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1621 - mae: 7.1621\n",
      "Epoch 59/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1611 - mae: 7.1611\n",
      "Epoch 60/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1675 - mae: 7.1675\n",
      "Epoch 61/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1677 - mae: 7.1677\n",
      "Epoch 62/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1505 - mae: 7.1505\n",
      "Epoch 63/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1420 - mae: 7.1420\n",
      "Epoch 64/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1460 - mae: 7.1460\n",
      "Epoch 65/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1337 - mae: 7.1337\n",
      "Epoch 66/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1354 - mae: 7.1354\n",
      "Epoch 67/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1293 - mae: 7.1293\n",
      "Epoch 68/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1330 - mae: 7.1330\n",
      "Epoch 69/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1232 - mae: 7.1232\n",
      "Epoch 70/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1097 - mae: 7.1097\n",
      "Epoch 71/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1030 - mae: 7.1030\n",
      "Epoch 72/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0963 - mae: 7.0963\n",
      "Epoch 73/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1109 - mae: 7.1109\n",
      "Epoch 74/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0956 - mae: 7.0956\n",
      "Epoch 75/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0913 - mae: 7.0913\n",
      "Epoch 76/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 77/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0657 - mae: 7.0657\n",
      "Epoch 78/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0716 - mae: 7.0716\n",
      "Epoch 79/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0605 - mae: 7.0605\n",
      "Epoch 80/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0622 - mae: 7.0622\n",
      "Epoch 81/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0633 - mae: 7.0633\n",
      "Epoch 82/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0507 - mae: 7.0507\n",
      "Epoch 83/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0481 - mae: 7.0481\n",
      "Epoch 84/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0404 - mae: 7.0404\n",
      "Epoch 85/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0400 - mae: 7.0400\n",
      "Epoch 86/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0327 - mae: 7.0327\n",
      "Epoch 87/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0310 - mae: 7.0310\n",
      "Epoch 88/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0247 - mae: 7.0247\n",
      "Epoch 89/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0196 - mae: 7.0196\n",
      "Epoch 90/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0127 - mae: 7.0127\n",
      "Epoch 91/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0194 - mae: 7.0194\n",
      "Epoch 92/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9995 - mae: 6.9995\n",
      "Epoch 93/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9943 - mae: 6.9943\n",
      "Epoch 94/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9984 - mae: 6.9984\n",
      "Epoch 95/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9866 - mae: 6.9866\n",
      "Epoch 96/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9870 - mae: 6.9870\n",
      "Epoch 97/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9776 - mae: 6.9776\n",
      "Epoch 98/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9860 - mae: 6.9860\n",
      "Epoch 99/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9738 - mae: 6.9738\n",
      "Epoch 100/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9720 - mae: 6.9720\n",
      "Epoch 101/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 102/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9711 - mae: 6.9711\n",
      "Epoch 103/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9583 - mae: 6.9583\n",
      "Epoch 104/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9417 - mae: 6.9417\n",
      "Epoch 105/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9564 - mae: 6.9564\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9628 - mae: 6.9628\n",
      "Epoch 107/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9296 - mae: 6.9296\n",
      "Epoch 108/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9449 - mae: 6.9449\n",
      "Epoch 109/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9349 - mae: 6.9349\n",
      "Epoch 110/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9424 - mae: 6.9424\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 111/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8718 - mae: 6.8718\n",
      "Epoch 112/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8546 - mae: 6.8546\n",
      "Epoch 113/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8465 - mae: 6.8465\n",
      "Epoch 114/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8429 - mae: 6.8429\n",
      "Epoch 115/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8425 - mae: 6.8425\n",
      "Epoch 116/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8396 - mae: 6.8396\n",
      "Epoch 117/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8385 - mae: 6.8385\n",
      "Epoch 118/200\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8368 - mae: 6.8368\n",
      "Epoch 119/200\n",
      "1451/1548 [===========================>..] - ETA: 0s - loss: 6.8274 - mae: 6.8274"
     ]
    }
   ],
   "source": [
    "a = [16,17,18,19,20,21,22,23,24,25,26,31,38,39,40,41,42,43,44,45,46,47]\n",
    "kf = 10\n",
    "p = 78\n",
    "KF = KFold(n_splits = kf,shuffle=True,random_state=7)\n",
    "MAE = np.zeros([kf])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, :]\n",
    "    train_X = train_X[:, [_ for _ in range(1,78) if _ in a]]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, :]\n",
    "    test_X = test_X[:, [_ for _ in range(1,78) if _ in a]]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Define Sequential model with 2 hidden layers\n",
    "    model_one_layers = keras.Sequential([\n",
    "        layers.Dense(22, activation = \"relu\", name = \"input\", input_dim = 22),\n",
    "        layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "        layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "        layers.Dense(1, name = \"output\")])\n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                verbose = 1)\n",
    "    # Optimizer for Adam\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "    model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "    # Train the model\n",
    "    history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "    # Prediction\n",
    "    test_predictions = model_one_layers.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel() - test_Y))\n",
    "    MAE[i] = model_error.mean()\n",
    "    i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_final_model_traditional.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5a027",
   "metadata": {},
   "source": [
    "### Model III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a45ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pd.read_csv('Data_model_citation_counts_new.csv')\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dde6de8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.6757 - mae: 9.6757\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.7589 - mae: 8.7589\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5209 - mae: 8.5209\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2421 - mae: 8.2421\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1665 - mae: 8.1665\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0415 - mae: 8.0415\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9932 - mae: 7.9932\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6669 - mae: 7.6669\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6879 - mae: 7.6879\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6469 - mae: 7.6469\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5970 - mae: 7.5970\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5405 - mae: 7.5405\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5041 - mae: 7.5041\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4433 - mae: 7.4433\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3941 - mae: 7.3941\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4075 - mae: 7.4075\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3283 - mae: 7.3283\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1539 - mae: 7.1539\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1748 - mae: 7.1748\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2243 - mae: 7.2243\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1388 - mae: 7.1388\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0409 - mae: 7.0409\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1168 - mae: 7.1168\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0369 - mae: 7.0369\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9981 - mae: 6.9981\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0234 - mae: 7.0234\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9642 - mae: 6.9642\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0564 - mae: 7.0564\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9241 - mae: 6.9241\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9406 - mae: 6.9406\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8853 - mae: 6.8853\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8350 - mae: 6.8350\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8376 - mae: 6.8376\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8588 - mae: 6.8588\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7328 - mae: 6.7328\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8355 - mae: 6.8355\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7700 - mae: 6.7700\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8109 - mae: 6.8109\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4308 - mae: 6.4308\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2044 - mae: 6.2044\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1200 - mae: 6.1200\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0434 - mae: 6.0434\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9996 - mae: 5.9996\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9533 - mae: 5.9533\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9201 - mae: 5.9201\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9001 - mae: 5.9001\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8840 - mae: 5.8840\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8388 - mae: 5.8388\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8448 - mae: 5.8448\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.2753 - mae: 9.2753\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4120 - mae: 8.4120\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9895 - mae: 7.9895\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8216 - mae: 7.8216\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7486 - mae: 7.7486\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6861 - mae: 7.6861\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6338 - mae: 7.6338\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5949 - mae: 7.5949\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5252 - mae: 7.5252\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4489 - mae: 7.4489\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3535 - mae: 7.3535\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2642 - mae: 7.2642\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3316 - mae: 7.3316\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2805 - mae: 7.2805\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2931 - mae: 7.2931\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7488 - mae: 6.7488\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6481 - mae: 6.6481\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5849 - mae: 6.5849\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5160 - mae: 6.5160\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4781 - mae: 6.4781\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4277 - mae: 6.4277\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4123 - mae: 6.4123\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3664 - mae: 6.3664\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3405 - mae: 6.3405\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3183 - mae: 6.3183\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2933 - mae: 6.2933\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2622 - mae: 6.2622\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2597 - mae: 6.2597\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2194 - mae: 6.2194\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2192 - mae: 6.2192\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1715 - mae: 6.1715\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1660 - mae: 6.1660\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1565 - mae: 6.1565\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1104 - mae: 6.1104\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1167 - mae: 6.1167\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0903 - mae: 6.0903\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0813 - mae: 6.0813\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0559 - mae: 6.0559\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0322 - mae: 6.0322\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0208 - mae: 6.0208\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9927 - mae: 5.9927\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9932 - mae: 5.9932\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9898 - mae: 5.9898\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9671 - mae: 5.9671\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9349 - mae: 5.9349\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9230 - mae: 5.9230\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9247 - mae: 5.9247\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8920 - mae: 5.8920\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8940 - mae: 5.8940\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8828 - mae: 5.8828\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4547 - mae: 9.4547\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5335 - mae: 8.5335\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2569 - mae: 8.2569\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1808 - mae: 8.1808\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1632 - mae: 8.1632\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8777 - mae: 7.8777\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8473 - mae: 7.8473\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7345 - mae: 7.7345\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7858 - mae: 7.7858\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5703 - mae: 7.5703\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6417 - mae: 7.6417\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4983 - mae: 7.4983\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4591 - mae: 7.4591\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4247 - mae: 7.4247\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4224 - mae: 7.4224\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3536 - mae: 7.3536\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4208 - mae: 7.4208\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3257 - mae: 7.3257\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3737 - mae: 7.3737\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2235 - mae: 7.2235\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2347 - mae: 7.2347\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0885 - mae: 7.0885\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2115 - mae: 7.2115\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1198 - mae: 7.1198\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0887 - mae: 7.0887\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7357 - mae: 6.7357\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.5288 - mae: 6.5288\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4488 - mae: 6.4488\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3901 - mae: 6.3901\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3571 - mae: 6.3571\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3073 - mae: 6.3073\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2637 - mae: 6.2637\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2480 - mae: 6.2480\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1983 - mae: 6.1983\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2031 - mae: 6.2031\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1690 - mae: 6.1690\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1386 - mae: 6.1386\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1199 - mae: 6.1199\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0976 - mae: 6.0976\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0745 - mae: 6.0745\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0547 - mae: 6.0547\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0407 - mae: 6.0407\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0236 - mae: 6.0236\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9938 - mae: 5.9938\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9750 - mae: 5.9750\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9556 - mae: 5.9556\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9486 - mae: 5.9486\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9234 - mae: 5.9234\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9101 - mae: 5.9101\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8949 - mae: 5.8949\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4898 - mae: 9.4898\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5949 - mae: 8.5949\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2306 - mae: 8.2306\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0964 - mae: 8.0964\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9374 - mae: 7.9374\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8221 - mae: 7.8221\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8220 - mae: 7.8220\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7626 - mae: 7.7626\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6576 - mae: 7.6576\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6979 - mae: 7.6979\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5677 - mae: 7.5677\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5517 - mae: 7.5517\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4662 - mae: 7.4662\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4639 - mae: 7.4639\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3618 - mae: 7.3618\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2484 - mae: 7.2484\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2636 - mae: 7.2636\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2111 - mae: 7.2111\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2848 - mae: 7.2848\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1309 - mae: 7.1309\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0512 - mae: 7.0512\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9883 - mae: 6.9883\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0162 - mae: 7.0162\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9321 - mae: 6.9321\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7877 - mae: 6.7877\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9879 - mae: 6.9879\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8494 - mae: 6.8494\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7663 - mae: 6.7663\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7716 - mae: 6.7716\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8477 - mae: 6.8477\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7408 - mae: 6.7408\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7680 - mae: 6.7680\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7961 - mae: 6.7961\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6365 - mae: 6.6365\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7012 - mae: 6.7012\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7143 - mae: 6.7143\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6972 - mae: 6.6972\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2166 - mae: 6.2166\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0385 - mae: 6.0385\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9707 - mae: 5.9707\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9176 - mae: 5.9176\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8839 - mae: 5.8839\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8515 - mae: 5.8515\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8250 - mae: 5.8250\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8038 - mae: 5.8038\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7812 - mae: 5.7812\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7788 - mae: 5.7788\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7626 - mae: 5.7626\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7412 - mae: 5.7412\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7344 - mae: 5.7344\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3242 - mae: 9.3242\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5068 - mae: 8.5068\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1278 - mae: 8.1278\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1103 - mae: 8.1103\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0413 - mae: 8.0413\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0073 - mae: 8.0073\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9078 - mae: 7.9078\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7655 - mae: 7.7655\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7029 - mae: 7.7029\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6518 - mae: 7.6518\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5308 - mae: 7.5308\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5602 - mae: 7.5602\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5001 - mae: 7.5001\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4321 - mae: 7.4321\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4734 - mae: 7.4734\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3548 - mae: 7.3548\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3718 - mae: 7.3718\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3994 - mae: 7.3994\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3259 - mae: 7.3259\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2275 - mae: 7.2275\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2787 - mae: 7.2787\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1730 - mae: 7.1730\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2104 - mae: 7.2104\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1100 - mae: 7.1100\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1513 - mae: 7.1513\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1648 - mae: 7.1648\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1436 - mae: 7.1436\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6258 - mae: 6.6258\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4622 - mae: 6.4622\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4016 - mae: 6.4016\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3740 - mae: 6.3740\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3207 - mae: 6.3207\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2962 - mae: 6.2962\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2596 - mae: 6.2596\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2418 - mae: 6.2418\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2070 - mae: 6.2070\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1753 - mae: 6.1753\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1578 - mae: 6.1578\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1351 - mae: 6.1351\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0963 - mae: 6.0963\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0904 - mae: 6.0904\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0659 - mae: 6.0659\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0471 - mae: 6.0471\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0180 - mae: 6.0180\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9985 - mae: 5.9985\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9809 - mae: 5.9809\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9843 - mae: 5.9843\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9688 - mae: 5.9688\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9451 - mae: 5.9451\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9191 - mae: 5.9191\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.2854 - mae: 9.2854\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4975 - mae: 8.4975\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2088 - mae: 8.2088\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1072 - mae: 8.1072\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9590 - mae: 7.9590\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8106 - mae: 7.8106\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7746 - mae: 7.7746\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6984 - mae: 7.6984\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6805 - mae: 7.6805\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6554 - mae: 7.6554\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4431 - mae: 7.4431\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3667 - mae: 7.3667\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3946 - mae: 7.3946\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3859 - mae: 7.3859\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3306 - mae: 7.3306\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3440 - mae: 7.3440\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2732 - mae: 7.2732\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1992 - mae: 7.1992\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2147 - mae: 7.2147\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2036 - mae: 7.2036\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1551 - mae: 7.1551\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0421 - mae: 7.0421\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0878 - mae: 7.0878\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0812 - mae: 7.0812\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9794 - mae: 6.9794\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9473 - mae: 6.9473\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9266 - mae: 6.9266\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9561 - mae: 6.9561\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8846 - mae: 6.8846\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9414 - mae: 6.9414\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9677 - mae: 6.9677\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9115 - mae: 6.9115\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4277 - mae: 6.4277\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2486 - mae: 6.2486\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1325 - mae: 6.1325\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0708 - mae: 6.0708\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0257 - mae: 6.0257\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9906 - mae: 5.9906\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9567 - mae: 5.9567\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9353 - mae: 5.9353\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8829 - mae: 5.8829\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9029 - mae: 5.9029\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8429 - mae: 5.8429\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8464 - mae: 5.8464\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8073 - mae: 5.8073\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8025 - mae: 5.8025\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7670 - mae: 5.7670\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7516 - mae: 5.7516\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7446 - mae: 5.7446\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7242 - mae: 5.7242\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4725 - mae: 9.4725\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6671 - mae: 8.6671\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.3613 - mae: 8.3613\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1731 - mae: 8.1731\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9952 - mae: 7.9952\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8865 - mae: 7.8865\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9504 - mae: 7.9504\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8153 - mae: 7.8153\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6952 - mae: 7.6952\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7441 - mae: 7.7441\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6667 - mae: 7.6667\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4938 - mae: 7.4938\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5323 - mae: 7.5323\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4557 - mae: 7.4557\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4729 - mae: 7.4729\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4333 - mae: 7.4333\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3230 - mae: 7.3230\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2000 - mae: 7.2000\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2747 - mae: 7.2747\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2297 - mae: 7.2297\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1724 - mae: 7.1724\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0947 - mae: 7.0947\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0476 - mae: 7.0476\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1229 - mae: 7.1229\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0287 - mae: 7.0287\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0185 - mae: 7.0185\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8870 - mae: 6.8870\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9465 - mae: 6.9465\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8859 - mae: 6.8859\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8505 - mae: 6.8505\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8845 - mae: 6.8845\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9536 - mae: 6.9536\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7774 - mae: 6.7774\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0128 - mae: 7.0128\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7884 - mae: 6.7884\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8204 - mae: 6.8204\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3135 - mae: 6.3135\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1686 - mae: 6.1686\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1151 - mae: 6.1151\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0613 - mae: 6.0613\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0128 - mae: 6.0128\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9856 - mae: 5.9856\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9565 - mae: 5.9565\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9097 - mae: 5.9097\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8711 - mae: 5.8711\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8675 - mae: 5.8675\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8398 - mae: 5.8398\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8082 - mae: 5.8082\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8154 - mae: 5.8154\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7919 - mae: 5.7919\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.3727 - mae: 9.3727\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.5130 - mae: 8.5130\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2946 - mae: 8.2946\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1217 - mae: 8.1217\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0155 - mae: 8.0155\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9042 - mae: 7.9042\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8054 - mae: 7.8054\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7067 - mae: 7.7067\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6487 - mae: 7.6487\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6247 - mae: 7.6247\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4915 - mae: 7.4915\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 5s 4ms/step - loss: 7.5193 - mae: 7.5193\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4264 - mae: 7.4264\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3783 - mae: 7.3783\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2247 - mae: 7.2247\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2887 - mae: 7.2887\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2366 - mae: 7.2366\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1883 - mae: 7.1883\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1578 - mae: 7.1578\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1561 - mae: 7.1561\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0688 - mae: 7.0688\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0180 - mae: 7.0180\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0382 - mae: 7.0382\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9579 - mae: 6.9579\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0658 - mae: 7.0658\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8487 - mae: 6.8487\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9105 - mae: 6.9105\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8485 - mae: 6.8485\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7741 - mae: 6.7741\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8645 - mae: 6.8645\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8928 - mae: 6.8928\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7427 - mae: 6.7427\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.8581 - mae: 6.8581\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7094 - mae: 6.7094\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6385 - mae: 6.6385\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7738 - mae: 6.7738\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.7620 - mae: 6.7620\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6741 - mae: 6.6741\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1607 - mae: 6.1607\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9770 - mae: 5.9770\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9156 - mae: 5.9156\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8737 - mae: 5.8737\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8366 - mae: 5.8366\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8072 - mae: 5.8072\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7696 - mae: 5.7696\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7633 - mae: 5.7633\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7326 - mae: 5.7326\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7258 - mae: 5.7258\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.6822 - mae: 5.6822\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7002 - mae: 5.7002\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.5577 - mae: 9.5577\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.6724 - mae: 8.6724\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2743 - mae: 8.2743\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1517 - mae: 8.1517\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0609 - mae: 8.0609\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9884 - mae: 7.9884\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9023 - mae: 7.9023\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7764 - mae: 7.7764\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6932 - mae: 7.6932\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6993 - mae: 7.6993\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5869 - mae: 7.5869\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5150 - mae: 7.5150\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4344 - mae: 7.4344\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3978 - mae: 7.3978\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3593 - mae: 7.3593\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3345 - mae: 7.3345\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3271 - mae: 7.3271\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2024 - mae: 7.2024\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1435 - mae: 7.1435\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1230 - mae: 7.1230\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1194 - mae: 7.1194\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1391 - mae: 7.1391\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0456 - mae: 7.0456\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0827 - mae: 7.0827\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9850 - mae: 6.9850\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.9863 - mae: 6.9863\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0459 - mae: 7.0459\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0592 - mae: 7.0592\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4638 - mae: 6.4638\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3614 - mae: 6.3614\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2685 - mae: 6.2685\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2321 - mae: 6.2321\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1387 - mae: 6.1387\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1126 - mae: 6.1126\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0680 - mae: 6.0680\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0746 - mae: 6.0746\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0188 - mae: 6.0188\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0116 - mae: 6.0116\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9999 - mae: 5.9999\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9712 - mae: 5.9712\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9365 - mae: 5.9365\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9536 - mae: 5.9536\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8985 - mae: 5.8985\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9182 - mae: 5.9182\n",
      "Epoch 45/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8733 - mae: 5.8733\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8705 - mae: 5.8705\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8467 - mae: 5.8467\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8476 - mae: 5.8476\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.8348 - mae: 5.8348\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.7992 - mae: 5.7992\n",
      "Epoch 1/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 9.4008 - mae: 9.4008\n",
      "Epoch 2/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.4526 - mae: 8.4526\n",
      "Epoch 3/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.1518 - mae: 8.1518\n",
      "Epoch 4/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.2106 - mae: 8.2106\n",
      "Epoch 5/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 8.0583 - mae: 8.0583\n",
      "Epoch 6/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9929 - mae: 7.9929\n",
      "Epoch 7/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.8980 - mae: 7.8980\n",
      "Epoch 8/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7987 - mae: 7.7987\n",
      "Epoch 9/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.9866 - mae: 7.9866\n",
      "Epoch 10/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7486 - mae: 7.7486\n",
      "Epoch 11/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.7203 - mae: 7.7203\n",
      "Epoch 12/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5682 - mae: 7.5682\n",
      "Epoch 13/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6893 - mae: 7.6893\n",
      "Epoch 14/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.6420 - mae: 7.6420\n",
      "Epoch 15/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.5466 - mae: 7.5466\n",
      "Epoch 16/50\n",
      "1548/1548 [==============================] - 5s 3ms/step - loss: 7.4131 - mae: 7.4131\n",
      "Epoch 17/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4518 - mae: 7.4518\n",
      "Epoch 18/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.4772 - mae: 7.4772\n",
      "Epoch 19/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3889 - mae: 7.3889\n",
      "Epoch 20/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.3268 - mae: 7.3268\n",
      "Epoch 21/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2480 - mae: 7.2480\n",
      "Epoch 22/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2144 - mae: 7.2144\n",
      "Epoch 23/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2485 - mae: 7.2485\n",
      "Epoch 24/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0749 - mae: 7.0749\n",
      "Epoch 25/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.2408 - mae: 7.2408\n",
      "Epoch 26/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.1156 - mae: 7.1156\n",
      "Epoch 27/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 7.0850 - mae: 7.0850\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 28/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.6013 - mae: 6.6013\n",
      "Epoch 29/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.4385 - mae: 6.4385\n",
      "Epoch 30/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3332 - mae: 6.3332\n",
      "Epoch 31/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.3086 - mae: 6.3086\n",
      "Epoch 32/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2611 - mae: 6.2611\n",
      "Epoch 33/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2331 - mae: 6.2331\n",
      "Epoch 34/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.2021 - mae: 6.2021\n",
      "Epoch 35/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1702 - mae: 6.1702\n",
      "Epoch 36/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1699 - mae: 6.1699\n",
      "Epoch 37/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1285 - mae: 6.1285\n",
      "Epoch 38/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.1130 - mae: 6.1130\n",
      "Epoch 39/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0957 - mae: 6.0957\n",
      "Epoch 40/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0836 - mae: 6.0836\n",
      "Epoch 41/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0392 - mae: 6.0392\n",
      "Epoch 42/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0603 - mae: 6.0603\n",
      "Epoch 43/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0470 - mae: 6.0470\n",
      "Epoch 44/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0112 - mae: 6.0112\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1548/1548 [==============================] - 6s 4ms/step - loss: 6.0075 - mae: 6.0075\n",
      "Epoch 46/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9758 - mae: 5.9758\n",
      "Epoch 47/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9603 - mae: 5.9603\n",
      "Epoch 48/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9723 - mae: 5.9723\n",
      "Epoch 49/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9441 - mae: 5.9441\n",
      "Epoch 50/50\n",
      "1548/1548 [==============================] - 6s 4ms/step - loss: 5.9091 - mae: 5.9091\n"
     ]
    }
   ],
   "source": [
    "kf = 10\n",
    "p = 61\n",
    "KF = KFold(n_splits = kf,shuffle=True,random_state=7)\n",
    "MAE = np.zeros([kf])\n",
    "i = 0\n",
    "for train_index,test_index in KF.split(data):\n",
    "    train_X = data[train_index, 1:p+1]\n",
    "    train_Y = data[train_index, 0]\n",
    "    test_X = data[test_index, 1:p+1]\n",
    "    test_Y = data[test_index, 0]\n",
    "    # Define Sequential model with 2 hidden layers\n",
    "    model_one_layers = keras.Sequential([\n",
    "        layers.Dense(60, activation = \"relu\", name = \"input\", input_dim = 60),\n",
    "        layers.Dense(150, activation = \"relu\", name = \"layer1\"),\n",
    "        layers.Dense(130, activation = \"relu\", name = \"layer2\"),\n",
    "        layers.Dense(1, name = \"output\")])\n",
    "    # ReduceLROnPlateau\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'mae', \n",
    "                factor = 0.5, # Divide the learning rate by 2 when triggered\n",
    "                patience = 3, # If the verification loss does not improve within 3 rounds, then trigger this callback function\n",
    "                verbose = 1)\n",
    "    # Optimizer for Adam\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "    model_one_layers.compile(optimizer = optimizer,\n",
    "                    loss = 'mae',\n",
    "                    metrics = ['mae'])\n",
    "    # Train the model\n",
    "    history = model_one_layers.fit(train_X, train_Y, epochs = 200, verbose = 1, callbacks = [reduce_lr])\n",
    "    # Prediction\n",
    "    test_predictions = model_one_layers.predict(test_X)\n",
    "    # MAE\n",
    "    model_error = abs((test_predictions.ravel() - test_Y))\n",
    "    MAE[i] = model_error.mean()\n",
    "    i = i + 1\n",
    "# Save result\n",
    "MAE = pd.DataFrame(list(MAE))\n",
    "MAE.to_csv(\"MAE_final_model_lda.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3dc6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE.to_csv(\"MAE_final_model_lda.csv\", sep = \",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc22448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
